<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/akasha/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/akasha/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/akasha/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/akasha/images/logo.svg" color="#222">

<link rel="stylesheet" href="/akasha/css/main.css">


<link rel="stylesheet" href="/akasha/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"tea9297.github.io","root":"/akasha/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="akasha 0.9 使用手冊">
<meta property="og:url" content="https://tea9297.github.io/akasha/index.html">
<meta property="og:site_name" content="akasha 0.9 使用手冊">
<meta property="og:locale" content="zh_TW">
<meta property="article:author" content="Chih Chuan Chang&lt;ccchang@iii.org.tw&gt;">
<meta property="article:tag" content="akasha, manual, llm, rag">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://tea9297.github.io/akasha/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-TW'
  };
</script>

  <title>akasha 0.9 使用手冊</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/akasha/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">akasha 0.9 使用手冊</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">akasha 0.9 manual</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/akasha/" rel="section"><i class="fa fa-home fa-fw"></i>首頁</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/akasha/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>歸檔</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/31/%E7%9B%AE%E9%8C%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/31/%E7%9B%AE%E9%8C%84/" class="post-title-link" itemprop="url">目錄</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-31 23:59:59" itemprop="dateCreated datePublished" datetime="2024-12-31T23:59:59+08:00">2024-12-31</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2025-04-21 14:52:23" itemprop="dateModified" datetime="2025-04-21T14:52:23+08:00">2025-04-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E7%9B%AE%E9%8C%84/" itemprop="url" rel="index"><span itemprop="name">目錄</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="目錄"><a href="#目錄" class="headerlink" title="目錄"></a>目錄</h1><h2 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h2><ul>
<li><a href="/2024/12/31/2025%20updates/">2025 updates</a></li>
</ul>
<h2 id="安裝-設定"><a href="#安裝-設定" class="headerlink" title="安裝&amp;設定"></a>安裝&amp;設定</h2><ul>
<li><a href="/2024/12/30/%E5%AE%89%E8%A3%9D&%E4%BD%BF%E7%94%A8/">安裝&amp;使用</a></li>
<li><a href="/2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/">設定 API Key</a></li>
<li><a href="/2024/12/30/%E8%A8%AD%E5%AE%9A%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B/">設定語言模型</a></li>
<li><a href="/2024/12/30/%E8%A8%AD%E5%AE%9A%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/">設定嵌入模型</a></li>
</ul>
</br>
</br>


<h2 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h2><ul>
<li><a href="/2024/12/29/RAG/">RAG</a></li>
<li><a href="/2024/12/29/get_response/">get_response</a></li>
<li><a href="/2024/12/29/ask_whole_file/">ask_whole_file</a></li>
<li><a href="/2024/12/29/ask_self/">ask_self</a></li>
<li><a href="/2024/12/29/ask_agent/">ask_agent</a></li>
<li><a href="/2024/12/29/ask_image/">ask_image</a></li>
</ul>
</br>
</br>

<h2 id="評估"><a href="#評估" class="headerlink" title="評估"></a>評估</h2><ul>
<li><a href="/2024/12/28/auto_evaluation/">auto_evaluation</a></li>
<li><a href="/2024/12/28/auto_create_questionset/">auto_create_questionset</a></li>
<li><a href="/2024/12/28/optimum_combination/">optimum_combination</a></br>
</br></li>
</ul>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><ul>
<li><a href="/2024/12/27/summary/">summary</a></li>
</ul>
</br>
</br>

<h2 id="進階"><a href="#進階" class="headerlink" title="進階"></a>進階</h2><ul>
<li><a href="/2024/12/26/%E6%8F%90%E7%A4%BA%E6%A0%BC%E5%BC%8F/">提示格式</a></li>
<li><a href="/2024/12/26/%E6%96%87%E4%BB%B6%E6%90%9C%E5%B0%8B/">文件搜尋</a></li>
<li><a href="/2024/12/26/%E5%90%91%E9%87%8F%E8%B3%87%E6%96%99%E5%BA%AB/">向量資料庫</a></li>
<li><a href="/2024/12/26/%E8%BC%94%E5%8A%A9%E5%87%BD%E6%95%B8/">輔助函數</a></li>
<li><a href="/2024/12/26/%E4%BB%A3%E7%90%86/">代理</a></li>
<li><a href="/2024/12/26/%E6%B5%81%E8%BC%B8%E5%87%BA/">流輸出</a></li>
<li><a href="/2024/12/26/%E6%89%B9%E9%87%8F%E6%8E%A8%E7%90%86/">批量推理</a></li>
<li><a href="/2024/12/26/FAST%20API/">FAST API</a></li>
<li><a href="/2024/12/26/%E8%87%AA%E6%9F%A5%E8%A9%A2/">自查詢</a></li>
</ul>
</br>
</br>





<h2 id="UI"><a href="#UI" class="headerlink" title="UI"></a>UI</h2><ul>
<li><a href="/2024/12/24/ui%E8%A8%AD%E5%AE%9A/">ui設定</a></li>
<li><a href="/2024/12/24/ui%E6%93%8D%E4%BD%9C/">ui操作</a></li>
</ul>
</br>
</br>



<h2 id="UI-DEV"><a href="#UI-DEV" class="headerlink" title="UI-DEV"></a>UI-DEV</h2><ul>
<li><a href="/2024/01/01/DEV-%E5%AE%89%E8%A3%9D&%E5%9F%B7%E8%A1%8C/">DEV-安裝&amp;執行</a></li>
<li><a href="/2024/01/01/DEV-%E8%A8%BB%E5%86%8A%E5%B8%B3%E8%99%9F/">DEV-註冊帳號</a></li>
<li><a href="/2024/01/01/DEV-%E8%A8%AD%E5%AE%9A/">DEV-設定</a></li>
<li><a href="/2024/01/01/DEV-Datasets/">DEV-Datasets</a></li>
<li><a href="/2024/01/01/DEV-Knowledges/">DEV-Knowledges</a></li>
<li><a href="/2024/01/01/DEV-Consult/">DEV-Consult</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/31/2025%20updates/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/31/2025%20updates/" class="post-title-link" itemprop="url">2025 updates 0.9</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-31 23:57:58" itemprop="dateCreated datePublished" datetime="2024-12-31T23:57:58+08:00">2024-12-31</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2025-04-11 12:29:14" itemprop="dateModified" datetime="2025-04-11T12:29:14+08:00">2025-04-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E7%9B%AE%E9%8C%84/" itemprop="url" rel="index"><span itemprop="name">目錄</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="01-07-0-8-86"><a href="#01-07-0-8-86" class="headerlink" title="01&#x2F;07(0.8.86)"></a>01&#x2F;07(0.8.86)</h2><ul>
<li>更新huggingface embedding 以支援更多sentence transformer嵌入模型</li>
<li>新增 環境變數 <em><strong>REMOTE_API_KEY</strong></em>用來設定遠端api的金鑰 (見<a href="/2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/">設定 API Key</a>)</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/30/%E5%AE%89%E8%A3%9D&%E4%BD%BF%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/30/%E5%AE%89%E8%A3%9D&%E4%BD%BF%E7%94%A8/" class="post-title-link" itemprop="url">安裝&使用</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-30 23:59:59" itemprop="dateCreated datePublished" datetime="2024-12-30T23:59:59+08:00">2024-12-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2025-04-14 15:52:07" itemprop="dateModified" datetime="2025-04-14T15:52:07+08:00">2025-04-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E5%AE%89%E8%A3%9D-%E8%A8%AD%E5%AE%9A/" itemprop="url" rel="index"><span itemprop="name">安裝&設定</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="使用anaconda和pip安裝akasha套件"><a href="#使用anaconda和pip安裝akasha套件" class="headerlink" title="使用anaconda和pip安裝akasha套件"></a>使用anaconda和pip安裝akasha套件</h2><p>Linux使用者安裝完畢anaconda，進行安裝akasha套件。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">###create environment</span><br><span class="line">$ conda create --name py3-10 python=3.10</span><br><span class="line">$ activate py3-10</span><br><span class="line"></span><br><span class="line">###install akasha</span><br><span class="line">$ pip install akasha-terminal</span><br></pre></td></tr></table></figure>

</br>
</br>


<h2 id="使用uv安裝akasha套件"><a href="#使用uv安裝akasha套件" class="headerlink" title="使用uv安裝akasha套件"></a>使用uv安裝akasha套件</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">###create environment</span><br><span class="line">$ uv venv --python 3.10</span><br><span class="line"></span><br><span class="line">###install akasha</span><br><span class="line">$ uv pip install akasha-terminal</span><br></pre></td></tr></table></figure>

</br>
</br>

<h2 id="在Python中使用"><a href="#在Python中使用" class="headerlink" title="在Python中使用"></a>在Python中使用</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># PYTHON3.10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line">ak = akasha.RAG(</span><br><span class="line">    embeddings=<span class="string">&quot;openai:text-embedding-3-small&quot;</span>,</span><br><span class="line">    model=<span class="string">&quot;openai:gpt-4o&quot;</span>,</span><br><span class="line">    max_input_tokens=<span class="number">3000</span>,</span><br><span class="line">    keep_logs=<span class="literal">True</span>,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">res = ak(</span><br><span class="line">    data_source=[<span class="string">&quot;docs/mic&quot;</span>, <span class="string">&quot;https://github.com/iii-org/akasha&quot;</span>],</span><br><span class="line">    prompt=PROMPT,</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</br>
</br>

<h2 id="簡單UI介面"><a href="#簡單UI介面" class="headerlink" title="簡單UI介面"></a>簡單UI介面</h2><p>在terminal上輸入，便會開起streamlit使用介面</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ akasha toy</span><br></pre></td></tr></table></figure>
</br>

<p>在瀏覽器中開啟 <a target="_blank" rel="noopener" href="http://localhost:8501/">http://localhost:8501/</a> <img src="https://hackmd.io/_uploads/SJ5f34qAyx.png" alt="ui_5"><br>進行設定後，便可在ui介面使用akasha的功能，詳情見 <img src="/akasha/2024/12/24/ui%E8%A8%AD%E5%AE%9A/" alt="ui設定"><br><strong>此介面僅為簡單展示，不適合作為服務使用</strong></p>
</br>
</br>

<h2 id="CLI"><a href="#CLI" class="headerlink" title="CLI"></a>CLI</h2><p>透過command line interface使用akasha，你可以用’keep-rag’來建立一個文檔問答模型，並可以提出不同的問題，根據給定目錄中的文檔獲取語言模型的回答。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">akasha keep-rag -d ../doc/plc/  -c 400</span></span><br><span class="line">Please input your question(type &quot;exit()&quot; to quit) : 應回收廢塑膠容器材質種類不包含哪種?  聚丙烯（PP） 聚苯乙烯（PS） 聚氯乙烯（PVC）  低密度聚乙烯（LDPE）</span><br><span class="line">Response:  應回收廢塑膠容器材質種類不包含低密度聚乙烯（LDPE）。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Please input your question(type &quot;exit()&quot; to quit) : 所謂市盈率，是指每股市價除以每股盈餘，也就是股票的?   本益比  帳面值比  派息   資金</span><br><span class="line">英國和德國等多個市場。然而，義大利、加拿大和澳洲並不在這些可交易的國家之列。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Please input your question(type &quot;exit()&quot; to quit) : exit()</span><br></pre></td></tr></table></figure>

</br>
</br>

<p>現在可使用的指令: <em><strong>rag</strong></em>, <em><strong>keep-rag</strong></em>, <em><strong>toy</strong></em>, <em><strong>api</strong></em> and <em><strong>auto-evaluation</strong></em>.</p>
</br>


<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">akasha keep-rag --<span class="built_in">help</span></span></span><br><span class="line">Usage: akasha keep-rag [OPTIONS]</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -d, --data_source TEXT          document directory path, or urls, parse all</span><br><span class="line">                                  .txt, .pdf, .docx files in the directory   </span><br><span class="line">                                  [required]</span><br><span class="line">  -e, --embeddings TEXT           embeddings for storing the documents</span><br><span class="line">  -c, --chunk_size INTEGER        chunk size for storing the documents</span><br><span class="line">  -m, --model TEXT                llm model for generating the response</span><br><span class="line">  -l, --language TEXT             language for the documents, default is &#x27;ch&#x27;</span><br><span class="line">                                  for chinese</span><br><span class="line">  -s, --search_type TEXT          search type for the documents, include</span><br><span class="line">                                  auto, knn, svm, bm25</span><br><span class="line">  -sys, --system_prompt TEXT      system prompt for the llm model</span><br><span class="line">  -md, --max_input_tokens INTEGER</span><br><span class="line">                                  max token for the llm model input</span><br><span class="line">  --help                          Show this message and exit.</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>

<h2 id="安裝WSL"><a href="#安裝WSL" class="headerlink" title="安裝WSL"></a>安裝WSL</h2><p>windows使用者可以安裝Windows子系統(WSL)，直接在Windows 執行Linux，請先確認windows版本是 Windows 10 版本 2004(組建 19041 和更新版本)或 Windows 11以上的版本才能安裝WSL。<br>先搜尋PowerShell，以系統管理員開啟 PowerShell執行WSL並安裝linux ubuntu，安裝完畢後要重新開機。</p>
<h3 id="install-wsl"><a href="#install-wsl" class="headerlink" title="install wsl"></a>install wsl</h3><p>安裝WSL並且安裝linux ubuntu。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ wsl --install</span><br></pre></td></tr></table></figure>
<p>安裝完畢，重新開機</p>
<h3 id="更新ubuntu"><a href="#更新ubuntu" class="headerlink" title="更新ubuntu"></a>更新ubuntu</h3><p>重新開機後，開啟wsl，更新ubuntu到最新版本</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt update -y &amp;&amp; sudo apt upgrade -y</span><br></pre></td></tr></table></figure>

<h3 id="更新系統套件到最新版本"><a href="#更新系統套件到最新版本" class="headerlink" title="更新系統套件到最新版本"></a>更新系統套件到最新版本</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$sudo apt update &amp;&amp; upgrade</span><br></pre></td></tr></table></figure>
<h3 id="安裝curl-套件"><a href="#安裝curl-套件" class="headerlink" title="安裝curl 套件"></a>安裝curl 套件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$sudo apt install curl</span><br></pre></td></tr></table></figure>
<h3 id="安裝anaconda"><a href="#安裝anaconda" class="headerlink" title="安裝anaconda"></a>安裝anaconda</h3><h3 id="先建立一個資料夾"><a href="#先建立一個資料夾" class="headerlink" title="先建立一個資料夾"></a>先建立一個資料夾</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$mkdir temp</span><br></pre></td></tr></table></figure>

<h3 id="進入資料夾"><a href="#進入資料夾" class="headerlink" title="進入資料夾"></a>進入資料夾</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$cd temp</span><br></pre></td></tr></table></figure>
<h3 id="下載anaconda-sh"><a href="#下載anaconda-sh" class="headerlink" title="下載anaconda.sh"></a>下載anaconda.sh</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$curl https://repo.anaconda.com/archive/Anaconda3-2023.09-0-Linux-x86_64.sh --output anaconda.sh</span><br></pre></td></tr></table></figure>
<h3 id="安裝anaconda-1"><a href="#安裝anaconda-1" class="headerlink" title="安裝anaconda"></a>安裝anaconda</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$bash anaconda.sh</span><br></pre></td></tr></table></figure>

<h3 id="新增conda-指令"><a href="#新增conda-指令" class="headerlink" title="新增conda 指令"></a>新增conda 指令</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$source ~/.bashrc</span><br></pre></td></tr></table></figure>

<h3 id="確認conda-有安裝成功"><a href="#確認conda-有安裝成功" class="headerlink" title="確認conda 有安裝成功"></a>確認conda 有安裝成功</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$conda info</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/" class="post-title-link" itemprop="url">設定 API Key</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-30 22:59:59" itemprop="dateCreated datePublished" datetime="2024-12-30T22:59:59+08:00">2024-12-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2025-04-14 15:54:22" itemprop="dateModified" datetime="2025-04-14T15:54:22+08:00">2025-04-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E5%AE%89%E8%A3%9D-%E8%A8%AD%E5%AE%9A/" itemprop="url" rel="index"><span itemprop="name">安裝&設定</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="openAI-API-Key"><a href="#openAI-API-Key" class="headerlink" title="openAI API Key"></a>openAI API Key</h1></br>
</br>

<h2 id="openAI"><a href="#openAI" class="headerlink" title="openAI:"></a>openAI:</h2><p>如果需要使用openAI的模型，必須先去<a target="_blank" rel="noopener" href="https://platform.openai.com/account/api-keys">openai</a>取得API金鑰。取得金鑰後，你可以選擇其中一種方法來匯入key:</p>
<h5 id="1-將KEY放於-env檔案中OPENAI-API-KEY-your-api-key"><a href="#1-將KEY放於-env檔案中OPENAI-API-KEY-your-api-key" class="headerlink" title="1.將KEY放於.env檔案中OPENAI_API_KEY&#x3D;your api key"></a>1.將KEY放於.env檔案中OPENAI_API_KEY&#x3D;your api key</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">OPENAI_API_KEY=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="2-設定成環境變數-變數名-OPENAI-API-KEY"><a href="#2-設定成環境變數-變數名-OPENAI-API-KEY" class="headerlink" title="2.設定成環境變數(變數名:OPENAI_API_KEY)"></a>2.設定成環境變數(變數名:OPENAI_API_KEY)</h5><h5 id="3-在terminal中使用export設定環境變數"><a href="#3-在terminal中使用export設定環境變數" class="headerlink" title="3.在terminal中使用export設定環境變數"></a>3.在terminal中使用export設定環境變數</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export OPENAI_API_KEY=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="4-在Python中使用os-environ-‘OPENAI-API-KEY’-your-api-key"><a href="#4-在Python中使用os-environ-‘OPENAI-API-KEY’-your-api-key" class="headerlink" title="4.在Python中使用os.environ[‘OPENAI_API_KEY’]&#x3D;your api key"></a>4.在Python中使用os.environ[‘OPENAI_API_KEY’]&#x3D;your api key</h5></br>
</br>

<h2 id="Azure-openAI"><a href="#Azure-openAI" class="headerlink" title="Azure openAI"></a>Azure openAI</h2><p>如果你想使用Azure openAI，先去<a target="_blank" rel="noopener" href="https://oai.azure.com/portal">azureAI</a>取得base url 和 API key。</p>
<p>將<em><strong>OPENAI_API_KEY&#x3D;your azure key</strong></em>, <em><strong>OPENAI_API_BASE&#x3D;your Language API base url</strong></em>, <em><strong>OPENAI_API_TYPE&#x3D;azure</strong></em>, <em><strong>OPENAI_API_VERSION&#x3D;2023-05-15</strong></em> 寫於.env檔案並放於你要執行akasha的路徑中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">## .env file</span><br><span class="line">AZURE_API_KEY=&#123;your azure key&#125;</span><br><span class="line">AZURE_API_BASE=&#123;your Language API base url&#125;</span><br><span class="line">AZURE_API_TYPE=azure</span><br><span class="line">AZURE_API_VERSION=2023-05-15</span><br></pre></td></tr></table></figure>


<h3 id="請記得在Azure-openAI-Studio部署所有你需要的模型，且部署名稱與模型名稱相同。"><a href="#請記得在Azure-openAI-Studio部署所有你需要的模型，且部署名稱與模型名稱相同。" class="headerlink" title="請記得在Azure openAI Studio部署所有你需要的模型，且部署名稱與模型名稱相同。"></a>請記得在<a target="_blank" rel="noopener" href="https://oai.azure.com/portal">Azure openAI Studio</a>部署所有你需要的模型，且部署名稱與模型名稱相同。</h3></br>
</br>


<h1 id="gemini-API-Key"><a href="#gemini-API-Key" class="headerlink" title="gemini API Key"></a>gemini API Key</h1><p>如果你想使用Gemini 模型，請至<a target="_blank" rel="noopener" href="https://aistudio.google.com/">google aistudio</a> 或 <a target="_blank" rel="noopener" href="https://console.cloud.google.com/">GCP</a>申請API金鑰。</p>
<p>取得金鑰後，你可以選擇其中一種方法來匯入key:</p>
<h5 id="1-將KEY放於-env檔案中GEMINI-API-KEY-your-api-key"><a href="#1-將KEY放於-env檔案中GEMINI-API-KEY-your-api-key" class="headerlink" title="1.將KEY放於.env檔案中GEMINI_API_KEY&#x3D;your api key"></a>1.將KEY放於.env檔案中GEMINI_API_KEY&#x3D;your api key</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GEMINI_API_KEY=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="2-設定成環境變數-變數名-GEMINI-API-KEY"><a href="#2-設定成環境變數-變數名-GEMINI-API-KEY" class="headerlink" title="2.設定成環境變數(變數名:GEMINI_API_KEY)"></a>2.設定成環境變數(變數名:GEMINI_API_KEY)</h5><h5 id="3-在terminal中使用export設定環境變數-1"><a href="#3-在terminal中使用export設定環境變數-1" class="headerlink" title="3.在terminal中使用export設定環境變數"></a>3.在terminal中使用export設定環境變數</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export GEMINI_API_KEY=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="4-在Python中使用os-environ-‘GEMINI-API-KEY’-your-api-key"><a href="#4-在Python中使用os-environ-‘GEMINI-API-KEY’-your-api-key" class="headerlink" title="4.在Python中使用os.environ[‘GEMINI_API_KEY’]&#x3D;your api key"></a>4.在Python中使用os.environ[‘GEMINI_API_KEY’]&#x3D;your api key</h5></br>
</br>

<h1 id="anthropic-API-Key"><a href="#anthropic-API-Key" class="headerlink" title="anthropic API Key"></a>anthropic API Key</h1><p>如果你想使用Gemini 模型，請至<a target="_blank" rel="noopener" href="https://www.anthropic.com/api/">anthropic</a>申請API金鑰。</p>
<p>取得金鑰後，你可以選擇其中一種方法來匯入key:</p>
<h5 id="1-將KEY放於-env檔案中ANTHROPIC-API-KEY-your-api-key"><a href="#1-將KEY放於-env檔案中ANTHROPIC-API-KEY-your-api-key" class="headerlink" title="1.將KEY放於.env檔案中ANTHROPIC_API_KEY&#x3D;your api key"></a>1.將KEY放於.env檔案中ANTHROPIC_API_KEY&#x3D;your api key</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ANTHROPIC_API_KEY=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="2-設定成環境變數-變數名-ANTHROPIC-API-KEY"><a href="#2-設定成環境變數-變數名-ANTHROPIC-API-KEY" class="headerlink" title="2.設定成環境變數(變數名:ANTHROPIC_API_KEY)"></a>2.設定成環境變數(變數名:ANTHROPIC_API_KEY)</h5><h5 id="3-在terminal中使用export設定環境變數-2"><a href="#3-在terminal中使用export設定環境變數-2" class="headerlink" title="3.在terminal中使用export設定環境變數"></a>3.在terminal中使用export設定環境變數</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export ANTHROPIC_API_KEY=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="4-在Python中使用os-environ-‘ANTHROPIC-API-KEY’-your-api-key"><a href="#4-在Python中使用os-environ-‘ANTHROPIC-API-KEY’-your-api-key" class="headerlink" title="4.在Python中使用os.environ[‘ANTHROPIC_API_KEY’]&#x3D;your api key"></a>4.在Python中使用os.environ[‘ANTHROPIC_API_KEY’]&#x3D;your api key</h5></br>
</br>


<h1 id="遠端API-Key"><a href="#遠端API-Key" class="headerlink" title="遠端API Key"></a>遠端API Key</h1><p>如果你想使用的遠端模型需指定API金鑰</p>
<h5 id="1-將KEY放於-env檔案中RETMOE-API-KEY-your-api-key"><a href="#1-將KEY放於-env檔案中RETMOE-API-KEY-your-api-key" class="headerlink" title="1.將KEY放於.env檔案中RETMOE_API_KEY&#x3D;your api key"></a>1.將KEY放於.env檔案中RETMOE_API_KEY&#x3D;your api key</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">REMOTE_API_KEY=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="2-設定成環境變數-變數名-REMOTE-API-KEY"><a href="#2-設定成環境變數-變數名-REMOTE-API-KEY" class="headerlink" title="2.設定成環境變數(變數名:REMOTE_API_KEY)"></a>2.設定成環境變數(變數名:REMOTE_API_KEY)</h5><h5 id="3-在terminal中使用export設定環境變數-3"><a href="#3-在terminal中使用export設定環境變數-3" class="headerlink" title="3.在terminal中使用export設定環境變數"></a>3.在terminal中使用export設定環境變數</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export REMOTE_API_KEY=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>

<h5 id="4-在Python中使用os-environ-‘REMOTE-API-KEY’-your-api-key"><a href="#4-在Python中使用os-environ-‘REMOTE-API-KEY’-your-api-key" class="headerlink" title="4.在Python中使用os.environ[‘REMOTE_API_KEY’]&#x3D;your api key"></a>4.在Python中使用os.environ[‘REMOTE_API_KEY’]&#x3D;your api key</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os </span><br><span class="line">os.environ[<span class="string">&#x27;REMOTE_API_KEY&#x27;</span>]=<span class="string">&quot;your api key&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


</br>
</br>
</br>
</br>


<h2 id="LLAMA-2"><a href="#LLAMA-2" class="headerlink" title="LLAMA-2"></a>LLAMA-2</h2><p>如果你想使用原版的meta-llama model，並須先去<a target="_blank" rel="noopener" href="https://ai.meta.com/resources/models-and-libraries/llama-downloads/">meta-llama</a>去取得授權，並註冊<a target="_blank" rel="noopener" href="https://huggingface.co/login?next=/settings/tokens">huggingface</a>取得access token，取得授權後才能經由huggingface下載並使用模型。<br><img src="https://hackmd.io/_uploads/H1LOb2ot6.png" alt="granted"></p>
<p>the account on Hugging Face and the email you use to request access to Meta-Llama must be the same, so that you can download models from Hugging Face once your account is approved.</p>
<p>You should see the Gated model You have been granted access to this model once your account is approved</p>
</br>
</br>


<p>同樣的，取得huggingface key值後，你可以選擇其中一種方法來匯入key:</p>
<h5 id="1-將KEY放於-env檔案中HF-TOKEN-your-api-key"><a href="#1-將KEY放於-env檔案中HF-TOKEN-your-api-key" class="headerlink" title="1.將KEY放於.env檔案中HF_TOKEN&#x3D;your api key"></a>1.將KEY放於.env檔案中HF_TOKEN&#x3D;your api key</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HF_TOKEN=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="2-設定成環境變數-變數名-HF-TOKEN"><a href="#2-設定成環境變數-變數名-HF-TOKEN" class="headerlink" title="2.設定成環境變數(變數名:HF_TOKEN)"></a>2.設定成環境變數(變數名:HF_TOKEN)</h5><h5 id="3-在terminal中使用export設定環境變數-4"><a href="#3-在terminal中使用export設定環境變數-4" class="headerlink" title="3.在terminal中使用export設定環境變數"></a>3.在terminal中使用export設定環境變數</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export HF_TOKEN=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="4-在Python中使用os-environ-‘HF-TOKEN’-your-api-key"><a href="#4-在Python中使用os-environ-‘HF-TOKEN’-your-api-key" class="headerlink" title="4.在Python中使用os.environ[‘HF_TOKEN’]&#x3D;your api key"></a>4.在Python中使用os.environ[‘HF_TOKEN’]&#x3D;your api key</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#PYTHON3.9</span><br><span class="line"># os.environ[&#x27;HF_TOKEN&#x27;]=your api key</span><br><span class="line">import akasha</span><br><span class="line">ak = akasha.Doc_QA()</span><br><span class="line">response = ak.get_response(dir_path, prompt, model=&quot;hf:meta-llama/Llama-2-7b-chat-hf&quot;)</span><br></pre></td></tr></table></figure>


</br>
</br>

<h1 id="設定多組不同API-KEY"><a href="#設定多組不同API-KEY" class="headerlink" title="設定多組不同API KEY"></a>設定多組不同API KEY</h1><p>若你需要根據不同模型設定不同的API KEY，在Doc_QA, Model_Eval, Summary Class中皆提供env_file參數，可輸入不同的.env檔來export API KEY<br>若不存在或為空值，則為預設值(.env)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line">ak = akasha.ask(<span class="string">&quot;openai:gpt-4o&quot;</span>, env_file=<span class="string">&quot;.env&quot;</span>, verbose=<span class="literal">True</span>)</span><br><span class="line">ak(<span class="string">&quot;日本本州最大的城市是哪裡?&quot;</span>)</span><br><span class="line"></span><br><span class="line">ak2 = akasha.ak(<span class="string">&quot;openai:gpt-4&quot;</span>, env_file=<span class="string">&quot;.env2&quot;</span>, verbose=<span class="literal">True</span>)</span><br><span class="line">ak2(<span class="string">&quot;日本本州最大的城市是哪裡?&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">設定語言模型</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-30 21:59:59" itemprop="dateCreated datePublished" datetime="2024-12-30T21:59:59+08:00">2024-12-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2025-04-14 16:19:54" itemprop="dateModified" datetime="2025-04-14T16:19:54+08:00">2025-04-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E5%AE%89%E8%A3%9D-%E8%A8%AD%E5%AE%9A/" itemprop="url" rel="index"><span itemprop="name">安裝&設定</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="選擇不同語言模型"><a href="#選擇不同語言模型" class="headerlink" title="選擇不同語言模型"></a>選擇不同語言模型</h2><p>使用參數<em><strong>model</strong></em>便可以選擇不同的語言模型，預設是<em><strong>openai:gpt-3.5-turbo</strong></em>.</p>
<h2 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h2><h3 id="1-openai"><a href="#1-openai" class="headerlink" title="1. openai"></a>1. openai</h3><p>(請先完成<a href="/2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/">設定 API Key</a>)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">akasha.RAG(embeddings=&quot;openai:text-embedding-ada-002&quot;,</span><br><span class="line">                model=&quot;openai:gpt-3.5-turbo&quot;)</span><br><span class="line">ak(dir_path, prompt, )</span><br></pre></td></tr></table></figure>

</br>
</br>

<h3 id="2-huggingface"><a href="#2-huggingface" class="headerlink" title="2. huggingface"></a>2. huggingface</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.RAG(embeddings=&quot;hf:Alibaba-NLP/gte-multilingual-base&quot;,</span><br><span class="line">                model=&quot;hf:Qwen/Qwen2.5-7B-Instruct&quot;)</span><br><span class="line">ak(dir_path, prompt, )</span><br></pre></td></tr></table></figure>
</br>
</br>

<h3 id="3-llama-cpp"><a href="#3-llama-cpp" class="headerlink" title="3. llama-cpp"></a>3. llama-cpp</h3><p>安裝llama-cpp-python可以使用cpu推論.gguf格式的模型，或是安裝akasha時選擇llama-cpp</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install llama-cpp-python</span><br><span class="line">#pip install akasha-terminal[llama-cpp]</span><br></pre></td></tr></table></figure>

<p>llama-cpp允許使用quantized模型並執行在cpu上，你可以從huggingface上下載.gguf llama-cpp 模型，如範例，如果你的模型下載到”model&#x2F;“路徑下，可以使用以下方法加載模型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.RAG(embeddings=&quot;hf:Alibaba-NLP/gte-multilingual-base&quot;,</span><br><span class="line">                model=&quot;llama-cpp:model/llama-2-13b-chat.Q5_K_S.gguf&quot;)</span><br><span class="line">ak(dir_path, prompt,)</span><br></pre></td></tr></table></figure>
</br>
</br>

<p>llama-cpp同樣允許使用gpu運算模型，但安裝套件時需要使用cmake安裝，並確認已安裝g++, gcc和nvidia driver &amp; toolkit，詳細請見<a target="_blank" rel="noopener" href="https://github.com/abetlen/llama-cpp-python">llama-cpp-python</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CMAKE_ARGS=&quot;-DGGML_CUDA=on&quot; FORCE_CMAKE=1 python -m pip install --upgrade --force-reinstall llama-cpp-python&gt;=0.3.1 --no-cache-dir</span><br></pre></td></tr></table></figure>

</br>
</br>

<h3 id="4-遠端api"><a href="#4-遠端api" class="headerlink" title="4. 遠端api"></a>4. 遠端api</h3><p>如果你使用別人的api或者透過支援openAI api框架的部署自己的模型(例如vllm, TGI, litellm…)，你可以使用 <em><strong>remote:{your LLM api url}</strong></em> 來加載模型，若須指定模型名稱，使用 <em><strong>remote:{your LLM api url}@{your model name}</strong></em> 。</p>
<p>若遠端api需要api金鑰，請先完成設定環境變數 <em><strong>REMOTE_API_KEY</strong></em> ，參考<a href="/2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/">設定 API Key</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.RAG(model=&quot;remote:http://140.92.60.189:8081@llama-3.2-11B&quot;)</span><br><span class="line">ak(dir_path, prompt, )</span><br></pre></td></tr></table></figure>

</br>
</br>

<h3 id="5-gemini"><a href="#5-gemini" class="headerlink" title="5. gemini"></a>5. gemini</h3><p>(請先完成<a href="/2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/">設定 API Key</a>)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.RAG(embeddings=&quot;gemini:models/text-embedding-004&quot;,</span><br><span class="line">                model=&quot;gemini:gemini-1.5-flash&quot;)</span><br><span class="line">ak(dir_path, prompt, )</span><br></pre></td></tr></table></figure>


</br>
</br>


<h3 id="6-anthropic"><a href="#6-anthropic" class="headerlink" title="6. anthropic"></a>6. anthropic</h3><p>(請先完成<a href="/2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/">設定 API Key</a>)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ask_tool = akasha.ask(model=&quot;anthropic:claude-3-5-sonnet-20241022&quot;)</span><br><span class="line">ask_tool( prompt, info=dir_path, )</span><br></pre></td></tr></table></figure>


</br>
</br>


<h2 id="推薦一些可使用的模型"><a href="#推薦一些可使用的模型" class="headerlink" title="推薦一些可使用的模型"></a>推薦一些可使用的模型</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">openai_model = &quot;openai:gpt-3.5-turbo&quot;  # need environment variable &quot;OPENAI_API_KEY&quot;</span><br><span class="line">gemini_model=&quot;gemini:gemini-1.5-flash&quot; # need environment variable &quot;GEMINI_API_KEY&quot;</span><br><span class="line">anthropic_model = &quot;anthropic:claude-3-5-sonnet-20241022&quot; # need environment variable &quot;ANTHROPIC_API_KEY&quot;</span><br><span class="line">huggingface_model = &quot;hf:meta-llama/Llama-2-7b-chat-hf&quot; #need environment variable &quot;HUGGINGFACEHUB_API_TOKEN&quot; to download meta-llama model</span><br><span class="line">qwen_model = &quot;hf:Qwen/Qwen2.5-7B-Instruct&quot;</span><br><span class="line">quantized_ch_llama_model = &quot;hf:FlagAlpha/Llama2-Chinese-13b-Chat-4bit&quot;</span><br><span class="line">taiwan_llama_gptq = &quot;hf:weiren119/Taiwan-LLaMa-v1.0-4bits-GPTQ&quot;</span><br><span class="line">mistral = &quot;hf:Mistral-7B-Instruct-v0.2&quot; </span><br><span class="line">mediatek_Breeze = &quot;hf:MediaTek-Research/Breeze-7B-Instruct-64k-v0.1&quot;</span><br><span class="line">### If you want to use llama-cpp to run model on cpu, you can download gguf version of models </span><br><span class="line">### from https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF  and the name behind &quot;llama-cpp:&quot;</span><br><span class="line">### from https://huggingface.co/TheBloke/CodeUp-Llama-2-13B-Chat-HF-GGUF</span><br><span class="line">### is the path of the downloaded .gguf file</span><br><span class="line">llama_cpp_model = &quot;llama-cpp:model/llama-2-13b-chat-hf.Q5_K_S.gguf&quot;  </span><br><span class="line">llama_cpp_model = &quot;llama-cpp:model/llama-2-7b-chat.Q5_K_S.gguf&quot;</span><br><span class="line">llama_cpp_chinese_alpaca = &quot;llama-cpp:model/chinese-alpaca-2-7b.Q5_K_S.gguf&quot;</span><br><span class="line">llama_cpp_chinese_alpaca = &quot;llama-cpp:model/chinese-alpaca-2-13b.Q5_K_M.gguf&quot;</span><br><span class="line">chatglm_model = &quot;chatglm:THUDM/chatglm2-6b&quot;</span><br></pre></td></tr></table></figure>


</br>
</br>
</br>
</br>


<h2 id="自訂語言模型"><a href="#自訂語言模型" class="headerlink" title="自訂語言模型"></a>自訂語言模型</h2><p>如果你想使用其他模型，可以建立一個輸入是prompt的函數並回傳語言模型的回答，並將此函數作為<em><strong>model</strong></em>參數</p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><p>我們建立一個test_model函數，並可以將它作為參數輸入進RAG 或 ask物件回答問題</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">def test_model(prompt:str):</span><br><span class="line">    </span><br><span class="line">    import openai</span><br><span class="line">    from langchain.chat_models import ChatOpenAI</span><br><span class="line">    openai.api_type = &quot;open_ai&quot;</span><br><span class="line">    model = ChatOpenAI(model=&quot;gpt-3.5-turbo&quot;, temperature = 0)</span><br><span class="line">    ret = model.predict(prompt)</span><br><span class="line">    </span><br><span class="line">    return ret</span><br><span class="line"></span><br><span class="line">prompt = &quot;工業4.0是什麼?&quot;</span><br><span class="line"></span><br><span class="line">cs = akasha.ask(verbose=True, model = test_model)</span><br><span class="line">cs(prompt = prompt)</span><br></pre></td></tr></table></figure>
</br>
</br>
</br>
</br>

<h2 id="建立LLM物件"><a href="#建立LLM物件" class="headerlink" title="建立LLM物件"></a>建立LLM物件</h2><p>以上使用model參數選擇模型後，便會在Doc_QA物件內建立模型的物件model_obj(LLM)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">AK = akasha.RAG(model=&quot;openai:gpt-3.5-turbo&quot;)</span><br><span class="line"></span><br><span class="line">print(type(AK.model_obj)) </span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>


<p>也可以使用輔助函數建立LLM物件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import akasha.helper as ah</span><br><span class="line"></span><br><span class="line">model_obj = ah.handle_model(&quot;openai:gpt-3.5-turbo&quot;,verbose=False,temperature=0.0)</span><br><span class="line"></span><br><span class="line">print(type(model_obj)) </span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>

<p>此LLM物件也可直接傳入高級物件，避免重複宣告</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">import</span> akasha.helper <span class="keyword">as</span> ah</span><br><span class="line">model_obj = ah.handle_model(<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>,verbose=<span class="literal">False</span>,temperature=<span class="number">0.0</span>)</span><br><span class="line"></span><br><span class="line">AK = akasha.ask(model=model_obj) </span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="直接使用LLM物件"><a href="#直接使用LLM物件" class="headerlink" title="直接使用LLM物件"></a>直接使用LLM物件</h2><h3 id="取得模型類別"><a href="#取得模型類別" class="headerlink" title="取得模型類別"></a>取得模型類別</h3><p>使用_llm_type()可取得語言模型的類別</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> akasha.helper <span class="keyword">as</span> ah</span><br><span class="line">model_obj = ah.handle_model(<span class="string">&quot;gemini:gemini-1.5-flash&quot;</span>,verbose=<span class="literal">False</span>,temperature=<span class="number">0.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model_obj._llm_type()) <span class="comment">## &quot;gemini:gemini-1.5-flash&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="模型推論"><a href="#模型推論" class="headerlink" title="模型推論"></a>模型推論</h3><p>若要使用語言模型進行推論，可以使用函式call_model</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha.helper <span class="keyword">as</span> ah</span><br><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">from</span> akasha.utils.prompts.gen_prompt <span class="keyword">import</span> format_sys_prompt</span><br><span class="line">system_prompt = <span class="string">&quot;用中文回答&quot;</span></span><br><span class="line">prompt = <span class="string">&quot;五軸是什麼?&quot;</span></span><br><span class="line">model_obj = ah.handle_model(<span class="string">&quot;openai:gpt-e3.5-turbo&quot;</span>, <span class="literal">False</span>, <span class="number">0.0</span>)</span><br><span class="line">input_text = format_sys_prompt(system_prompt, prompt, <span class="string">&quot;gpt&quot;</span>)</span><br><span class="line"></span><br><span class="line">response = akasha.call_model(model_obj, input_text)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>


<h3 id="流輸出"><a href="#流輸出" class="headerlink" title="流輸出"></a>流輸出</h3><p>若要呼叫語言模型即時回答，可以使用函式call_stream_model</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha.helper <span class="keyword">as</span> ah</span><br><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">from</span> akasha.utils.prompts.gen_prompt <span class="keyword">import</span> format_sys_prompt</span><br><span class="line"></span><br><span class="line">system_prompt = <span class="string">&quot;用中文回答&quot;</span></span><br><span class="line">prompt = <span class="string">&quot;五軸是什麼?&quot;</span></span><br><span class="line">model_obj = ah.handle_model(<span class="string">&quot;openai:gpt-e3.5-turbo&quot;</span>, <span class="literal">False</span>, <span class="number">0.0</span>)</span><br><span class="line">input_text = format_sys_prompt(system_prompt, prompt, <span class="string">&quot;gpt&quot;</span>)</span><br><span class="line"></span><br><span class="line">streaming = akasha.call_stream_model(model_obj, input_text)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> streaming:</span><br><span class="line">    <span class="built_in">print</span>(s)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>


<h3 id="批量推論"><a href="#批量推論" class="headerlink" title="批量推論"></a>批量推論</h3><p>如果你有大量不需要連貫的推理需求，可以使用<strong>akasha.helper.call_batch_model</strong> 來進行批量推理來提升速度。</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def call_batch_model(model: LLM, prompt: List[str], </span><br><span class="line">    system_prompt: Union[List[str], str] = &quot;&quot;) -&gt; List[str]:</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">import</span> akasha.helper <span class="keyword">as</span> ah</span><br><span class="line">model_obj = ah.handle_model(<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>, <span class="literal">False</span>, <span class="number">0.0</span>)</span><br><span class="line"><span class="comment"># this prompt ask LLM to response &#x27;yes&#x27; or &#x27;no&#x27; if the document segment is relevant to the user question or not.</span></span><br><span class="line">SYSTEM_PROMPT = <span class="string">&quot;response only &#x27;yes&#x27; or &#x27;no&#x27;, &#x27;yes&#x27; if the document segment is relevant to the user question, &#x27;no&#x27; for not.&quot;</span></span><br><span class="line">documents = [<span class="string">&quot;Doc1...&quot;</span>, <span class="string">&quot;Doc2...&quot;</span>, <span class="string">&quot;Doc3...&quot;</span>, <span class="string">&quot;Doc4...&quot;</span>]</span><br><span class="line">question = <span class="string">&quot;五軸是什麼?&quot;</span></span><br><span class="line"></span><br><span class="line">prompts = [<span class="string">&quot;document: &quot;</span> + doc +<span class="string">&quot;\n\n&quot;</span> + <span class="string">&quot;User Question: &quot;</span>+ question <span class="keyword">for</span> doc <span class="keyword">in</span> documents]</span><br><span class="line"></span><br><span class="line">response_list = call_batch_model(model_obj, prompt, SYSTEM_PROMPT)</span><br><span class="line"></span><br><span class="line"><span class="comment">## [&quot;yes&quot;, &quot;no&quot;, &quot;yes&quot;, &quot;yes&quot;]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">設定嵌入模型</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-30 20:59:59" itemprop="dateCreated datePublished" datetime="2024-12-30T20:59:59+08:00">2024-12-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2025-04-14 16:24:50" itemprop="dateModified" datetime="2025-04-14T16:24:50+08:00">2025-04-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E5%AE%89%E8%A3%9D-%E8%A8%AD%E5%AE%9A/" itemprop="url" rel="index"><span itemprop="name">安裝&設定</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="選擇不同嵌入模型"><a href="#選擇不同嵌入模型" class="headerlink" title="選擇不同嵌入模型"></a>選擇不同嵌入模型</h2><p>使用參數<em><strong>embeddings</strong></em>便可以選擇不同的嵌入模型，預設是<em><strong>openai:text-embedding-ada-002</strong></em>.</p>
<h2 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h2><h3 id="1-openai"><a href="#1-openai" class="headerlink" title="1. openai"></a>1. openai</h3><p>(請先完成<a href="/2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/">設定 API Key</a>)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">akasha.RAG( embeddings=&quot;openai:text-embedding-ada-002&quot;)</span><br><span class="line">ak(dir_path, prompt)</span><br></pre></td></tr></table></figure>

</br>
</br>

<h3 id="2-huggingface"><a href="#2-huggingface" class="headerlink" title="2. huggingface"></a>2. huggingface</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">akasha.RAG( embeddings=&quot;huggingface:all-MiniLM-L6-v2&quot;)</span><br><span class="line">ak(dir_path, prompt)</span><br></pre></td></tr></table></figure>
</br>
</br>

<h3 id="3-gemini"><a href="#3-gemini" class="headerlink" title="3. gemini"></a>3. gemini</h3><p>(請先完成<a href="/2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/">設定 API Key</a>)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">akasha.RAG( embeddings=&quot;gemini:models/text-embedding-004&quot;,</span><br><span class="line">                model=&quot;gemini:gemini-1.5-flash&quot;)</span><br><span class="line">ak(dir_path, prompt)</span><br></pre></td></tr></table></figure>


</br>
</br>

<h2 id="推薦一些可使用的模型"><a href="#推薦一些可使用的模型" class="headerlink" title="推薦一些可使用的模型"></a>推薦一些可使用的模型</h2><p>每個嵌入模型都有max sequence length，超過的話後面的文字就會被截斷，不會拿進去做嵌入。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">openai_emb = &quot;openai:text-embedding-ada-002&quot;  # need environment variable &quot;OPENAI_API_KEY&quot;  # 8192 max seq length</span><br><span class="line">openai_3l_emb = &quot;openai:text-embedding-3-large&quot;</span><br><span class="line">openai_3s_emb = &quot;openai:text-embedding-3-small&quot;</span><br><span class="line">gemini_emb = &quot;gemini:models/text-embedding-004&quot;</span><br><span class="line">huggingface_emb = &quot;hf:all-MiniLM-L6-v2&quot; </span><br><span class="line">alibaba_bge_emb = &quot;hf:Alibaba-NLP/gte-multilingual-base&quot; #8192 max seq length</span><br><span class="line">bge_en_emb = &quot;hf:BAAI/bge-base-en-v1.5&quot;  # 512 max seq length</span><br><span class="line">bge_ch_emb = &quot;hf:BAAI/bge-base-zh-v1.5&quot;  # 512 max seq length</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>
</br>
</br>


<h2 id="自訂嵌入模型"><a href="#自訂嵌入模型" class="headerlink" title="自訂嵌入模型"></a>自訂嵌入模型</h2><p>如果你想使用其他模型，可以建立一個輸入是<em><strong>texts:list</strong></em>的函數，代表的是文件庫中所有分割好的文字段落，此函數需回傳embedding之後每段文字的向量，並將此函數作為<em><strong>embeddings</strong></em>參數</p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><p>我們建立一個test_embed函數，並可以將它作為參數輸入進get_response回答問題</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">def test_embed(texts:list)-&gt;list:</span><br><span class="line"></span><br><span class="line">    from sentence_transformers import SentenceTransformer</span><br><span class="line">    mdl = SentenceTransformer(&#x27;BAAI/bge-large-zh-v1.5&#x27;)</span><br><span class="line">    embeds =  mdl.encode(texts,normalize_embeddings=True)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    return embeds</span><br><span class="line"></span><br><span class="line">doc_source = [&quot;./mic/&quot;]</span><br><span class="line">prompt = &quot;五軸是什麼?&quot;</span><br><span class="line"></span><br><span class="line">qa = akasha.RAG(verbose=True, search_type = &quot;svm&quot;, embeddings = test_embed)</span><br><span class="line">qa(doc_source= doc_path, prompt = prompt)</span><br></pre></td></tr></table></figure>


<h2 id="建立Embeddings物件"><a href="#建立Embeddings物件" class="headerlink" title="建立Embeddings物件"></a>建立Embeddings物件</h2><p>以上使用embeddings參數選擇模型後，便會在Doc_QA物件內建立模型的物件embeddings_obj(Embeddings)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">AK = akasha.RAG(embeddings=&quot;openai:text-embedding-ada-002&quot;)</span><br><span class="line"></span><br><span class="line">print(type(AK.embeddings_obj)) </span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>


<p>也可以使用輔助函數建立Embeddings物件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line">import akasha.helper as ah</span><br><span class="line">embeddings_obj = ah.handle_embeddings(&quot;openai:text-embedding-ada-002&quot;,verbose=False)</span><br><span class="line"></span><br><span class="line">print(type(embeddings_obj)) </span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>

<p>此Embeddings物件也可直接傳入高級物件，避免重複宣告</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">import</span> akasha.helper <span class="keyword">as</span> ah</span><br><span class="line">model_obj = ah.handle_model(<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>,verbose=<span class="literal">False</span>,temperature=<span class="number">0.0</span>)</span><br><span class="line">embeddings_obj = ah.handle_embeddings(<span class="string">&quot;openai:text-embedding-ada-002&quot;</span>,verbose=<span class="literal">False</span>)</span><br><span class="line">AK = akasha.RAG(model=model_obj, embeddings=embeddings_obj) </span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>

<h2 id="直接使用Embeddings物件"><a href="#直接使用Embeddings物件" class="headerlink" title="直接使用Embeddings物件"></a>直接使用Embeddings物件</h2><h3 id="embed-documents"><a href="#embed-documents" class="headerlink" title="embed_documents"></a>embed_documents</h3><p>創建完Embeddings物件後，可以直接使用來得到文件片段的向量資料(list[list[float]])</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">import</span> akasha.helper <span class="keyword">as</span> ah</span><br><span class="line">text_list = [<span class="string">&quot;範例文件內容1&quot;</span>, <span class="string">&quot;範例文件內容2&quot;</span>, <span class="string">&quot;範例文件內容3&quot;</span>]</span><br><span class="line">embeddings_obj = ah.handle_embeddings(<span class="string">&quot;openai:text-embedding-ada-002&quot;</span>,verbose=<span class="literal">False</span>)</span><br><span class="line">vectors = embeddings_obj.embed_documents(text_list)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(vectors) <span class="comment"># [[-0.004720511846244335, -2.9706923214689596e-06, -0.013798418454825878,...], [-0.004720511846244335, -2.9706923214689596e-06, -0.013798418454825878,...], [-0.004720511846244335, -2.9706923214689596e-06, -0.013798418454825878,...]]</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/29/RAG/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/29/RAG/" class="post-title-link" itemprop="url">RAG</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-29 23:59:59" itemprop="dateCreated datePublished" datetime="2024-12-29T23:59:59+08:00">2024-12-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2025-04-21 14:48:59" itemprop="dateModified" datetime="2025-04-21T14:48:59+08:00">2025-04-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E5%8A%9F%E8%83%BD/" itemprop="url" rel="index"><span itemprop="name">功能</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="RAG"><a href="#RAG" class="headerlink" title="RAG"></a>RAG</h2><p>使用者可輸入一個或多個文件(.pdf, .docx, .md, .txt, .csv, .pptx)、資料夾、或網址，RAG將藉由嵌入模型將文件儲存成向量資料庫(儲存在&#x2F;chromadb中)<br>此函數可以讓語言模型根據搜尋到的文件回答問題。藉由使用者的問題和文件庫搜尋到知識片段，可以不用將整份文件輸入給模型，就讓語言模型正確回答問題。</p>
<h3 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h3><p>宣告一個RAG的物件，可設定語言模型、嵌入模型、文本長度上限等參數。<br>使用 <em><strong>data_source</strong></em> 指定需要參考的文件資料，並建成向量資料庫(若已建立則直接讀取)，根據prompt回答問題<br>詢問完問題後，若有keep_logs參數，可選擇儲存成json檔案，也可使用reference()取得回答問題所使用的文件名稱、頁數(dict)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.RAG(</span><br><span class="line">    embeddings=&quot;openai:text-embedding-3-small&quot;,</span><br><span class="line">    model=&quot;openai:gpt-4o&quot;,</span><br><span class="line">    max_input_tokens=3000,</span><br><span class="line">    keep_logs=True,</span><br><span class="line">    verbose=True,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">res = ak(</span><br><span class="line">    data_source=[&quot;docs/mic&quot;, &quot;https://github.com/iii-org/akasha&quot;],</span><br><span class="line">    prompt=&quot;akasha是甚麼?&quot;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">## optional</span><br><span class="line">ref = ak.reference() #&#123;&quot;1.pdf&quot;:2,3,4&#125;</span><br><span class="line"></span><br><span class="line">ak.save_logs(&quot;logs.json&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="RAG-參數"><a href="#RAG-參數" class="headerlink" title="RAG 參數"></a>RAG 參數</h3><h5 id="verbose-bool-如果設True，會顯示每個步驟產生的文字和狀態"><a href="#verbose-bool-如果設True，會顯示每個步驟產生的文字和狀態" class="headerlink" title="verbose: bool 如果設True，會顯示每個步驟產生的文字和狀態"></a>verbose: bool 如果設True，會顯示每個步驟產生的文字和狀態</h5><h5 id="search-type-Union-str-Callable-用來搜尋文件段落的方法，可選擇-auto-svm-tfidf-bm25-mmr-knn"><a href="#search-type-Union-str-Callable-用來搜尋文件段落的方法，可選擇-auto-svm-tfidf-bm25-mmr-knn" class="headerlink" title="search_type: Union[str, Callable] 用來搜尋文件段落的方法，可選擇: auto, svm, tfidf, bm25, mmr, knn."></a>search_type: Union[str, Callable] 用來搜尋文件段落的方法，可選擇: <em><strong>auto</strong></em>, <em><strong>svm</strong></em>, <em><strong>tfidf</strong></em>, <em><strong>bm25</strong></em>, <em><strong>mmr</strong></em>, <em><strong>knn</strong></em>.</h5><h5 id="model-Union-str-BaseLanguageModel-使用的語言模型，如-openai-gpt-3-5-turbo-hf-meta-llama-Llama-2-13b-chat-hf"><a href="#model-Union-str-BaseLanguageModel-使用的語言模型，如-openai-gpt-3-5-turbo-hf-meta-llama-Llama-2-13b-chat-hf" class="headerlink" title="model: Union[str, BaseLanguageModel] 使用的語言模型，如 openai:gpt-3.5-turbo, hf:meta-llama&#x2F;Llama-2-13b-chat-hf"></a>model: Union[str, BaseLanguageModel] 使用的語言模型，如 <em><strong>openai:gpt-3.5-turbo</strong></em>, <em><strong>hf:meta-llama&#x2F;Llama-2-13b-chat-hf</strong></em></h5><h5 id="embeddings-Union-str-Embeddings"><a href="#embeddings-Union-str-Embeddings" class="headerlink" title="embeddings: Union[str, Embeddings]"></a>embeddings: Union[str, Embeddings]</h5><h5 id="max-input-tokens-int-最長可允許的文件總token長度"><a href="#max-input-tokens-int-最長可允許的文件總token長度" class="headerlink" title="max_input_tokens: int 最長可允許的文件總token長度"></a>max_input_tokens: int 最長可允許的文件總token長度</h5><h5 id="chunk-size-int-單個文件段落的長度"><a href="#chunk-size-int-單個文件段落的長度" class="headerlink" title="chunk_size: int 單個文件段落的長度"></a>chunk_size: int 單個文件段落的長度</h5><h5 id="temperature-float-語言模型的變化度-0-1"><a href="#temperature-float-語言模型的變化度-0-1" class="headerlink" title="temperature: float 語言模型的變化度(0~1)"></a>temperature: float 語言模型的變化度(0~1)</h5><h5 id="system-prompt-str-指示給語言模型的output格式需求"><a href="#system-prompt-str-指示給語言模型的output格式需求" class="headerlink" title="system_prompt: str 指示給語言模型的output格式需求"></a>system_prompt: str 指示給語言模型的output格式需求</h5><h4 id="stream-bool-如果設為True，會回傳generator"><a href="#stream-bool-如果設為True，會回傳generator" class="headerlink" title="stream: bool 如果設為True，會回傳generator"></a>stream: bool 如果設為True，會回傳generator</h4><h4 id="max-input-tokens-int-單次輸入模型的最大token數"><a href="#max-input-tokens-int-單次輸入模型的最大token數" class="headerlink" title="max_input_tokens: int 單次輸入模型的最大token數"></a>max_input_tokens: int 單次輸入模型的最大token數</h4><h4 id="max-output-tokens-int-模型輸出的最大token數"><a href="#max-output-tokens-int-模型輸出的最大token數" class="headerlink" title="max_output_tokens: int 模型輸出的最大token數"></a>max_output_tokens: int 模型輸出的最大token數</h4><h4 id="env-file-str-指定-env環境設定檔名"><a href="#env-file-str-指定-env環境設定檔名" class="headerlink" title="env_file:str  指定.env環境設定檔名"></a>env_file:str  指定.env環境設定檔名</h4><h4 id="keep-logs-bool-是否保存執行過程和結果"><a href="#keep-logs-bool-是否保存執行過程和結果" class="headerlink" title="keep_logs: bool 是否保存執行過程和結果"></a>keep_logs: bool 是否保存執行過程和結果</h4><h3 id="call-參數"><a href="#call-參數" class="headerlink" title="call 參數"></a><strong>call</strong> 參數</h3><h5 id="doc-source-Union-List-Union-str-Path-Path-str-dbs-一個或多個包含文件檔案的資料夾路徑名稱、網址，或單一個dbs物件"><a href="#doc-source-Union-List-Union-str-Path-Path-str-dbs-一個或多個包含文件檔案的資料夾路徑名稱、網址，或單一個dbs物件" class="headerlink" title="doc_source: Union[List[Union[str, Path]], Path, str, dbs] 一個或多個包含文件檔案的資料夾路徑名稱、網址，或單一個dbs物件"></a>doc_source: Union[List[Union[str, Path]], Path, str, dbs] 一個或多個包含文件檔案的資料夾路徑名稱、網址，或單一個dbs物件</h5><h5 id="prompt-str-使用者的問題"><a href="#prompt-str-使用者的問題" class="headerlink" title="prompt: str 使用者的問題"></a>prompt: str 使用者的問題</h5><h4 id="history-messages-List-str-需要一併提供給語言模型的對話紀錄"><a href="#history-messages-List-str-需要一併提供給語言模型的對話紀錄" class="headerlink" title="history_messages: List[str] 需要一併提供給語言模型的對話紀錄"></a>history_messages: List[str] 需要一併提供給語言模型的對話紀錄</h4><h3 id="stream輸出"><a href="#stream輸出" class="headerlink" title="stream輸出"></a>stream輸出</h3><p>若需要即時輸出的場合(如UI即時顯示回答)，使用stream&#x3D;True可使RAG回傳generator。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.RAG(</span><br><span class="line">    embeddings=&quot;openai:text-embedding-3-small&quot;,</span><br><span class="line">    model=&quot;openai:gpt-4o&quot;,</span><br><span class="line">    max_input_tokens=3000,</span><br><span class="line">    keep_logs=True,</span><br><span class="line">    verbose=True,</span><br><span class="line">    stream=True</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">streaming = ak(</span><br><span class="line">    data_source=[&quot;docs/mic&quot;, &quot;https://github.com/iii-org/akasha&quot;],</span><br><span class="line">    prompt=&quot;akasha是甚麼?&quot;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">for s in streaming:</span><br><span class="line">    print(s)</span><br></pre></td></tr></table></figure>


<h2 id="dbs物件"><a href="#dbs物件" class="headerlink" title="dbs物件"></a>dbs物件</h2><p>如想對同個文件集做多次問答，可以先建立dbs物件並傳入，避免多次重複載入文件的chromadb，若文件內容、使用嵌入模型、chunk size相等的chromadb已存在，則不會重新創建而直接讀取。</p>
<p>創建chromadb可使用 <em><strong>process_db</strong></em></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line">import akasha.utils.db as adb</span><br><span class="line">db_files = adb.process_db(data_source = [&quot;docs/mic&quot;], embeddings=&quot;openai:text-embedding-ada-002&quot;,chunk_size=500)</span><br><span class="line"></span><br><span class="line">qa = akasha.RAG(</span><br><span class="line">    verbose=True, </span><br><span class="line">    search_type=&quot;knn&quot;,</span><br><span class="line">    embeddings=&quot;openai:text-embedding-ada-002&quot;,</span><br><span class="line">    chunk_size=500, </span><br><span class="line">    model=&quot;openai:gpt-3.5-turbo&quot;, </span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">qa(</span><br><span class="line">    doc_path=db_files,</span><br><span class="line">    prompt=&quot;五軸是甚麼?&quot;,</span><br><span class="line">    system_prompt=&quot;請用中文回答&quot;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


</br>
</br>


<h2 id="RAG-輸出"><a href="#RAG-輸出" class="headerlink" title="RAG 輸出"></a>RAG 輸出</h2><p>使用完RAG的函式後，物件內部會儲存用來搜尋的db(self.db)、讓語言模型參考的文件(self.docs)、使用者的問題(self.prompt)和回答(self.response)等資訊，若需要更完整的資訊可參考<a href="/2024/12/26/%E8%BC%94%E5%8A%A9%E5%87%BD%E6%95%B8/">輔助函數</a>中的 <em><strong>儲存紀錄</strong></em></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.RAG(</span><br><span class="line">    embeddings=&quot;openai:text-embedding-3-small&quot;,</span><br><span class="line">    model=&quot;openai:gpt-4o&quot;,</span><br><span class="line">    max_input_tokens=3000,</span><br><span class="line">    keep_logs=True,</span><br><span class="line">    verbose=True,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">response = ak(</span><br><span class="line">    data_source=[&quot;docs/mic&quot;, &quot;https://github.com/iii-org/akasha&quot;],</span><br><span class="line">    prompt=&quot;akasha是甚麼?&quot;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">## self.db (dbs class) ##</span><br><span class="line">print(len(ak.db.ids), ak.db.metadatas[0])</span><br><span class="line"></span><br><span class="line">## self.docs (list of Documents) ##</span><br><span class="line">print(ak.docs[0])</span><br><span class="line"></span><br><span class="line">## self.doc_tokens (integer, length of document tokens) ##</span><br><span class="line">print(ak.prompt_tokens, ak.doc_tokens)</span><br><span class="line"></span><br><span class="line">print(ak.prompt, ak.response)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>

<h2 id="selfask-RAG"><a href="#selfask-RAG" class="headerlink" title="selfask_RAG"></a>selfask_RAG</h2><p>selfask_RAG會先將使用者問題嘗試使用語言模型進行拆分，再進行RAG回答問題，對於需要多個知識點的問題可能會獲得較好的結果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import akasha</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ak = akasha.RAG(</span><br><span class="line">    embeddings=&quot;openai:text-embedding-3-small&quot;,</span><br><span class="line">    model=&quot;openai:gpt-4o&quot;,</span><br><span class="line">    max_input_tokens=DEFAULT_MAX_INPUT_TOKENS,</span><br><span class="line">    keep_logs=True,</span><br><span class="line">    verbose=True,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">res = ak.selfask_RAG(data_source=[&quot;docs/mic&quot;],</span><br><span class="line">    prompt=&quot;LPWAN和5G的區別是什麼?&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="self-db的詳細資訊可參考向量資料庫"><a href="#self-db的詳細資訊可參考向量資料庫" class="headerlink" title="self.db的詳細資訊可參考向量資料庫"></a>self.db的詳細資訊可參考<a href="/2024/12/26/%E5%90%91%E9%87%8F%E8%B3%87%E6%96%99%E5%BA%AB/">向量資料庫</a></h2><h3 id="self-docs的詳細資訊可參考文件搜尋"><a href="#self-docs的詳細資訊可參考文件搜尋" class="headerlink" title="self.docs的詳細資訊可參考文件搜尋"></a>self.docs的詳細資訊可參考<a href="/2024/12/26/%E6%96%87%E4%BB%B6%E6%90%9C%E5%B0%8B/">文件搜尋</a></h3><h3 id="self-model-obj的詳細資訊可參考設定語言模型"><a href="#self-model-obj的詳細資訊可參考設定語言模型" class="headerlink" title="self.model_obj的詳細資訊可參考設定語言模型"></a>self.model_obj的詳細資訊可參考<a href="/2024/12/30/%E8%A8%AD%E5%AE%9A%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B/">設定語言模型</a></h3><h3 id="self-embeddings-obj的詳細資訊可參考設定嵌入模型"><a href="#self-embeddings-obj的詳細資訊可參考設定嵌入模型" class="headerlink" title="self.embeddings_obj的詳細資訊可參考設定嵌入模型"></a>self.embeddings_obj的詳細資訊可參考<a href="/2024/12/30/%E8%A8%AD%E5%AE%9A%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/">設定嵌入模型</a></h3>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/29/ask_whole_file/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/29/ask_whole_file/" class="post-title-link" itemprop="url">ask_whole_file</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-29 21:30:59" itemprop="dateCreated datePublished" datetime="2024-12-29T21:30:59+08:00">2024-12-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2024-11-13 16:00:58" itemprop="dateModified" datetime="2024-11-13T16:00:58+08:00">2024-11-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E6%96%87%E6%AA%94%E5%95%8F%E7%AD%94/" itemprop="url" rel="index"><span itemprop="name">文檔問答</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="ask-whole-file"><a href="#ask-whole-file" class="headerlink" title="ask_whole_file"></a>ask_whole_file</h2><p>如果你想詢問單個檔案的內容，你可以使用ask_whole_file將整個文件的內容給語言模型做為參考。</p>
<p>若檔案中的總文字內容過多，文件內容會被分別提供給語言模型作回答，並最終整合成一個最終回答，因此可能會花費較久時間。</p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.Doc_QA(</span><br><span class="line">    search_type=&quot;merge&quot;,</span><br><span class="line">    verbose=True,</span><br><span class="line">    max_input_tokens=30000,</span><br><span class="line">    model=&quot;openai:gpt-4-32k&quot;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">response = ak.ask_whole_file(system_prompt=&quot;用列舉的方式描述&quot;,</span><br><span class="line">    file_path=&quot;docs/mic/20230726_工業4_0發展重點與案例分析，以西門子、鴻海為例.pdf&quot;,</span><br><span class="line">    prompt=&quot;工業4.0有什麼可以參考的標準或是架構嗎?&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">工業4.0的參考標準或架構主要有以下幾種：</span><br><span class="line"></span><br><span class="line">1. 「工業 4.0成熟度指數」：由德國國家工程院（Acatech）提出，將發展階段劃分為電腦化、可連結、可視化、可分析、可預測、自適應共六個成熟度，前項為後項發展基礎。</span><br><span class="line"></span><br><span class="line">2. 「新加坡工業智慧指數」（Singapore Smart Industry Readiness Index, SIRI）：由新加坡政府提出，用於評估企業在工業4.0的發展程度。</span><br><span class="line"></span><br><span class="line">3. 「工業 4.0實施步驟方法論」：這是一種實施工業4.0的具體步驟，包括盤點公司內部待改善問題，分析現況與預期目標差異，以及規劃具體要改善的業務流程路線圖。</span><br></pre></td></tr></table></figure>


<h5 id="self-docs的詳細資訊可參考文件搜尋"><a href="#self-docs的詳細資訊可參考文件搜尋" class="headerlink" title="self.docs的詳細資訊可參考文件搜尋"></a>self.docs的詳細資訊可參考<a href="/2024/12/26/%E6%96%87%E4%BB%B6%E6%90%9C%E5%B0%8B/">文件搜尋</a></h5><h5 id="self-model-obj的詳細資訊可參考語言模型"><a href="#self-model-obj的詳細資訊可參考語言模型" class="headerlink" title="self.model_obj的詳細資訊可參考語言模型"></a>self.model_obj的詳細資訊可參考<a href="/2024/12/26/%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B/">語言模型</a></h5>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/29/ask_image/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/29/ask_image/" class="post-title-link" itemprop="url">ask_image</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-29 20:59:59" itemprop="dateCreated datePublished" datetime="2024-12-29T20:59:59+08:00">2024-12-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2024-11-13 16:02:12" itemprop="dateModified" datetime="2024-11-13T16:02:12+08:00">2024-11-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E6%96%87%E6%AA%94%E5%95%8F%E7%AD%94/" itemprop="url" rel="index"><span itemprop="name">文檔問答</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="ask-image"><a href="#ask-image" class="headerlink" title="ask_image"></a>ask_image</h2><p>如果你想同時輸入圖片與文字來詢問多模態模型(如gpt-4o, llama3.2-Vision)，可以使用ask_image，圖片路徑image_path可以是網址或本地圖片路徑，模型類別目前支援 <em><strong>openai</strong></em>, <em><strong>remote</strong></em>(vllm), <em><strong>huggingface</strong></em>(llama3.2-Vision), <em><strong>anthropic</strong></em>(claude-3-5-sonnet-20241022) ，但huggingface目前不支援stream流輸出。</p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ak = akasha.Doc_QA(model=<span class="string">&quot;openai:gpt-4o&quot;</span>,)</span><br><span class="line">url = <span class="string">&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg&quot;</span></span><br><span class="line">png = <span class="string">&quot;../miao.png&quot;</span></span><br><span class="line"></span><br><span class="line">res = ak.ask_image(image_path=url, prompt = <span class="string">&quot;這張圖片是甚麼?&quot;</span>) </span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">這張圖片顯示了一個長度不等的木板路，穿過一片綠色的草地和樹林。路面上有許多細小的草根和葉子。路面兩側是高約1米左右的青綠色野生植物，中間有一些紅色的灌木丛。天空是藍色的，有一</span><br><span class="line">些白雲。</span><br><span class="line"></span><br><span class="line">這張圖像可能是一個自然景觀或一個旅遊目的地，例如一個國家公園或一個鳥類保護區。它也可能是一個攝影作品，用來展示自然美景和人們與環境之間的互動關係。</span><br><span class="line"></span><br><span class="line">總體而言，這張圖像展現了人們與自然環境之間美麗而微妙的關係，並呼籲我們去探索、欣賞和保護我們周圍的世界。這張圖片顯示了一個長度不等的木板路，穿過一片綠色的草地和樹林。路面上有許多細小的草根和葉子。路面兩側是高約1米左右的青綠色野生植物，中間有一些紅色的灌木叢。天空是藍色的，有一些白雲。</span><br><span class="line"></span><br><span class="line">這張圖像可能是一個自然景觀或一個旅遊目的地，例如一個國家公園或一個鳥類保護區。它也可能是一個攝影作品，用來展示自然美景和人們與環境之間的互動關係。</span><br><span class="line"></span><br><span class="line">總體而言，這張圖像展現了人們與自然環境之間美麗而微妙的關係，並呼籲我們去探索、欣賞和保護我們周圍的世界。</span><br></pre></td></tr></table></figure>



<h5 id="self-model-obj的詳細資訊可參考語言模型"><a href="#self-model-obj的詳細資訊可參考語言模型" class="headerlink" title="self.model_obj的詳細資訊可參考語言模型"></a>self.model_obj的詳細資訊可參考<a href="/2024/12/26/%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B/">語言模型</a></h5>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/29/ask_self/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/29/ask_self/" class="post-title-link" itemprop="url">ask_self</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-29 20:59:59" itemprop="dateCreated datePublished" datetime="2024-12-29T20:59:59+08:00">2024-12-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2024-11-13 16:00:50" itemprop="dateModified" datetime="2024-11-13T16:00:50+08:00">2024-11-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E6%96%87%E6%AA%94%E5%95%8F%E7%AD%94/" itemprop="url" rel="index"><span itemprop="name">文檔問答</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="ask-self"><a href="#ask-self" class="headerlink" title="ask_self"></a>ask_self</h2><p>如果你不想使用文件檔案，希望直接輸入文件內容，你可以使用ask_self，使用 <em><strong>info</strong></em> 參數將文件的內容傳給語言模型，<em><strong>info</strong></em>參數可為<em><strong>str</strong></em> 或者 <em><strong>list of str</strong></em>。<br>若 <em><strong>info</strong></em>中的單一字串長度大於語言模型上限，該字串會被自行切割成 <em><strong>list of str</strong></em>，因此建議若文字過多，請自行分段成 <em><strong>list of str</strong></em></p>
<p>若 <em><strong>info</strong></em>中的總文字內容過多，文件內容會被分別提供給語言模型作回答，並最終整合成一個最終回答，因此可能會花費較久時間。</p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">install_requires = [</span><br><span class="line">    &quot;pypdf&quot;,</span><br><span class="line">    &quot;langchain&gt;=0.1.0&quot;,</span><br><span class="line">    &quot;chromadb==0.4.14&quot;,</span><br><span class="line">    &quot;openai==0.27&quot;,</span><br><span class="line">    &quot;tiktoken&quot;,</span><br><span class="line">    &quot;lark==1.1.7&quot;,</span><br><span class="line">    &quot;scikit-learn&lt;1.3.0&quot;,</span><br><span class="line">    &quot;jieba==0.42.1&quot;,</span><br><span class="line">    &quot;sentence-transformers==2.2.2&quot;,</span><br><span class="line">    &quot;torch==2.0.1&quot;,</span><br><span class="line">    &quot;transformers&gt;=4.33.4&quot;, </span><br><span class="line">    &quot;llama-cpp-python==0.2.6&quot;,</span><br><span class="line">    &quot;auto-gptq==0.3.1&quot;,</span><br><span class="line">    &quot;tqdm==4.65.0&quot;,</span><br><span class="line">    &quot;docx2txt==0.8&quot;,</span><br><span class="line">    &quot;rouge==1.0.1&quot;,</span><br><span class="line">    &quot;rouge-chinese==1.0.3&quot;,</span><br><span class="line">    &quot;bert-score==0.3.13&quot;,</span><br><span class="line">    &quot;click&quot;,</span><br><span class="line">    &quot;tokenizers&gt;=0.13.3&quot;,</span><br><span class="line">    &quot;streamlit==1.28.2&quot;,</span><br><span class="line">    &quot;streamlit_option_menu==0.3.6&quot;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">ak = akasha.Doc_QA(</span><br><span class="line">    verbose=True,</span><br><span class="line">    max_input_tokens=30000,</span><br><span class="line">    model=&quot;openai:gpt-4&quot;,</span><br><span class="line">)</span><br><span class="line">response = ak.ask_self(prompt=&quot;langchain的套件版本?&quot;, info=install_requires)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">langchain的套件版本是0.1.0或更高版本。</span><br></pre></td></tr></table></figure>

<h5 id="self-docs的詳細資訊可參考文件搜尋"><a href="#self-docs的詳細資訊可參考文件搜尋" class="headerlink" title="self.docs的詳細資訊可參考文件搜尋"></a>self.docs的詳細資訊可參考<a href="/2024/12/26/%E6%96%87%E4%BB%B6%E6%90%9C%E5%B0%8B/">文件搜尋</a></h5><h5 id="self-model-obj的詳細資訊可參考語言模型"><a href="#self-model-obj的詳細資訊可參考語言模型" class="headerlink" title="self.model_obj的詳細資訊可參考語言模型"></a>self.model_obj的詳細資訊可參考<a href="/2024/12/26/%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B/">語言模型</a></h5>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/akasha/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/akasha/page/4/">4</a><a class="extend next" rel="next" href="/akasha/page/2/"><i class="fa fa-angle-right" aria-label="下一頁"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Chih Chuan Chang<ccchang@iii.org.tw></p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/akasha/archives/">
        
          <span class="site-state-item-count">34</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">分類</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">標籤</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chih Chuan Chang<ccchang@iii.org.tw></span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 強力驅動
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/akasha/lib/anime.min.js"></script>
  <script src="/akasha/lib/velocity/velocity.min.js"></script>
  <script src="/akasha/lib/velocity/velocity.ui.min.js"></script>

<script src="/akasha/js/utils.js"></script>

<script src="/akasha/js/motion.js"></script>


<script src="/akasha/js/schemes/muse.js"></script>


<script src="/akasha/js/next-boot.js"></script>




  















  

  

</body>
</html>
