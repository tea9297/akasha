<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/akasha/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/akasha/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/akasha/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/akasha/images/logo.svg" color="#222">

<link rel="stylesheet" href="/akasha/css/main.css">


<link rel="stylesheet" href="/akasha/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"tea9297.github.io","root":"/akasha/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="akasha 0.9 使用手冊">
<meta property="og:url" content="https://tea9297.github.io/akasha/index.html">
<meta property="og:site_name" content="akasha 0.9 使用手冊">
<meta property="og:locale" content="zh_TW">
<meta property="article:author" content="Chih Chuan Chang&lt;ccchang@iii.org.tw&gt;">
<meta property="article:tag" content="akasha, manual, llm, rag">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://tea9297.github.io/akasha/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-TW'
  };
</script>

  <title>akasha 0.9 使用手冊</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/akasha/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">akasha 0.9 使用手冊</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">akasha 0.9 manual</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/akasha/" rel="section"><i class="fa fa-home fa-fw"></i>首頁</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/akasha/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>歸檔</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/31/%E7%9B%AE%E9%8C%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/31/%E7%9B%AE%E9%8C%84/" class="post-title-link" itemprop="url">目錄</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-31 23:59:59" itemprop="dateCreated datePublished" datetime="2024-12-31T23:59:59+08:00">2024-12-31</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2025-05-26 15:21:44" itemprop="dateModified" datetime="2025-05-26T15:21:44+08:00">2025-05-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E7%9B%AE%E9%8C%84/" itemprop="url" rel="index"><span itemprop="name">目錄</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="目錄"><a href="#目錄" class="headerlink" title="目錄"></a>目錄</h1><h2 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h2><ul>
<li><a href="2024/12/31/2025%20updates/">2025 updates</a></li>
</ul>
<h2 id="安裝-設定"><a href="#安裝-設定" class="headerlink" title="安裝&amp;設定"></a>安裝&amp;設定</h2><ul>
<li><a href="2024/12/30/%E5%AE%89%E8%A3%9D&%E4%BD%BF%E7%94%A8/">安裝&amp;使用</a></li>
<li><a href="2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/">設定 API Key</a></li>
<li><a href="2024/12/30/%E8%A8%AD%E5%AE%9A%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B/">設定語言模型</a></li>
<li><a href="2024/12/30/%E8%A8%AD%E5%AE%9A%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/">設定嵌入模型</a></li>
</ul>
</br>
</br>


<h2 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h2><ul>
<li><a href="2024/12/29/RAG/">RAG</a></li>
<li><a href="2024/12/29/ask/">ask</a></li>
<li><a href="2024/12/28/eval/">eval</a></li>
<li><a href="2024/12/27/summary/">summary</a> </li>
<li><a href="2024/12/27/websearch/">websearch</a></li>
<li><a href="2024/12/27/gen_image/">gen_image</a></li>
<li><a href="2024/12/26/%E4%BB%A3%E7%90%86/">代理</a></li>
</ul>
</br>
</br>


<h2 id="進階"><a href="#進階" class="headerlink" title="進階"></a>進階</h2><ul>
<li><a href="2024/12/26/%E6%8F%90%E7%A4%BA%E6%A0%BC%E5%BC%8F/">提示格式</a></li>
<li><a href="2024/12/26/%E6%96%87%E4%BB%B6%E6%90%9C%E5%B0%8B/">文件搜尋</a></li>
<li><a href="2024/12/26/%E5%90%91%E9%87%8F%E8%B3%87%E6%96%99%E5%BA%AB/">向量資料庫</a></li>
<li><a href="2024/12/26/%E8%BC%94%E5%8A%A9%E5%87%BD%E6%95%B8/">輔助函數</a></li>
<li><a href="2024/12/26/%E6%B5%81%E8%BC%B8%E5%87%BA/">流輸出</a></li>
<li><a href="2024/12/26/FAST%20API/">FAST API</a></li>
<li><a href="2024/12/26/%E8%87%AA%E6%9F%A5%E8%A9%A2/">自查詢</a></li>
</ul>
</br>
</br>





<h2 id="UI"><a href="#UI" class="headerlink" title="UI"></a>UI</h2><ul>
<li><a href="2024/12/24/ui%E8%A8%AD%E5%AE%9A/">ui設定</a></li>
<li><a href="2024/12/24/ui%E6%93%8D%E4%BD%9C/">ui操作</a></li>
</ul>
</br>
</br>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/31/2025%20updates/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/31/2025%20updates/" class="post-title-link" itemprop="url">2025 updates 0.9</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-31 23:57:58" itemprop="dateCreated datePublished" datetime="2024-12-31T23:57:58+08:00">2024-12-31</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2025-05-26 15:23:12" itemprop="dateModified" datetime="2025-05-26T15:23:12+08:00">2025-05-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E7%9B%AE%E9%8C%84/" itemprop="url" rel="index"><span itemprop="name">目錄</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="05-26-0-9-0b"><a href="#05-26-0-9-0b" class="headerlink" title="05&#x2F;26(0.9.0b)"></a>05&#x2F;26(0.9.0b)</h2><ul>
<li>新增gen_image輸入prompt產生圖片(見<a href="2024/12/27/gen_image/">gen_image</a>)</li>
<li>新增 call_JSON_formatter(見<a href="2024/12/26/%E8%BC%94%E5%8A%A9%E5%87%BD%E6%95%B8/">輔助函數</a>)</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/30/%E5%AE%89%E8%A3%9D&%E4%BD%BF%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/30/%E5%AE%89%E8%A3%9D&%E4%BD%BF%E7%94%A8/" class="post-title-link" itemprop="url">安裝&使用</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-30 23:59:59" itemprop="dateCreated datePublished" datetime="2024-12-30T23:59:59+08:00">2024-12-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2025-04-14 15:52:07" itemprop="dateModified" datetime="2025-04-14T15:52:07+08:00">2025-04-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E5%AE%89%E8%A3%9D-%E8%A8%AD%E5%AE%9A/" itemprop="url" rel="index"><span itemprop="name">安裝&設定</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="使用anaconda和pip安裝akasha套件"><a href="#使用anaconda和pip安裝akasha套件" class="headerlink" title="使用anaconda和pip安裝akasha套件"></a>使用anaconda和pip安裝akasha套件</h2><p>Linux使用者安裝完畢anaconda，進行安裝akasha套件。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">###create environment</span><br><span class="line">$ conda create --name py3-10 python=3.10</span><br><span class="line">$ activate py3-10</span><br><span class="line"></span><br><span class="line">###install akasha</span><br><span class="line">$ pip install akasha-terminal</span><br></pre></td></tr></table></figure>

</br>
</br>


<h2 id="使用uv安裝akasha套件"><a href="#使用uv安裝akasha套件" class="headerlink" title="使用uv安裝akasha套件"></a>使用uv安裝akasha套件</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">###create environment</span><br><span class="line">$ uv venv --python 3.10</span><br><span class="line"></span><br><span class="line">###install akasha</span><br><span class="line">$ uv pip install akasha-terminal</span><br></pre></td></tr></table></figure>

</br>
</br>

<h2 id="在Python中使用"><a href="#在Python中使用" class="headerlink" title="在Python中使用"></a>在Python中使用</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># PYTHON3.10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line">ak = akasha.RAG(</span><br><span class="line">    embeddings=<span class="string">&quot;openai:text-embedding-3-small&quot;</span>,</span><br><span class="line">    model=<span class="string">&quot;openai:gpt-4o&quot;</span>,</span><br><span class="line">    max_input_tokens=<span class="number">3000</span>,</span><br><span class="line">    keep_logs=<span class="literal">True</span>,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">res = ak(</span><br><span class="line">    data_source=[<span class="string">&quot;docs/mic&quot;</span>, <span class="string">&quot;https://github.com/iii-org/akasha&quot;</span>],</span><br><span class="line">    prompt=PROMPT,</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</br>
</br>

<h2 id="簡單UI介面"><a href="#簡單UI介面" class="headerlink" title="簡單UI介面"></a>簡單UI介面</h2><p>在terminal上輸入，便會開起streamlit使用介面</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ akasha toy</span><br></pre></td></tr></table></figure>
</br>

<p>在瀏覽器中開啟 <a target="_blank" rel="noopener" href="http://localhost:8501/">http://localhost:8501/</a> <img src="https://hackmd.io/_uploads/SJ5f34qAyx.png" alt="ui_5"><br>進行設定後，便可在ui介面使用akasha的功能，詳情見 <img src="/akasha/2024/12/24/ui%E8%A8%AD%E5%AE%9A/" alt="ui設定"><br><strong>此介面僅為簡單展示，不適合作為服務使用</strong></p>
</br>
</br>

<h2 id="CLI"><a href="#CLI" class="headerlink" title="CLI"></a>CLI</h2><p>透過command line interface使用akasha，你可以用’keep-rag’來建立一個文檔問答模型，並可以提出不同的問題，根據給定目錄中的文檔獲取語言模型的回答。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">akasha keep-rag -d ../doc/plc/  -c 400</span></span><br><span class="line">Please input your question(type &quot;exit()&quot; to quit) : 應回收廢塑膠容器材質種類不包含哪種?  聚丙烯（PP） 聚苯乙烯（PS） 聚氯乙烯（PVC）  低密度聚乙烯（LDPE）</span><br><span class="line">Response:  應回收廢塑膠容器材質種類不包含低密度聚乙烯（LDPE）。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Please input your question(type &quot;exit()&quot; to quit) : 所謂市盈率，是指每股市價除以每股盈餘，也就是股票的?   本益比  帳面值比  派息   資金</span><br><span class="line">英國和德國等多個市場。然而，義大利、加拿大和澳洲並不在這些可交易的國家之列。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Please input your question(type &quot;exit()&quot; to quit) : exit()</span><br></pre></td></tr></table></figure>

</br>
</br>

<p>現在可使用的指令: <em><strong>rag</strong></em>, <em><strong>keep-rag</strong></em>, <em><strong>toy</strong></em>, <em><strong>api</strong></em> and <em><strong>auto-evaluation</strong></em>.</p>
</br>


<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">akasha keep-rag --<span class="built_in">help</span></span></span><br><span class="line">Usage: akasha keep-rag [OPTIONS]</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -d, --data_source TEXT          document directory path, or urls, parse all</span><br><span class="line">                                  .txt, .pdf, .docx files in the directory   </span><br><span class="line">                                  [required]</span><br><span class="line">  -e, --embeddings TEXT           embeddings for storing the documents</span><br><span class="line">  -c, --chunk_size INTEGER        chunk size for storing the documents</span><br><span class="line">  -m, --model TEXT                llm model for generating the response</span><br><span class="line">  -l, --language TEXT             language for the documents, default is &#x27;ch&#x27;</span><br><span class="line">                                  for chinese</span><br><span class="line">  -s, --search_type TEXT          search type for the documents, include</span><br><span class="line">                                  auto, knn, svm, bm25</span><br><span class="line">  -sys, --system_prompt TEXT      system prompt for the llm model</span><br><span class="line">  -md, --max_input_tokens INTEGER</span><br><span class="line">                                  max token for the llm model input</span><br><span class="line">  --help                          Show this message and exit.</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>

<h2 id="安裝WSL"><a href="#安裝WSL" class="headerlink" title="安裝WSL"></a>安裝WSL</h2><p>windows使用者可以安裝Windows子系統(WSL)，直接在Windows 執行Linux，請先確認windows版本是 Windows 10 版本 2004(組建 19041 和更新版本)或 Windows 11以上的版本才能安裝WSL。<br>先搜尋PowerShell，以系統管理員開啟 PowerShell執行WSL並安裝linux ubuntu，安裝完畢後要重新開機。</p>
<h3 id="install-wsl"><a href="#install-wsl" class="headerlink" title="install wsl"></a>install wsl</h3><p>安裝WSL並且安裝linux ubuntu。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ wsl --install</span><br></pre></td></tr></table></figure>
<p>安裝完畢，重新開機</p>
<h3 id="更新ubuntu"><a href="#更新ubuntu" class="headerlink" title="更新ubuntu"></a>更新ubuntu</h3><p>重新開機後，開啟wsl，更新ubuntu到最新版本</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt update -y &amp;&amp; sudo apt upgrade -y</span><br></pre></td></tr></table></figure>

<h3 id="更新系統套件到最新版本"><a href="#更新系統套件到最新版本" class="headerlink" title="更新系統套件到最新版本"></a>更新系統套件到最新版本</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$sudo apt update &amp;&amp; upgrade</span><br></pre></td></tr></table></figure>
<h3 id="安裝curl-套件"><a href="#安裝curl-套件" class="headerlink" title="安裝curl 套件"></a>安裝curl 套件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$sudo apt install curl</span><br></pre></td></tr></table></figure>
<h3 id="安裝anaconda"><a href="#安裝anaconda" class="headerlink" title="安裝anaconda"></a>安裝anaconda</h3><h3 id="先建立一個資料夾"><a href="#先建立一個資料夾" class="headerlink" title="先建立一個資料夾"></a>先建立一個資料夾</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$mkdir temp</span><br></pre></td></tr></table></figure>

<h3 id="進入資料夾"><a href="#進入資料夾" class="headerlink" title="進入資料夾"></a>進入資料夾</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$cd temp</span><br></pre></td></tr></table></figure>
<h3 id="下載anaconda-sh"><a href="#下載anaconda-sh" class="headerlink" title="下載anaconda.sh"></a>下載anaconda.sh</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$curl https://repo.anaconda.com/archive/Anaconda3-2023.09-0-Linux-x86_64.sh --output anaconda.sh</span><br></pre></td></tr></table></figure>
<h3 id="安裝anaconda-1"><a href="#安裝anaconda-1" class="headerlink" title="安裝anaconda"></a>安裝anaconda</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$bash anaconda.sh</span><br></pre></td></tr></table></figure>

<h3 id="新增conda-指令"><a href="#新增conda-指令" class="headerlink" title="新增conda 指令"></a>新增conda 指令</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$source ~/.bashrc</span><br></pre></td></tr></table></figure>

<h3 id="確認conda-有安裝成功"><a href="#確認conda-有安裝成功" class="headerlink" title="確認conda 有安裝成功"></a>確認conda 有安裝成功</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$conda info</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/" class="post-title-link" itemprop="url">設定 API Key</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-30 22:59:59" itemprop="dateCreated datePublished" datetime="2024-12-30T22:59:59+08:00">2024-12-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2025-04-14 15:54:22" itemprop="dateModified" datetime="2025-04-14T15:54:22+08:00">2025-04-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E5%AE%89%E8%A3%9D-%E8%A8%AD%E5%AE%9A/" itemprop="url" rel="index"><span itemprop="name">安裝&設定</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="openAI-API-Key"><a href="#openAI-API-Key" class="headerlink" title="openAI API Key"></a>openAI API Key</h1></br>
</br>

<h2 id="openAI"><a href="#openAI" class="headerlink" title="openAI:"></a>openAI:</h2><p>如果需要使用openAI的模型，必須先去<a target="_blank" rel="noopener" href="https://platform.openai.com/account/api-keys">openai</a>取得API金鑰。取得金鑰後，你可以選擇其中一種方法來匯入key:</p>
<h5 id="1-將KEY放於-env檔案中OPENAI-API-KEY-your-api-key"><a href="#1-將KEY放於-env檔案中OPENAI-API-KEY-your-api-key" class="headerlink" title="1.將KEY放於.env檔案中OPENAI_API_KEY&#x3D;your api key"></a>1.將KEY放於.env檔案中OPENAI_API_KEY&#x3D;your api key</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">OPENAI_API_KEY=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="2-設定成環境變數-變數名-OPENAI-API-KEY"><a href="#2-設定成環境變數-變數名-OPENAI-API-KEY" class="headerlink" title="2.設定成環境變數(變數名:OPENAI_API_KEY)"></a>2.設定成環境變數(變數名:OPENAI_API_KEY)</h5><h5 id="3-在terminal中使用export設定環境變數"><a href="#3-在terminal中使用export設定環境變數" class="headerlink" title="3.在terminal中使用export設定環境變數"></a>3.在terminal中使用export設定環境變數</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export OPENAI_API_KEY=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="4-在Python中使用os-environ-‘OPENAI-API-KEY’-your-api-key"><a href="#4-在Python中使用os-environ-‘OPENAI-API-KEY’-your-api-key" class="headerlink" title="4.在Python中使用os.environ[‘OPENAI_API_KEY’]&#x3D;your api key"></a>4.在Python中使用os.environ[‘OPENAI_API_KEY’]&#x3D;your api key</h5></br>
</br>

<h2 id="Azure-openAI"><a href="#Azure-openAI" class="headerlink" title="Azure openAI"></a>Azure openAI</h2><p>如果你想使用Azure openAI，先去<a target="_blank" rel="noopener" href="https://oai.azure.com/portal">azureAI</a>取得base url 和 API key。</p>
<p>將<em><strong>OPENAI_API_KEY&#x3D;your azure key</strong></em>, <em><strong>OPENAI_API_BASE&#x3D;your Language API base url</strong></em>, <em><strong>OPENAI_API_TYPE&#x3D;azure</strong></em>, <em><strong>OPENAI_API_VERSION&#x3D;2023-05-15</strong></em> 寫於.env檔案並放於你要執行akasha的路徑中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">## .env file</span><br><span class="line">AZURE_API_KEY=&#123;your azure key&#125;</span><br><span class="line">AZURE_API_BASE=&#123;your Language API base url&#125;</span><br><span class="line">AZURE_API_TYPE=azure</span><br><span class="line">AZURE_API_VERSION=2023-05-15</span><br></pre></td></tr></table></figure>


<h3 id="請記得在Azure-openAI-Studio部署所有你需要的模型，且部署名稱與模型名稱相同。"><a href="#請記得在Azure-openAI-Studio部署所有你需要的模型，且部署名稱與模型名稱相同。" class="headerlink" title="請記得在Azure openAI Studio部署所有你需要的模型，且部署名稱與模型名稱相同。"></a>請記得在<a target="_blank" rel="noopener" href="https://oai.azure.com/portal">Azure openAI Studio</a>部署所有你需要的模型，且部署名稱與模型名稱相同。</h3></br>
</br>


<h1 id="gemini-API-Key"><a href="#gemini-API-Key" class="headerlink" title="gemini API Key"></a>gemini API Key</h1><p>如果你想使用Gemini 模型，請至<a target="_blank" rel="noopener" href="https://aistudio.google.com/">google aistudio</a> 或 <a target="_blank" rel="noopener" href="https://console.cloud.google.com/">GCP</a>申請API金鑰。</p>
<p>取得金鑰後，你可以選擇其中一種方法來匯入key:</p>
<h5 id="1-將KEY放於-env檔案中GEMINI-API-KEY-your-api-key"><a href="#1-將KEY放於-env檔案中GEMINI-API-KEY-your-api-key" class="headerlink" title="1.將KEY放於.env檔案中GEMINI_API_KEY&#x3D;your api key"></a>1.將KEY放於.env檔案中GEMINI_API_KEY&#x3D;your api key</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GEMINI_API_KEY=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="2-設定成環境變數-變數名-GEMINI-API-KEY"><a href="#2-設定成環境變數-變數名-GEMINI-API-KEY" class="headerlink" title="2.設定成環境變數(變數名:GEMINI_API_KEY)"></a>2.設定成環境變數(變數名:GEMINI_API_KEY)</h5><h5 id="3-在terminal中使用export設定環境變數-1"><a href="#3-在terminal中使用export設定環境變數-1" class="headerlink" title="3.在terminal中使用export設定環境變數"></a>3.在terminal中使用export設定環境變數</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export GEMINI_API_KEY=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="4-在Python中使用os-environ-‘GEMINI-API-KEY’-your-api-key"><a href="#4-在Python中使用os-environ-‘GEMINI-API-KEY’-your-api-key" class="headerlink" title="4.在Python中使用os.environ[‘GEMINI_API_KEY’]&#x3D;your api key"></a>4.在Python中使用os.environ[‘GEMINI_API_KEY’]&#x3D;your api key</h5></br>
</br>

<h1 id="anthropic-API-Key"><a href="#anthropic-API-Key" class="headerlink" title="anthropic API Key"></a>anthropic API Key</h1><p>如果你想使用Gemini 模型，請至<a target="_blank" rel="noopener" href="https://www.anthropic.com/api/">anthropic</a>申請API金鑰。</p>
<p>取得金鑰後，你可以選擇其中一種方法來匯入key:</p>
<h5 id="1-將KEY放於-env檔案中ANTHROPIC-API-KEY-your-api-key"><a href="#1-將KEY放於-env檔案中ANTHROPIC-API-KEY-your-api-key" class="headerlink" title="1.將KEY放於.env檔案中ANTHROPIC_API_KEY&#x3D;your api key"></a>1.將KEY放於.env檔案中ANTHROPIC_API_KEY&#x3D;your api key</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ANTHROPIC_API_KEY=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="2-設定成環境變數-變數名-ANTHROPIC-API-KEY"><a href="#2-設定成環境變數-變數名-ANTHROPIC-API-KEY" class="headerlink" title="2.設定成環境變數(變數名:ANTHROPIC_API_KEY)"></a>2.設定成環境變數(變數名:ANTHROPIC_API_KEY)</h5><h5 id="3-在terminal中使用export設定環境變數-2"><a href="#3-在terminal中使用export設定環境變數-2" class="headerlink" title="3.在terminal中使用export設定環境變數"></a>3.在terminal中使用export設定環境變數</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export ANTHROPIC_API_KEY=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="4-在Python中使用os-environ-‘ANTHROPIC-API-KEY’-your-api-key"><a href="#4-在Python中使用os-environ-‘ANTHROPIC-API-KEY’-your-api-key" class="headerlink" title="4.在Python中使用os.environ[‘ANTHROPIC_API_KEY’]&#x3D;your api key"></a>4.在Python中使用os.environ[‘ANTHROPIC_API_KEY’]&#x3D;your api key</h5></br>
</br>


<h1 id="遠端API-Key"><a href="#遠端API-Key" class="headerlink" title="遠端API Key"></a>遠端API Key</h1><p>如果你想使用的遠端模型需指定API金鑰</p>
<h5 id="1-將KEY放於-env檔案中RETMOE-API-KEY-your-api-key"><a href="#1-將KEY放於-env檔案中RETMOE-API-KEY-your-api-key" class="headerlink" title="1.將KEY放於.env檔案中RETMOE_API_KEY&#x3D;your api key"></a>1.將KEY放於.env檔案中RETMOE_API_KEY&#x3D;your api key</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">REMOTE_API_KEY=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="2-設定成環境變數-變數名-REMOTE-API-KEY"><a href="#2-設定成環境變數-變數名-REMOTE-API-KEY" class="headerlink" title="2.設定成環境變數(變數名:REMOTE_API_KEY)"></a>2.設定成環境變數(變數名:REMOTE_API_KEY)</h5><h5 id="3-在terminal中使用export設定環境變數-3"><a href="#3-在terminal中使用export設定環境變數-3" class="headerlink" title="3.在terminal中使用export設定環境變數"></a>3.在terminal中使用export設定環境變數</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export REMOTE_API_KEY=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>

<h5 id="4-在Python中使用os-environ-‘REMOTE-API-KEY’-your-api-key"><a href="#4-在Python中使用os-environ-‘REMOTE-API-KEY’-your-api-key" class="headerlink" title="4.在Python中使用os.environ[‘REMOTE_API_KEY’]&#x3D;your api key"></a>4.在Python中使用os.environ[‘REMOTE_API_KEY’]&#x3D;your api key</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os </span><br><span class="line">os.environ[<span class="string">&#x27;REMOTE_API_KEY&#x27;</span>]=<span class="string">&quot;your api key&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


</br>
</br>
</br>
</br>


<h2 id="LLAMA-2"><a href="#LLAMA-2" class="headerlink" title="LLAMA-2"></a>LLAMA-2</h2><p>如果你想使用原版的meta-llama model，並須先去<a target="_blank" rel="noopener" href="https://ai.meta.com/resources/models-and-libraries/llama-downloads/">meta-llama</a>去取得授權，並註冊<a target="_blank" rel="noopener" href="https://huggingface.co/login?next=/settings/tokens">huggingface</a>取得access token，取得授權後才能經由huggingface下載並使用模型。<br><img src="https://hackmd.io/_uploads/H1LOb2ot6.png" alt="granted"></p>
<p>the account on Hugging Face and the email you use to request access to Meta-Llama must be the same, so that you can download models from Hugging Face once your account is approved.</p>
<p>You should see the Gated model You have been granted access to this model once your account is approved</p>
</br>
</br>


<p>同樣的，取得huggingface key值後，你可以選擇其中一種方法來匯入key:</p>
<h5 id="1-將KEY放於-env檔案中HF-TOKEN-your-api-key"><a href="#1-將KEY放於-env檔案中HF-TOKEN-your-api-key" class="headerlink" title="1.將KEY放於.env檔案中HF_TOKEN&#x3D;your api key"></a>1.將KEY放於.env檔案中HF_TOKEN&#x3D;your api key</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HF_TOKEN=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="2-設定成環境變數-變數名-HF-TOKEN"><a href="#2-設定成環境變數-變數名-HF-TOKEN" class="headerlink" title="2.設定成環境變數(變數名:HF_TOKEN)"></a>2.設定成環境變數(變數名:HF_TOKEN)</h5><h5 id="3-在terminal中使用export設定環境變數-4"><a href="#3-在terminal中使用export設定環境變數-4" class="headerlink" title="3.在terminal中使用export設定環境變數"></a>3.在terminal中使用export設定環境變數</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export HF_TOKEN=&#123;your api key&#125;</span><br></pre></td></tr></table></figure>
<h5 id="4-在Python中使用os-environ-‘HF-TOKEN’-your-api-key"><a href="#4-在Python中使用os-environ-‘HF-TOKEN’-your-api-key" class="headerlink" title="4.在Python中使用os.environ[‘HF_TOKEN’]&#x3D;your api key"></a>4.在Python中使用os.environ[‘HF_TOKEN’]&#x3D;your api key</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#PYTHON3.9</span><br><span class="line"># os.environ[&#x27;HF_TOKEN&#x27;]=your api key</span><br><span class="line">import akasha</span><br><span class="line">ak = akasha.Doc_QA()</span><br><span class="line">response = ak.get_response(dir_path, prompt, model=&quot;hf:meta-llama/Llama-2-7b-chat-hf&quot;)</span><br></pre></td></tr></table></figure>


</br>
</br>

<h1 id="設定多組不同API-KEY"><a href="#設定多組不同API-KEY" class="headerlink" title="設定多組不同API KEY"></a>設定多組不同API KEY</h1><p>若你需要根據不同模型設定不同的API KEY，在Doc_QA, Model_Eval, Summary Class中皆提供env_file參數，可輸入不同的.env檔來export API KEY<br>若不存在或為空值，則為預設值(.env)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line">ak = akasha.ask(<span class="string">&quot;openai:gpt-4o&quot;</span>, env_file=<span class="string">&quot;.env&quot;</span>, verbose=<span class="literal">True</span>)</span><br><span class="line">ak(<span class="string">&quot;日本本州最大的城市是哪裡?&quot;</span>)</span><br><span class="line"></span><br><span class="line">ak2 = akasha.ak(<span class="string">&quot;openai:gpt-4&quot;</span>, env_file=<span class="string">&quot;.env2&quot;</span>, verbose=<span class="literal">True</span>)</span><br><span class="line">ak2(<span class="string">&quot;日本本州最大的城市是哪裡?&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">設定語言模型</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-30 21:59:59" itemprop="dateCreated datePublished" datetime="2024-12-30T21:59:59+08:00">2024-12-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2025-08-20 18:19:34" itemprop="dateModified" datetime="2025-08-20T18:19:34+08:00">2025-08-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E5%AE%89%E8%A3%9D-%E8%A8%AD%E5%AE%9A/" itemprop="url" rel="index"><span itemprop="name">安裝&設定</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="選擇不同語言模型"><a href="#選擇不同語言模型" class="headerlink" title="選擇不同語言模型"></a>選擇不同語言模型</h2><p>使用參數<em><strong>model</strong></em>便可以選擇不同的語言模型，預設是<em><strong>openai:gpt-3.5-turbo</strong></em>.</p>
<h2 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h2><h3 id="1-openai"><a href="#1-openai" class="headerlink" title="1. openai"></a>1. openai</h3><p>(請先完成<a href="/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/">設定 API Key</a>)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">akasha.RAG(embeddings=&quot;openai:text-embedding-ada-002&quot;,</span><br><span class="line">                model=&quot;openai:gpt-3.5-turbo&quot;)</span><br><span class="line">ak(dir_path, prompt, )</span><br></pre></td></tr></table></figure>

</br>
</br>

<h3 id="2-huggingface"><a href="#2-huggingface" class="headerlink" title="2. huggingface"></a>2. huggingface</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.RAG(embeddings=&quot;hf:Alibaba-NLP/gte-multilingual-base&quot;,</span><br><span class="line">                model=&quot;hf:Qwen/Qwen2.5-7B-Instruct&quot;)</span><br><span class="line">ak(dir_path, prompt, )</span><br></pre></td></tr></table></figure>
</br>
</br>

<h3 id="3-llama-cpp"><a href="#3-llama-cpp" class="headerlink" title="3. llama-cpp"></a>3. llama-cpp</h3><p>安裝llama-cpp-python可以使用cpu推論.gguf格式的模型，或是安裝akasha時選擇llama-cpp</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install llama-cpp-python</span><br><span class="line">#pip install akasha-terminal[llama-cpp]</span><br></pre></td></tr></table></figure>

<p>llama-cpp允許使用quantized模型並執行在cpu上，你可以從huggingface上下載.gguf llama-cpp 模型，如範例，如果你的模型下載到”model&#x2F;“路徑下，可以使用以下方法加載模型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.RAG(embeddings=&quot;hf:Alibaba-NLP/gte-multilingual-base&quot;,</span><br><span class="line">                model=&quot;llama-cpp:model/llama-2-13b-chat.Q5_K_S.gguf&quot;)</span><br><span class="line">ak(dir_path, prompt,)</span><br></pre></td></tr></table></figure>
</br>
</br>

<p>llama-cpp同樣允許使用gpu運算模型，但安裝套件時需要使用cmake安裝，並確認已安裝g++, gcc和nvidia driver &amp; toolkit，詳細請見<a target="_blank" rel="noopener" href="https://github.com/abetlen/llama-cpp-python">llama-cpp-python</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CMAKE_ARGS=&quot;-DGGML_CUDA=on&quot; FORCE_CMAKE=1 python -m pip install --upgrade --force-reinstall llama-cpp-python&gt;=0.3.1 --no-cache-dir</span><br></pre></td></tr></table></figure>

</br>
</br>

<h3 id="4-遠端api"><a href="#4-遠端api" class="headerlink" title="4. 遠端api"></a>4. 遠端api</h3><p>如果你使用別人的api或者透過支援openAI api框架的部署自己的模型(例如vllm, TGI, litellm…)，你可以使用 <em><strong>remote:{your LLM api url}</strong></em> 來加載模型，若須指定模型名稱，使用 <em><strong>remote:{your LLM api url}@{your model name}</strong></em> 。</p>
<p>若遠端api需要api金鑰，請先完成設定環境變數 <em><strong>REMOTE_API_KEY</strong></em> ，參考<a href="/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/">設定 API Key</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.RAG(model=&quot;remote:http://140.92.60.189:8081@llama-3.2-11B&quot;)</span><br><span class="line">ak(dir_path, prompt, )</span><br></pre></td></tr></table></figure>

</br>
</br>

<h3 id="5-gemini"><a href="#5-gemini" class="headerlink" title="5. gemini"></a>5. gemini</h3><p>(請先完成<a href="/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/">設定 API Key</a>)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.RAG(embeddings=&quot;gemini:models/text-embedding-004&quot;,</span><br><span class="line">                model=&quot;gemini:gemini-1.5-flash&quot;)</span><br><span class="line">ak(dir_path, prompt, )</span><br></pre></td></tr></table></figure>


</br>
</br>


<h3 id="6-anthropic"><a href="#6-anthropic" class="headerlink" title="6. anthropic"></a>6. anthropic</h3><p>(請先完成<a href="/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/">設定 API Key</a>)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ask_tool = akasha.ask(model=&quot;anthropic:claude-3-5-sonnet-20241022&quot;)</span><br><span class="line">ask_tool( prompt, info=dir_path, )</span><br></pre></td></tr></table></figure>


</br>
</br>


<h2 id="推薦一些可使用的模型"><a href="#推薦一些可使用的模型" class="headerlink" title="推薦一些可使用的模型"></a>推薦一些可使用的模型</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">openai_model = &quot;openai:gpt-3.5-turbo&quot;  # need environment variable &quot;OPENAI_API_KEY&quot;</span><br><span class="line">gemini_model=&quot;gemini:gemini-1.5-flash&quot; # need environment variable &quot;GEMINI_API_KEY&quot;</span><br><span class="line">anthropic_model = &quot;anthropic:claude-3-5-sonnet-20241022&quot; # need environment variable &quot;ANTHROPIC_API_KEY&quot;</span><br><span class="line">huggingface_model = &quot;hf:meta-llama/Llama-2-7b-chat-hf&quot; #need environment variable &quot;HUGGINGFACEHUB_API_TOKEN&quot; to download meta-llama model</span><br><span class="line">qwen_model = &quot;hf:Qwen/Qwen2.5-7B-Instruct&quot;</span><br><span class="line">quantized_ch_llama_model = &quot;hf:FlagAlpha/Llama2-Chinese-13b-Chat-4bit&quot;</span><br><span class="line">taiwan_llama_gptq = &quot;hf:weiren119/Taiwan-LLaMa-v1.0-4bits-GPTQ&quot;</span><br><span class="line">mistral = &quot;hf:Mistral-7B-Instruct-v0.2&quot; </span><br><span class="line">mediatek_Breeze = &quot;hf:MediaTek-Research/Breeze-7B-Instruct-64k-v0.1&quot;</span><br><span class="line">### If you want to use llama-cpp to run model on cpu, you can download gguf version of models </span><br><span class="line">### from https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF  and the name behind &quot;llama-cpp:&quot;</span><br><span class="line">### from https://huggingface.co/TheBloke/CodeUp-Llama-2-13B-Chat-HF-GGUF</span><br><span class="line">### is the path of the downloaded .gguf file</span><br><span class="line">llama_cpp_model = &quot;llama-cpp:model/llama-2-13b-chat-hf.Q5_K_S.gguf&quot;  </span><br><span class="line">llama_cpp_model = &quot;llama-cpp:model/llama-2-7b-chat.Q5_K_S.gguf&quot;</span><br><span class="line">llama_cpp_chinese_alpaca = &quot;llama-cpp:model/chinese-alpaca-2-7b.Q5_K_S.gguf&quot;</span><br><span class="line">llama_cpp_chinese_alpaca = &quot;llama-cpp:model/chinese-alpaca-2-13b.Q5_K_M.gguf&quot;</span><br><span class="line">chatglm_model = &quot;chatglm:THUDM/chatglm2-6b&quot;</span><br></pre></td></tr></table></figure>


</br>
</br>
</br>
</br>


<h2 id="自訂語言模型"><a href="#自訂語言模型" class="headerlink" title="自訂語言模型"></a>自訂語言模型</h2><p>如果你想使用其他模型，可以建立一個輸入是prompt的函數並回傳語言模型的回答，並將此函數作為<em><strong>model</strong></em>參數</p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><p>我們建立一個test_model函數，並可以將它作為參數輸入進RAG 或 ask物件回答問題</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">def test_model(prompt:str):</span><br><span class="line">    </span><br><span class="line">    import openai</span><br><span class="line">    from langchain.chat_models import ChatOpenAI</span><br><span class="line">    openai.api_type = &quot;open_ai&quot;</span><br><span class="line">    model = ChatOpenAI(model=&quot;gpt-3.5-turbo&quot;, temperature = 0)</span><br><span class="line">    ret = model.predict(prompt)</span><br><span class="line">    </span><br><span class="line">    return ret</span><br><span class="line"></span><br><span class="line">prompt = &quot;工業4.0是什麼?&quot;</span><br><span class="line"></span><br><span class="line">cs = akasha.ask(verbose=True, model = test_model)</span><br><span class="line">cs(prompt = prompt)</span><br></pre></td></tr></table></figure>
</br>
</br>
</br>
</br>

<h2 id="建立LLM物件"><a href="#建立LLM物件" class="headerlink" title="建立LLM物件"></a>建立LLM物件</h2><p>以上使用model參數選擇模型後，便會在Doc_QA物件內建立模型的物件model_obj(LLM)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">AK = akasha.RAG(model=&quot;openai:gpt-3.5-turbo&quot;)</span><br><span class="line"></span><br><span class="line">print(type(AK.model_obj)) </span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>


<p>也可以使用輔助函數建立LLM物件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import akasha.helper as ah</span><br><span class="line"></span><br><span class="line">model_obj = ah.handle_model(&quot;openai:gpt-3.5-turbo&quot;,verbose=False,temperature=0.0)</span><br><span class="line"></span><br><span class="line">print(type(model_obj)) </span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>

<p>此LLM物件也可直接傳入高級物件，避免重複宣告</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">import</span> akasha.helper <span class="keyword">as</span> ah</span><br><span class="line">model_obj = ah.handle_model(<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>,verbose=<span class="literal">False</span>,temperature=<span class="number">0.0</span>)</span><br><span class="line"></span><br><span class="line">AK = akasha.ask(model=model_obj) </span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="直接使用LLM物件"><a href="#直接使用LLM物件" class="headerlink" title="直接使用LLM物件"></a>直接使用LLM物件</h2><h3 id="取得模型類別"><a href="#取得模型類別" class="headerlink" title="取得模型類別"></a>取得模型類別</h3><p>使用_llm_type()可取得語言模型的類別</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> akasha.helper <span class="keyword">as</span> ah</span><br><span class="line">model_obj = ah.handle_model(<span class="string">&quot;gemini:gemini-1.5-flash&quot;</span>,verbose=<span class="literal">False</span>,temperature=<span class="number">0.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model_obj._llm_type()) <span class="comment">## &quot;gemini:gemini-1.5-flash&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="模型推論"><a href="#模型推論" class="headerlink" title="模型推論"></a>模型推論</h3><p>若要使用語言模型進行推論，可以使用函式call_model</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha.helper <span class="keyword">as</span> ah</span><br><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">from</span> akasha.utils.prompts.gen_prompt <span class="keyword">import</span> format_sys_prompt</span><br><span class="line">system_prompt = <span class="string">&quot;用中文回答&quot;</span></span><br><span class="line">prompt = <span class="string">&quot;五軸是什麼?&quot;</span></span><br><span class="line">model_obj = ah.handle_model(<span class="string">&quot;openai:gpt-e3.5-turbo&quot;</span>, <span class="literal">False</span>, <span class="number">0.0</span>)</span><br><span class="line">input_text = format_sys_prompt(system_prompt, prompt, <span class="string">&quot;gpt&quot;</span>)</span><br><span class="line"></span><br><span class="line">response = akasha.call_model(model_obj, input_text)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>


<h3 id="流輸出"><a href="#流輸出" class="headerlink" title="流輸出"></a>流輸出</h3><p>若要呼叫語言模型即時回答，可以使用函式call_stream_model</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha.helper <span class="keyword">as</span> ah</span><br><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">from</span> akasha.utils.prompts.gen_prompt <span class="keyword">import</span> format_sys_prompt</span><br><span class="line"></span><br><span class="line">system_prompt = <span class="string">&quot;用中文回答&quot;</span></span><br><span class="line">prompt = <span class="string">&quot;五軸是什麼?&quot;</span></span><br><span class="line">model_obj = ah.handle_model(<span class="string">&quot;openai:gpt-e3.5-turbo&quot;</span>, <span class="literal">False</span>, <span class="number">0.0</span>)</span><br><span class="line">input_text = format_sys_prompt(system_prompt, prompt, <span class="string">&quot;gpt&quot;</span>)</span><br><span class="line"></span><br><span class="line">streaming = akasha.call_stream_model(model_obj, input_text)</span><br><span class="line">tot_text = <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> streaming:</span><br><span class="line">    tot_text+=s</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>


<h3 id="批量推論"><a href="#批量推論" class="headerlink" title="批量推論"></a>批量推論</h3><p>如果你有大量不需要連貫的推理需求，可以使用<strong>akasha.helper.call_batch_model</strong> 來進行批量推理來提升速度。</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def call_batch_model(model: LLM, prompt: List[str], </span><br><span class="line">    system_prompt: Union[List[str], str] = &quot;&quot;) -&gt; List[str]:</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">import</span> akasha.helper <span class="keyword">as</span> ah</span><br><span class="line">model_obj = ah.handle_model(<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>, <span class="literal">False</span>, <span class="number">0.0</span>)</span><br><span class="line"><span class="comment"># this prompt ask LLM to response &#x27;yes&#x27; or &#x27;no&#x27; if the document segment is relevant to the user question or not.</span></span><br><span class="line">SYSTEM_PROMPT = <span class="string">&quot;response only &#x27;yes&#x27; or &#x27;no&#x27;, &#x27;yes&#x27; if the document segment is relevant to the user question, &#x27;no&#x27; for not.&quot;</span></span><br><span class="line">documents = [<span class="string">&quot;Doc1...&quot;</span>, <span class="string">&quot;Doc2...&quot;</span>, <span class="string">&quot;Doc3...&quot;</span>, <span class="string">&quot;Doc4...&quot;</span>]</span><br><span class="line">question = <span class="string">&quot;五軸是什麼?&quot;</span></span><br><span class="line"></span><br><span class="line">prompts = [<span class="string">&quot;document: &quot;</span> + doc +<span class="string">&quot;\n\n&quot;</span> + <span class="string">&quot;User Question: &quot;</span>+ question <span class="keyword">for</span> doc <span class="keyword">in</span> documents]</span><br><span class="line"></span><br><span class="line">response_list = call_batch_model(model_obj, prompt, SYSTEM_PROMPT)</span><br><span class="line"></span><br><span class="line"><span class="comment">## [&quot;yes&quot;, &quot;no&quot;, &quot;yes&quot;, &quot;yes&quot;]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="輸出格式化"><a href="#輸出格式化" class="headerlink" title="輸出格式化"></a>輸出格式化</h3><p>如果你想強制使語言模型輸出符合JSON格式的回答，可以使用 <em><strong>call_JSON_formatter</strong></em>，會轉換語言模型的輸出為字典或字典串列。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha.helper <span class="keyword">as</span> ah</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">PROMPT3 = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">openai_model = &quot;openai:gpt-3.5-turbo&quot;  # need environment variable &quot;OPENAI_API_KEY&quot;</span></span><br><span class="line"><span class="string">gemini_model=&quot;gemini:gemini-1.5-flash&quot; # need environment variable &quot;GEMINI_API_KEY&quot;</span></span><br><span class="line"><span class="string">anthropic_model = &quot;anthropic:claude-3-5-sonnet-20241022&quot; # need environment variable &quot;ANTHROPIC_API_KEY&quot;</span></span><br><span class="line"><span class="string">huggingface_model = &quot;hf:meta-llama/Llama-2-7b-chat-hf&quot; #need environment variable &quot;HUGGINGFACEHUB_API_TOKEN&quot; to download meta-llama model</span></span><br><span class="line"><span class="string">qwen_model = &quot;hf:Qwen/Qwen2.5-7B-Instruct&quot;</span></span><br><span class="line"><span class="string">quantized_ch_llama_model = &quot;hf:FlagAlpha/Llama2-Chinese-13b-Chat-4bit&quot;</span></span><br><span class="line"><span class="string">taiwan_llama_gptq = &quot;hf:weiren119/Taiwan-LLaMa-v1.0-4bits-GPTQ&quot;</span></span><br><span class="line"><span class="string">mistral = &quot;hf:Mistral-7B-Instruct-v0.2&quot; </span></span><br><span class="line"><span class="string">mediatek_Breeze = &quot;hf:MediaTek-Research/Breeze-7B-Instruct-64k-v0.1&quot;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">model_obj = ah.handle_model(<span class="string">&quot;openai:gpt-4o&quot;</span>, <span class="literal">False</span>, <span class="number">0.0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 使用BaseModel 指定輸出的keys</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model_Type</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    model_type: <span class="built_in">str</span></span><br><span class="line">    model_name: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">json_response = ah.call_JSON_formatter(model_obj, PROMPT3, keys=Model_Type)</span><br><span class="line"><span class="built_in">print</span>(json_response)</span><br><span class="line"><span class="comment"># response: [&#123;&#x27;model_type&#x27;: &#x27;openai&#x27;, &#x27;model_name&#x27;: &#x27;gpt-3.5-turbo&#x27;&#125;, &#123;&#x27;model_type&#x27;: &#x27;gemini&#x27;, &#x27;model_name&#x27;: &#x27;gemini-1.5-flash&#x27;&#125;, &#123;&#x27;model_type&#x27;: &#x27;anthropic&#x27;, &#x27;model_name&#x27;: &#x27;claude-3-5-sonnet-20241022&#x27;&#125;,...</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">設定嵌入模型</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-30 20:59:59" itemprop="dateCreated datePublished" datetime="2024-12-30T20:59:59+08:00">2024-12-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2025-04-22 11:33:19" itemprop="dateModified" datetime="2025-04-22T11:33:19+08:00">2025-04-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E5%AE%89%E8%A3%9D-%E8%A8%AD%E5%AE%9A/" itemprop="url" rel="index"><span itemprop="name">安裝&設定</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="選擇不同嵌入模型"><a href="#選擇不同嵌入模型" class="headerlink" title="選擇不同嵌入模型"></a>選擇不同嵌入模型</h2><p>使用參數<em><strong>embeddings</strong></em>便可以選擇不同的嵌入模型，預設是<em><strong>openai:text-embedding-ada-002</strong></em>.</p>
<h2 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h2><h3 id="1-openai"><a href="#1-openai" class="headerlink" title="1. openai"></a>1. openai</h3><p>(請先完成<a href="/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/">設定 API Key</a>)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">akasha.RAG( embeddings=&quot;openai:text-embedding-ada-002&quot;)</span><br><span class="line">ak(dir_path, prompt)</span><br></pre></td></tr></table></figure>

</br>
</br>

<h3 id="2-huggingface"><a href="#2-huggingface" class="headerlink" title="2. huggingface"></a>2. huggingface</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">akasha.RAG( embeddings=&quot;huggingface:all-MiniLM-L6-v2&quot;)</span><br><span class="line">ak(dir_path, prompt)</span><br></pre></td></tr></table></figure>
</br>
</br>

<h3 id="3-gemini"><a href="#3-gemini" class="headerlink" title="3. gemini"></a>3. gemini</h3><p>(請先完成<a href="/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%20API%20Key/">設定 API Key</a>)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">akasha.RAG( embeddings=&quot;gemini:models/text-embedding-004&quot;,</span><br><span class="line">                model=&quot;gemini:gemini-1.5-flash&quot;)</span><br><span class="line">ak(dir_path, prompt)</span><br></pre></td></tr></table></figure>


</br>
</br>

<h2 id="推薦一些可使用的模型"><a href="#推薦一些可使用的模型" class="headerlink" title="推薦一些可使用的模型"></a>推薦一些可使用的模型</h2><p>每個嵌入模型都有max sequence length，超過的話後面的文字就會被截斷，不會拿進去做嵌入。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">openai_emb = &quot;openai:text-embedding-ada-002&quot;  # need environment variable &quot;OPENAI_API_KEY&quot;  # 8192 max seq length</span><br><span class="line">openai_3l_emb = &quot;openai:text-embedding-3-large&quot;</span><br><span class="line">openai_3s_emb = &quot;openai:text-embedding-3-small&quot;</span><br><span class="line">gemini_emb = &quot;gemini:models/text-embedding-004&quot;</span><br><span class="line">huggingface_emb = &quot;hf:all-MiniLM-L6-v2&quot; </span><br><span class="line">alibaba_bge_emb = &quot;hf:Alibaba-NLP/gte-multilingual-base&quot; #8192 max seq length</span><br><span class="line">bge_en_emb = &quot;hf:BAAI/bge-base-en-v1.5&quot;  # 512 max seq length</span><br><span class="line">bge_ch_emb = &quot;hf:BAAI/bge-base-zh-v1.5&quot;  # 512 max seq length</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>
</br>
</br>


<h2 id="自訂嵌入模型"><a href="#自訂嵌入模型" class="headerlink" title="自訂嵌入模型"></a>自訂嵌入模型</h2><p>如果你想使用其他模型，可以建立一個輸入是<em><strong>texts:list</strong></em>的函數，代表的是文件庫中所有分割好的文字段落，此函數需回傳embedding之後每段文字的向量，並將此函數作為<em><strong>embeddings</strong></em>參數</p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><p>我們建立一個test_embed函數，並可以將它作為參數輸入進get_response回答問題</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">def test_embed(texts:list)-&gt;list:</span><br><span class="line"></span><br><span class="line">    from sentence_transformers import SentenceTransformer</span><br><span class="line">    mdl = SentenceTransformer(&#x27;BAAI/bge-large-zh-v1.5&#x27;)</span><br><span class="line">    embeds =  mdl.encode(texts,normalize_embeddings=True)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    return embeds</span><br><span class="line"></span><br><span class="line">doc_source = [&quot;./mic/&quot;]</span><br><span class="line">prompt = &quot;五軸是什麼?&quot;</span><br><span class="line"></span><br><span class="line">qa = akasha.RAG(verbose=True, search_type = &quot;svm&quot;, embeddings = test_embed)</span><br><span class="line">qa(doc_source= doc_path, prompt = prompt)</span><br></pre></td></tr></table></figure>


<h2 id="建立Embeddings物件"><a href="#建立Embeddings物件" class="headerlink" title="建立Embeddings物件"></a>建立Embeddings物件</h2><p>以上使用embeddings參數選擇模型後，便會在Doc_QA物件內建立模型的物件embeddings_obj(Embeddings)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">AK = akasha.RAG(embeddings=&quot;openai:text-embedding-ada-002&quot;)</span><br><span class="line"></span><br><span class="line">print(type(AK.embeddings_obj)) </span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>


<p>也可以使用輔助函數建立Embeddings物件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line">import akasha.helper as ah</span><br><span class="line">embeddings_obj = ah.handle_embeddings(&quot;openai:text-embedding-ada-002&quot;,verbose=False)</span><br><span class="line"></span><br><span class="line">print(type(embeddings_obj)) </span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>

<p>此Embeddings物件也可直接傳入高級物件，避免重複宣告</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">import</span> akasha.helper <span class="keyword">as</span> ah</span><br><span class="line">model_obj = ah.handle_model(<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>,verbose=<span class="literal">False</span>,temperature=<span class="number">0.0</span>)</span><br><span class="line">embeddings_obj = ah.handle_embeddings(<span class="string">&quot;openai:text-embedding-ada-002&quot;</span>,verbose=<span class="literal">False</span>)</span><br><span class="line">AK = akasha.RAG(model=model_obj, embeddings=embeddings_obj) </span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>

<h2 id="直接使用Embeddings物件"><a href="#直接使用Embeddings物件" class="headerlink" title="直接使用Embeddings物件"></a>直接使用Embeddings物件</h2><h3 id="embed-documents"><a href="#embed-documents" class="headerlink" title="embed_documents"></a>embed_documents</h3><p>創建完Embeddings物件後，可以直接使用來得到文件片段的向量資料(list[list[float]])</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">import</span> akasha.helper <span class="keyword">as</span> ah</span><br><span class="line">text_list = [<span class="string">&quot;範例文件內容1&quot;</span>, <span class="string">&quot;範例文件內容2&quot;</span>, <span class="string">&quot;範例文件內容3&quot;</span>]</span><br><span class="line">embeddings_obj = ah.handle_embeddings(<span class="string">&quot;openai:text-embedding-ada-002&quot;</span>,verbose=<span class="literal">False</span>)</span><br><span class="line">vectors = embeddings_obj.embed_documents(text_list)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(vectors) <span class="comment"># [[-0.004720511846244335, -2.9706923214689596e-06, -0.013798418454825878,...], [-0.004720511846244335, -2.9706923214689596e-06, -0.013798418454825878,...], [-0.004720511846244335, -2.9706923214689596e-06, -0.013798418454825878,...]]</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/29/RAG/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/29/RAG/" class="post-title-link" itemprop="url">RAG</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-29 23:59:59" itemprop="dateCreated datePublished" datetime="2024-12-29T23:59:59+08:00">2024-12-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2025-04-22 11:30:36" itemprop="dateModified" datetime="2025-04-22T11:30:36+08:00">2025-04-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E5%8A%9F%E8%83%BD/" itemprop="url" rel="index"><span itemprop="name">功能</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="RAG"><a href="#RAG" class="headerlink" title="RAG"></a>RAG</h2><p>使用者可輸入一個或多個文件(.pdf, .docx, .md, .txt, .csv, .pptx)、資料夾、或網址，RAG將藉由嵌入模型將文件儲存成向量資料庫(儲存在&#x2F;chromadb中)<br>此函數可以讓語言模型根據搜尋到的文件回答問題。藉由使用者的問題和文件庫搜尋到知識片段，可以不用將整份文件輸入給模型，就讓語言模型正確回答問題。</p>
<h3 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h3><p>宣告一個RAG的物件，可設定語言模型、嵌入模型、文本長度上限等參數。<br>使用 <em><strong>data_source</strong></em> 指定需要參考的文件資料，並建成向量資料庫(若已建立則直接讀取)，根據prompt回答問題<br>詢問完問題後，若有keep_logs參數，可選擇儲存成json檔案，也可使用reference()取得回答問題所使用的文件名稱、頁數(dict)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.RAG(</span><br><span class="line">    embeddings=&quot;openai:text-embedding-3-small&quot;,</span><br><span class="line">    model=&quot;openai:gpt-4o&quot;,</span><br><span class="line">    max_input_tokens=3000,</span><br><span class="line">    keep_logs=True,</span><br><span class="line">    verbose=True,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">res = ak(</span><br><span class="line">    data_source=[&quot;docs/mic&quot;, &quot;https://github.com/iii-org/akasha&quot;],</span><br><span class="line">    prompt=&quot;akasha是甚麼?&quot;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">## optional</span><br><span class="line">ref = ak.reference() #&#123;&quot;1.pdf&quot;:2,3,4&#125;</span><br><span class="line"></span><br><span class="line">ak.save_logs(&quot;logs.json&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="RAG-參數"><a href="#RAG-參數" class="headerlink" title="RAG 參數"></a>RAG 參數</h3><h5 id="verbose-bool-如果設True，會顯示每個步驟產生的文字和狀態"><a href="#verbose-bool-如果設True，會顯示每個步驟產生的文字和狀態" class="headerlink" title="verbose: bool 如果設True，會顯示每個步驟產生的文字和狀態"></a>verbose: bool 如果設True，會顯示每個步驟產生的文字和狀態</h5><h5 id="search-type-Union-str-Callable-用來搜尋文件段落的方法，可選擇-auto-svm-tfidf-bm25-mmr-knn"><a href="#search-type-Union-str-Callable-用來搜尋文件段落的方法，可選擇-auto-svm-tfidf-bm25-mmr-knn" class="headerlink" title="search_type: Union[str, Callable] 用來搜尋文件段落的方法，可選擇: auto, svm, tfidf, bm25, mmr, knn."></a>search_type: Union[str, Callable] 用來搜尋文件段落的方法，可選擇: <em><strong>auto</strong></em>, <em><strong>svm</strong></em>, <em><strong>tfidf</strong></em>, <em><strong>bm25</strong></em>, <em><strong>mmr</strong></em>, <em><strong>knn</strong></em>.</h5><h5 id="model-Union-str-BaseLanguageModel-使用的語言模型，如-openai-gpt-3-5-turbo-gemini-gemini-1-5-flash"><a href="#model-Union-str-BaseLanguageModel-使用的語言模型，如-openai-gpt-3-5-turbo-gemini-gemini-1-5-flash" class="headerlink" title="model: Union[str, BaseLanguageModel] 使用的語言模型，如 openai:gpt-3.5-turbo, gemini:gemini-1.5-flash"></a>model: Union[str, BaseLanguageModel] 使用的語言模型，如 <em><strong>openai:gpt-3.5-turbo</strong></em>, <em><strong>gemini:gemini-1.5-flash</strong></em></h5><h5 id="embeddings-Union-str-Embeddings"><a href="#embeddings-Union-str-Embeddings" class="headerlink" title="embeddings: Union[str, Embeddings]"></a>embeddings: Union[str, Embeddings]</h5><h5 id="chunk-size-int-單個文件段落的長度"><a href="#chunk-size-int-單個文件段落的長度" class="headerlink" title="chunk_size: int 單個文件段落的長度"></a>chunk_size: int 單個文件段落的長度</h5><h5 id="temperature-float-語言模型的變化度-0-1"><a href="#temperature-float-語言模型的變化度-0-1" class="headerlink" title="temperature: float 語言模型的變化度(0~1)"></a>temperature: float 語言模型的變化度(0~1)</h5><h5 id="system-prompt-str-指示給語言模型的output格式需求"><a href="#system-prompt-str-指示給語言模型的output格式需求" class="headerlink" title="system_prompt: str 指示給語言模型的output格式需求"></a>system_prompt: str 指示給語言模型的output格式需求</h5><h4 id="stream-bool-如果設為True，會回傳generator"><a href="#stream-bool-如果設為True，會回傳generator" class="headerlink" title="stream: bool 如果設為True，會回傳generator"></a>stream: bool 如果設為True，會回傳generator</h4><h4 id="max-input-tokens-int-單次輸入模型的最大token數"><a href="#max-input-tokens-int-單次輸入模型的最大token數" class="headerlink" title="max_input_tokens: int 單次輸入模型的最大token數"></a>max_input_tokens: int 單次輸入模型的最大token數</h4><h4 id="max-output-tokens-int-模型輸出的最大token數"><a href="#max-output-tokens-int-模型輸出的最大token數" class="headerlink" title="max_output_tokens: int 模型輸出的最大token數"></a>max_output_tokens: int 模型輸出的最大token數</h4><h4 id="env-file-str-指定-env環境設定檔名"><a href="#env-file-str-指定-env環境設定檔名" class="headerlink" title="env_file:str  指定.env環境設定檔名"></a>env_file:str  指定.env環境設定檔名</h4><h4 id="keep-logs-bool-是否保存執行過程和結果"><a href="#keep-logs-bool-是否保存執行過程和結果" class="headerlink" title="keep_logs: bool 是否保存執行過程和結果"></a>keep_logs: bool 是否保存執行過程和結果</h4><h3 id="call-參數"><a href="#call-參數" class="headerlink" title="call 參數"></a><strong>call</strong> 參數</h3><h5 id="doc-source-Union-List-Union-str-Path-Path-str-dbs-一個或多個包含文件檔案的資料夾路徑名稱、網址，或單一個dbs物件"><a href="#doc-source-Union-List-Union-str-Path-Path-str-dbs-一個或多個包含文件檔案的資料夾路徑名稱、網址，或單一個dbs物件" class="headerlink" title="doc_source: Union[List[Union[str, Path]], Path, str, dbs] 一個或多個包含文件檔案的資料夾路徑名稱、網址，或單一個dbs物件"></a>doc_source: Union[List[Union[str, Path]], Path, str, dbs] 一個或多個包含文件檔案的資料夾路徑名稱、網址，或單一個dbs物件</h5><h5 id="prompt-str-使用者的問題"><a href="#prompt-str-使用者的問題" class="headerlink" title="prompt: str 使用者的問題"></a>prompt: str 使用者的問題</h5><h4 id="history-messages-List-str-需要一併提供給語言模型的對話紀錄"><a href="#history-messages-List-str-需要一併提供給語言模型的對話紀錄" class="headerlink" title="history_messages: List[str] 需要一併提供給語言模型的對話紀錄"></a>history_messages: List[str] 需要一併提供給語言模型的對話紀錄</h4><h3 id="stream輸出"><a href="#stream輸出" class="headerlink" title="stream輸出"></a>stream輸出</h3><p>若需要即時輸出的場合(如UI即時顯示回答)，使用stream&#x3D;True可使RAG回傳generator。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.RAG(</span><br><span class="line">    embeddings=&quot;openai:text-embedding-3-small&quot;,</span><br><span class="line">    model=&quot;openai:gpt-4o&quot;,</span><br><span class="line">    max_input_tokens=3000,</span><br><span class="line">    keep_logs=True,</span><br><span class="line">    verbose=True,</span><br><span class="line">    stream=True</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">streaming = ak(</span><br><span class="line">    data_source=[&quot;docs/mic&quot;, &quot;https://github.com/iii-org/akasha&quot;],</span><br><span class="line">    prompt=&quot;akasha是甚麼?&quot;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">for s in streaming:</span><br><span class="line">    print(s)</span><br></pre></td></tr></table></figure>


<h2 id="dbs物件"><a href="#dbs物件" class="headerlink" title="dbs物件"></a>dbs物件</h2><p>如想對同個文件集做多次問答，可以先建立dbs物件並傳入，避免多次重複載入文件的chromadb，若文件內容、使用嵌入模型、chunk size相等的chromadb已存在，則不會重新創建而直接讀取。</p>
<p>創建chromadb可使用 <em><strong>process_db</strong></em></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line">import akasha.utils.db as adb</span><br><span class="line">db_files = adb.process_db(data_source = [&quot;docs/mic&quot;], embeddings=&quot;openai:text-embedding-ada-002&quot;,chunk_size=500)</span><br><span class="line"></span><br><span class="line">qa = akasha.RAG(</span><br><span class="line">    verbose=True, </span><br><span class="line">    search_type=&quot;knn&quot;,</span><br><span class="line">    embeddings=&quot;openai:text-embedding-ada-002&quot;,</span><br><span class="line">    chunk_size=500, </span><br><span class="line">    model=&quot;openai:gpt-3.5-turbo&quot;, </span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">qa(</span><br><span class="line">    doc_path=db_files,</span><br><span class="line">    prompt=&quot;五軸是甚麼?&quot;,</span><br><span class="line">    system_prompt=&quot;請用中文回答&quot;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


</br>
</br>


<h2 id="RAG-輸出"><a href="#RAG-輸出" class="headerlink" title="RAG 輸出"></a>RAG 輸出</h2><p>使用完RAG的函式後，物件內部會儲存用來搜尋的db(self.db)、讓語言模型參考的文件(self.docs)、使用者的問題(self.prompt)和回答(self.response)等資訊，若需要更完整的資訊可參考<a href="/2024/12/26/%E8%BC%94%E5%8A%A9%E5%87%BD%E6%95%B8/">輔助函數</a>中的 <em><strong>儲存紀錄</strong></em></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.RAG(</span><br><span class="line">    embeddings=&quot;openai:text-embedding-3-small&quot;,</span><br><span class="line">    model=&quot;openai:gpt-4o&quot;,</span><br><span class="line">    max_input_tokens=3000,</span><br><span class="line">    keep_logs=True,</span><br><span class="line">    verbose=True,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">response = ak(</span><br><span class="line">    data_source=[&quot;docs/mic&quot;, &quot;https://github.com/iii-org/akasha&quot;],</span><br><span class="line">    prompt=&quot;akasha是甚麼?&quot;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">## self.db (dbs class) ##</span><br><span class="line">print(len(ak.db.ids), ak.db.metadatas[0])</span><br><span class="line"></span><br><span class="line">## self.docs (list of Documents) ##</span><br><span class="line">print(ak.docs[0])</span><br><span class="line"></span><br><span class="line">## self.doc_tokens (integer, length of document tokens) ##</span><br><span class="line">print(ak.prompt_tokens, ak.doc_tokens)</span><br><span class="line"></span><br><span class="line">print(ak.prompt, ak.response)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>

<h2 id="selfask-RAG"><a href="#selfask-RAG" class="headerlink" title="selfask_RAG"></a>selfask_RAG</h2><p>selfask_RAG會先將使用者問題嘗試使用語言模型進行拆分，再進行RAG回答問題，對於需要多個知識點的問題可能會獲得較好的結果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import akasha</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ak = akasha.RAG(</span><br><span class="line">    embeddings=&quot;openai:text-embedding-3-small&quot;,</span><br><span class="line">    model=&quot;openai:gpt-4o&quot;,</span><br><span class="line">    max_input_tokens=DEFAULT_MAX_INPUT_TOKENS,</span><br><span class="line">    keep_logs=True,</span><br><span class="line">    verbose=True,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">res = ak.selfask_RAG(data_source=[&quot;docs/mic&quot;],</span><br><span class="line">    prompt=&quot;LPWAN和5G的區別是什麼?&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="相關連結"><a href="#相關連結" class="headerlink" title="相關連結"></a>相關連結</h3><p>self.db的詳細資訊可參考<a href="/akasha/2024/12/26/%E5%90%91%E9%87%8F%E8%B3%87%E6%96%99%E5%BA%AB/">向量資料庫</a><br>self.docs的詳細資訊可參考<a href="/akasha/2024/12/26/%E6%96%87%E4%BB%B6%E6%90%9C%E5%B0%8B/">文件搜尋</a><br>self.model_obj的詳細資訊可參考<a href="/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B/">設定語言模型</a><br>self.embeddings_obj的詳細資訊可參考<a href="/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/">設定嵌入模型</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/29/ask/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/29/ask/" class="post-title-link" itemprop="url">ask</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-29 22:59:59" itemprop="dateCreated datePublished" datetime="2024-12-29T22:59:59+08:00">2024-12-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2025-05-06 14:22:35" itemprop="dateModified" datetime="2025-05-06T14:22:35+08:00">2025-05-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E5%8A%9F%E8%83%BD/" itemprop="url" rel="index"><span itemprop="name">功能</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="ask"><a href="#ask" class="headerlink" title="ask"></a>ask</h2><p>如果你不想使用文件檔案，希望直接輸入文件內容，你可以使用ask物件，使用 <em><strong>info</strong></em> 參數將文件的內容傳給語言模型，<em><strong>info</strong></em>參數可輸入的內容為純文字、文件檔案名、文件資料夾名、網址，ask物件會讀取所有文件和純文字內容，並使用所有文件進行回答，因此若使用過多文件或文件內容過多，將花費大量時間與token。<br>若 <em><strong>info</strong></em>中的單一字串長度大於語言模型上限，該字串會強制被自行切割成 <em><strong>list of str</strong></em>，因此建議若文字過多，請自行分段成 <em><strong>list of str</strong></em></p>
<p>若 <em><strong>info</strong></em>中的總文字內容過多，文件內容會被分別提供給語言模型作回答，並最終整合成一個最終回答，因此可能會花費較久時間。<br>詢問完問題後，若有keep_logs參數，可選擇儲存成json檔案</p>
<h3 id="ask範例"><a href="#ask範例" class="headerlink" title="ask範例"></a>ask範例</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.ask(</span><br><span class="line">    model=&quot;openai:gpt-4o&quot;, max_input_tokens=8000, keep_logs=True, verbose=True</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">res = ak(</span><br><span class="line">    prompt=&quot;akasha是甚麼?&quot;,</span><br><span class="line">    info=[&quot;https://github.com/iii-org/akasha&quot;],</span><br><span class="line">)</span><br><span class="line">ak.save_logs(&quot;logs_ask.json&quot;)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="ask-參數"><a href="#ask-參數" class="headerlink" title="ask 參數"></a>ask 參數</h3><h5 id="verbose-bool-如果設True，會顯示每個步驟產生的文字和狀態"><a href="#verbose-bool-如果設True，會顯示每個步驟產生的文字和狀態" class="headerlink" title="verbose: bool 如果設True，會顯示每個步驟產生的文字和狀態"></a>verbose: bool 如果設True，會顯示每個步驟產生的文字和狀態</h5><h5 id="model-Union-str-BaseLanguageModel-使用的語言模型，如-openai-gpt-3-5-turbo-gemini-gemini-1-5-flash"><a href="#model-Union-str-BaseLanguageModel-使用的語言模型，如-openai-gpt-3-5-turbo-gemini-gemini-1-5-flash" class="headerlink" title="model: Union[str, BaseLanguageModel] 使用的語言模型，如 openai:gpt-3.5-turbo, gemini:gemini-1.5-flash"></a>model: Union[str, BaseLanguageModel] 使用的語言模型，如 <em><strong>openai:gpt-3.5-turbo</strong></em>, <em><strong>gemini:gemini-1.5-flash</strong></em></h5><h5 id="temperature-float-語言模型的變化度-0-1"><a href="#temperature-float-語言模型的變化度-0-1" class="headerlink" title="temperature: float 語言模型的變化度(0~1)"></a>temperature: float 語言模型的變化度(0~1)</h5><h5 id="system-prompt-str-指示給語言模型的output格式需求"><a href="#system-prompt-str-指示給語言模型的output格式需求" class="headerlink" title="system_prompt: str 指示給語言模型的output格式需求"></a>system_prompt: str 指示給語言模型的output格式需求</h5><h4 id="stream-bool-如果設為True，會回傳generator"><a href="#stream-bool-如果設為True，會回傳generator" class="headerlink" title="stream: bool 如果設為True，會回傳generator"></a>stream: bool 如果設為True，會回傳generator</h4><h4 id="max-input-tokens-int-單次輸入模型的最大token數"><a href="#max-input-tokens-int-單次輸入模型的最大token數" class="headerlink" title="max_input_tokens: int 單次輸入模型的最大token數"></a>max_input_tokens: int 單次輸入模型的最大token數</h4><h4 id="max-output-tokens-int-模型輸出的最大token數"><a href="#max-output-tokens-int-模型輸出的最大token數" class="headerlink" title="max_output_tokens: int 模型輸出的最大token數"></a>max_output_tokens: int 模型輸出的最大token數</h4><h4 id="env-file-str-指定-env環境設定檔名"><a href="#env-file-str-指定-env環境設定檔名" class="headerlink" title="env_file:str  指定.env環境設定檔名"></a>env_file:str  指定.env環境設定檔名</h4><h4 id="keep-logs-bool-是否保存執行過程和結果"><a href="#keep-logs-bool-是否保存執行過程和結果" class="headerlink" title="keep_logs: bool 是否保存執行過程和結果"></a>keep_logs: bool 是否保存執行過程和結果</h4><h3 id="call-參數"><a href="#call-參數" class="headerlink" title="call 參數"></a><strong>call</strong> 參數</h3><h5 id="info-Union-str-list-Path-Document-一個或多個包含文件檔案的資料夾路徑名稱、文件名稱、網址、純文字"><a href="#info-Union-str-list-Path-Document-一個或多個包含文件檔案的資料夾路徑名稱、文件名稱、網址、純文字" class="headerlink" title="info: Union[str, list, Path, Document] 一個或多個包含文件檔案的資料夾路徑名稱、文件名稱、網址、純文字"></a>info: Union[str, list, Path, Document] 一個或多個包含文件檔案的資料夾路徑名稱、文件名稱、網址、純文字</h5><h5 id="prompt-str-使用者的問題"><a href="#prompt-str-使用者的問題" class="headerlink" title="prompt: str 使用者的問題"></a>prompt: str 使用者的問題</h5><h4 id="history-messages-List-str-需要一併提供給語言模型的對話紀錄"><a href="#history-messages-List-str-需要一併提供給語言模型的對話紀錄" class="headerlink" title="history_messages: List[str] 需要一併提供給語言模型的對話紀錄"></a>history_messages: List[str] 需要一併提供給語言模型的對話紀錄</h4></br>
</br>


<h2 id="vision"><a href="#vision" class="headerlink" title="vision"></a>vision</h2><p>有些語言模型可以輸入圖片進行辨識，使用函式vision便可傳入圖片給語言模型。<br>參數 <em><strong>image_path</strong></em> 可為圖片的本機路徑或網址，也可以使用list傳入多張圖片</p>
<h3 id="vision範例"><a href="#vision範例" class="headerlink" title="vision範例"></a>vision範例</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line">ak = akasha.ask(</span><br><span class="line">    model=&quot;openai:gpt-4o&quot;, max_input_tokens=8000, keep_logs=True, verbose=True</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">res = ak.vision(</span><br><span class="line">    prompt=&quot;這張圖片是什麼?&quot;,</span><br><span class="line">    image_path=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg&quot;,</span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="vision-參數"><a href="#vision-參數" class="headerlink" title="vision 參數"></a>vision 參數</h3><h5 id="image-path-Union-List-str-str-圖片的本機路徑或網址，也可以使用list傳入多張圖片"><a href="#image-path-Union-List-str-str-圖片的本機路徑或網址，也可以使用list傳入多張圖片" class="headerlink" title="image_path: Union[List[str], str] 圖片的本機路徑或網址，也可以使用list傳入多張圖片"></a>image_path: Union[List[str], str] 圖片的本機路徑或網址，也可以使用list傳入多張圖片</h5><h5 id="prompt-str-使用者的問題-1"><a href="#prompt-str-使用者的問題-1" class="headerlink" title="prompt: str 使用者的問題"></a>prompt: str 使用者的問題</h5></br>
</br>

<h3 id="相關連結"><a href="#相關連結" class="headerlink" title="相關連結"></a>相關連結</h3><p>self.docs的詳細資訊可參考<a href="/akasha/2024/12/26/%E6%96%87%E4%BB%B6%E6%90%9C%E5%B0%8B/">文件搜尋</a><br>self.model_obj的詳細資訊可參考<a href="/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B/">設定語言模型</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/28/eval/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/28/eval/" class="post-title-link" itemprop="url">eval</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-28 20:59:59" itemprop="dateCreated datePublished" datetime="2024-12-28T20:59:59+08:00">2024-12-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2025-05-02 14:40:29" itemprop="dateModified" datetime="2025-05-02T14:40:29+08:00">2025-05-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E5%8A%9F%E8%83%BD/" itemprop="url" rel="index"><span itemprop="name">功能</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="eval"><a href="#eval" class="headerlink" title="eval"></a>eval</h2><p><code>eval</code> 是一個用於生成問題集並評估語言模型表現的class。它可以根據提供的資料來源自動生成問題集，並使用語言模型回答問題，最後根據答案的正確性或相似性進行評估。<code>eval</code> 支援多種問題類型與格式，並提供詳細的日誌記錄功能。</p>
<h3 id="eval-功能"><a href="#eval-功能" class="headerlink" title="eval 功能"></a>eval 功能</h3><ol>
<li><strong>生成問題集</strong>：根據提供的資料來源，生成指定數量的問題與答案。</li>
<li><strong>生成特定主題的問題集</strong>：根據主題篩選相關文件，生成與主題相關的問題集。</li>
<li><strong>評估模型表現</strong>：使用生成的問題集評估語言模型的回答表現，並計算分數（如 Bert Score、Rouge-L 或正確率）。</li>
<li><strong>日誌保存</strong>：支持保存執行過程與結果的日誌，便於後續分析。</li>
</ol>
<hr>
<h3 id="使用question-type測試不同方面的能力"><a href="#使用question-type測試不同方面的能力" class="headerlink" title="使用question_type測試不同方面的能力"></a>使用question_type測試不同方面的能力</h3><p>question_type 参数提供了四種問題類型：<em><strong>fact</strong></em>、<em><strong>summary</strong></em>、<em><strong>irrelevant</strong></em>、<em><strong>compared</strong></em>，預設是 fact。 </p>
<ol>
<li>fact測試回答一般事實的能力</li>
<li>summary測試模型做摘要的能力</li>
<li>irrelevant測試模型能否分辨文件中不存在答案的問題</li>
<li>compared測試模型比較不同事物的能力</li>
</ol>
<hr>
<h3 id="eval-範例"><a href="#eval-範例" class="headerlink" title="eval 範例"></a>eval 範例</h3><h4 id="生成問題集"><a href="#生成問題集" class="headerlink" title="生成問題集"></a>生成問題集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"></span><br><span class="line">ev = akasha.<span class="built_in">eval</span>(</span><br><span class="line">    model=<span class="string">&quot;openai:gpt-4o&quot;</span>,</span><br><span class="line">    question_type=<span class="string">&quot;fact&quot;</span>,</span><br><span class="line">    question_style=<span class="string">&quot;essay&quot;</span>,</span><br><span class="line">    keep_logs=<span class="literal">True</span>,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成問題集</span></span><br><span class="line">questions, answers = ev.create_questionset(</span><br><span class="line">    data_source=[<span class="string">&quot;docs/mic&quot;</span>], question_num=<span class="number">3</span>, choice_num=<span class="number">4</span>, output_file_path=<span class="string">&quot;cq3.json&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存日誌</span></span><br><span class="line">ev.save_logs(<span class="string">&quot;log_cq.json&quot;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="生成特定主題的問題集"><a href="#生成特定主題的問題集" class="headerlink" title="生成特定主題的問題集"></a>生成特定主題的問題集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成與主題相關的問題集</span></span><br><span class="line">questions, answers = ev.create_topic_questionset(</span><br><span class="line">    data_source=[<span class="string">&quot;docs/mic&quot;</span>],</span><br><span class="line">    topic=<span class="string">&quot;工業 4.0&quot;</span>,</span><br><span class="line">    question_num=<span class="number">3</span>,</span><br><span class="line">    choice_num=<span class="number">4</span>,</span><br><span class="line">    output_file_path=<span class="string">&quot;4-0topic.json&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h4 id="生成問題集格式"><a href="#生成問題集格式" class="headerlink" title="生成問題集格式"></a>生成問題集格式</h4><p>利用create_questionset生成的問題集為JSON格式，並包含 <em><strong>question</strong></em> 和 <em><strong>answer</strong></em> list 代表問題與參考答案。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;question_style&quot;</span><span class="punctuation">:</span> <span class="string">&quot;essay&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;question_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;fact&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;question&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="string">&quot;根據文件xxx，富士康深圳園區的龍華工廠在2019年首次被選為全球燈塔工廠，該工廠在智慧製造方面實現了哪些具體成效？\n\n&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;根據文件xxx，在工業 4.0的發展階段中，「視覺化」階段如何透過資料整合與應用來提升工廠運作效率？請說明其具體實現方式與可能的應用範例。\n\n&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;根據文件xxx，在工業4.0的推行過程中，企業應如何平衡智慧化方案的佈局與長期戰略規劃，以避免因資訊系統框架限制而導致資源重複投入？\n\n&quot;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;answer&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="string">&quot;富士康深圳園區的龍華工廠在2019年首次被選為全球燈塔工廠....&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;「視覺化」階段透過感測器和機械裝置的引數讀取，整合各產線作業資料，將工廠流程數...&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;企業在推行工業4.0時，需根據作業難度、流程需求及業務特性調...&quot;</span></span><br><span class="line">        </span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="評估模型表現"><a href="#評估模型表現" class="headerlink" title="評估模型表現"></a>評估模型表現</h3><p>若 <em><strong>question_style</strong></em> 為 <code>&quot;single_choice&quot;</code>（選擇題），evalution結果為正確率， 若為 <code>&quot;essay&quot;</code>（問答題），結果為 <em><strong>bert score</strong></em>,<br> <em><strong>rouge score</strong></em> 和 ***llm score *** 的分數，皆介於0~1之間</p>
<h5 id="bert-score"><a href="#bert-score" class="headerlink" title="bert-score"></a>bert-score</h5><p>使用bert-score套件計算回答與參考答案的每個token之間的contextual embeddings similarity.</p>
<h5 id="ROUGE-score"><a href="#ROUGE-score" class="headerlink" title="ROUGE-score"></a>ROUGE-score</h5><p>將語言模型的回答與問答題文件中的參考答案進行分詞後，藉由ROUGE 評估生成相似度分數</p>
<h5 id="llm-score"><a href="#llm-score" class="headerlink" title="llm-score"></a>llm-score</h5><p>利用另一種語言模型，將語言模型的回答與問答題文件中的參考答案進行比較，生成相似度分數，可以使用參數 <em><strong>eval_model</strong></em> 指定使用作為評判的語言模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用生成的問題集評估模型表現</span></span><br><span class="line">result = ev.evaluation(</span><br><span class="line">    questionset_file=<span class="string">&quot;cq3.json&quot;</span>,</span><br><span class="line">    data_source=[<span class="string">&quot;docs/mic&quot;</span>],</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="eval-參數"><a href="#eval-參數" class="headerlink" title="eval 參數"></a>eval 參數</h3><h4 id="初始化參數"><a href="#初始化參數" class="headerlink" title="初始化參數"></a>初始化參數</h4><h5 id="model-Union-str-BaseLanguageModel"><a href="#model-Union-str-BaseLanguageModel" class="headerlink" title="model: Union[str, BaseLanguageModel]"></a>model: Union[str, BaseLanguageModel]</h5><p>使用的語言模型，例如 <code>&quot;openai:gpt-4o&quot;</code> 或 <code>&quot;openai:gpt-3.5-turbo&quot;</code>。</p>
<h5 id="question-type-str"><a href="#question-type-str" class="headerlink" title="question_type: str"></a>question_type: str</h5><p>問題類型，包括 <code>&quot;fact&quot;</code>（事實型）、<code>&quot;irrelevant&quot;</code>（無關型）、<code>&quot;summary&quot;</code>（摘要型）、<code>&quot;compared&quot;</code>（比較型）。</p>
<h5 id="question-style-str"><a href="#question-style-str" class="headerlink" title="question_style: str"></a>question_style: str</h5><p>問題格式，包括 <code>&quot;essay&quot;</code>（問答題）或 <code>&quot;single_choice&quot;</code>（選擇題）。</p>
<h5 id="keep-logs-bool"><a href="#keep-logs-bool" class="headerlink" title="keep_logs: bool"></a>keep_logs: bool</h5><p>是否保存執行過程與結果的日誌。</p>
<h5 id="verbose-bool"><a href="#verbose-bool" class="headerlink" title="verbose: bool"></a>verbose: bool</h5><p>是否顯示詳細的執行過程。</p>
<h5 id="max-input-tokens-int"><a href="#max-input-tokens-int" class="headerlink" title="max_input_tokens: int"></a>max_input_tokens: int</h5><p>單次輸入模型的最大 token 數。</p>
<h5 id="max-output-tokens-int"><a href="#max-output-tokens-int" class="headerlink" title="max_output_tokens: int"></a>max_output_tokens: int</h5><p>模型輸出的最大 token 數。</p>
<h5 id="temperature-float"><a href="#temperature-float" class="headerlink" title="temperature: float"></a>temperature: float</h5><p>語言模型的隨機性參數，範圍為 0.0 到 1.0。</p>
<h5 id="system-prompt-str"><a href="#system-prompt-str" class="headerlink" title="system_prompt: str"></a>system_prompt: str</h5><p>指示語言模型的輸出格式需求。</p>
<hr>
<h3 id="create-questionset-參數"><a href="#create-questionset-參數" class="headerlink" title="create_questionset 參數"></a>create_questionset 參數</h3><h5 id="data-source-Union-List-Union-str-Path-Path-str-dbs"><a href="#data-source-Union-List-Union-str-Path-Path-str-dbs" class="headerlink" title="data_source: Union[List[Union[str, Path]], Path, str, dbs]"></a>data_source: Union[List[Union[str, Path]], Path, str, dbs]</h5><p>資料來源，可以是文件目錄、文件路徑或資料庫。</p>
<h5 id="question-num-int"><a href="#question-num-int" class="headerlink" title="question_num: int"></a>question_num: int</h5><p>生成的問題數量。</p>
<h5 id="choice-num-int"><a href="#choice-num-int" class="headerlink" title="choice_num: int"></a>choice_num: int</h5><p>選擇題的選項數量（僅在 <code>question_style=&quot;single_choice&quot;</code> 時有效）。</p>
<h5 id="output-file-path-str"><a href="#output-file-path-str" class="headerlink" title="output_file_path: str"></a>output_file_path: str</h5><p>輸出問題集的文件路徑。</p>
<hr>
<h3 id="create-topic-questionset-參數"><a href="#create-topic-questionset-參數" class="headerlink" title="create_topic_questionset 參數"></a>create_topic_questionset 參數</h3><h5 id="data-source-Union-List-str-str"><a href="#data-source-Union-List-str-str" class="headerlink" title="data_source: Union[List[str], str]"></a>data_source: Union[List[str], str]</h5><p>資料來源，可以是文件目錄或文件路徑。</p>
<h5 id="topic-str"><a href="#topic-str" class="headerlink" title="topic: str"></a>topic: str</h5><p>生成問題集的主題。</p>
<h5 id="question-num-int-1"><a href="#question-num-int-1" class="headerlink" title="question_num: int"></a>question_num: int</h5><p>生成的問題數量。</p>
<h5 id="choice-num-int-1"><a href="#choice-num-int-1" class="headerlink" title="choice_num: int"></a>choice_num: int</h5><p>選擇題的選項數量（僅在 <code>question_style=&quot;single_choice&quot;</code> 時有效）。</p>
<h5 id="output-file-path-str-1"><a href="#output-file-path-str-1" class="headerlink" title="output_file_path: str"></a>output_file_path: str</h5><p>輸出問題集的文件路徑。</p>
<hr>
<h3 id="evaluation-參數"><a href="#evaluation-參數" class="headerlink" title="evaluation 參數"></a>evaluation 參數</h3><h5 id="questionset-file-str"><a href="#questionset-file-str" class="headerlink" title="questionset_file: str"></a>questionset_file: str</h5><p>問題集文件的路徑，(.json) 格式。</p>
<h5 id="data-source-Union-List-Union-str-Path-Path-str-dbs-1"><a href="#data-source-Union-List-Union-str-Path-Path-str-dbs-1" class="headerlink" title="data_source: Union[List[Union[str, Path]], Path, str, dbs]"></a>data_source: Union[List[Union[str, Path]], Path, str, dbs]</h5><p>一個或多個包含文件檔案的資料夾路徑名稱、網址，或單一個dbs物件</p>
<h5 id="eval-model-Union-BaseLanguageModel-str"><a href="#eval-model-Union-BaseLanguageModel-str" class="headerlink" title="eval_model: Union[BaseLanguageModel, str]"></a>eval_model: Union[BaseLanguageModel, str]</h5><p>用於評估的語言模型，默認為初始化時的模型。</p>
<hr>
<h3 id="日誌與結果"><a href="#日誌與結果" class="headerlink" title="日誌與結果"></a>日誌與結果</h3><ul>
<li>問題集生成過程與結果會保存到指定的日誌文件中。</li>
<li>評估結果包括 Bert Score、Rouge-L 分數或正確率，具體取決於問題的格式。</li>
</ul>
<hr>
<h3 id="相關連結"><a href="#相關連結" class="headerlink" title="相關連結"></a>相關連結</h3><p>self.db的詳細資訊可參考<a href="/akasha/2024/12/26/%E5%90%91%E9%87%8F%E8%B3%87%E6%96%99%E5%BA%AB/">向量資料庫</a><br>self.docs的詳細資訊可參考<a href="/akasha/2024/12/26/%E6%96%87%E4%BB%B6%E6%90%9C%E5%B0%8B/">文件搜尋</a><br>self.model_obj的詳細資訊可參考<a href="/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B/">設定語言模型</a><br>self.embeddings_obj的詳細資訊可參考<a href="/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/">設定嵌入模型</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/27/summary/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/27/summary/" class="post-title-link" itemprop="url">summary</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-27 23:59:59" itemprop="dateCreated datePublished" datetime="2024-12-27T23:59:59+08:00">2024-12-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2025-04-22 11:31:28" itemprop="dateModified" datetime="2025-04-22T11:31:28+08:00">2025-04-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E5%8A%9F%E8%83%BD/" itemprop="url" rel="index"><span itemprop="name">功能</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h2><p><code>summary</code> 是一個用於總結文件內容的class，支援多種摘要方法（如 <code>map_reduce</code> 和 <code>refine</code>），可以處理多種格式的文件（如 <code>.txt</code>, <code>.docx</code>, <code>.pdf</code>, <code>.md</code>, <code>.csv</code>, <code>.pptx</code>），並將內容分塊後進行摘要，最終合併成一個完整的摘要。</p>
<h3 id="summary-功能"><a href="#summary-功能" class="headerlink" title="summary 功能"></a>summary 功能</h3><ol>
<li><strong>多種摘要方法</strong>：<ul>
<li><code>map_reduce</code>：將內容分塊後分別摘要，最後合併成完整摘要，速度較快，適合大規模內容。</li>
<li><code>refine</code>：逐塊摘要並使用前一塊的摘要作為提示，摘要一致性較高，但速度較慢。</li>
</ul>
</li>
<li><strong>支援多種輸入格式</strong>：可處理本地文件、目錄、網址或純文字內容。</li>
<li><strong>日誌保存</strong>：支持保存執行過程與結果的日誌，便於後續分析。</li>
</ol>
<hr>
<h3 id="summary-範例"><a href="#summary-範例" class="headerlink" title="summary 範例"></a>summary 範例</h3><h4 id="使用-map-reduce-方法進行摘要"><a href="#使用-map-reduce-方法進行摘要" class="headerlink" title="使用 map_reduce 方法進行摘要"></a>使用 <code>map_reduce</code> 方法進行摘要</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"></span><br><span class="line">summ = akasha.summary(</span><br><span class="line">    model=<span class="string">&quot;openai:gpt-4o&quot;</span>,</span><br><span class="line">    sum_type=<span class="string">&quot;map_reduce&quot;</span>,</span><br><span class="line">    chunk_size=<span class="number">1000</span>,</span><br><span class="line">    sum_len=<span class="number">1000</span>,</span><br><span class="line">    language=<span class="string">&quot;en&quot;</span>,</span><br><span class="line">    keep_logs=<span class="literal">True</span>,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">    max_input_tokens=<span class="number">8000</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 總結內容，來源可以是網址、文件或純文字</span></span><br><span class="line">ret = summ(content=[<span class="string">&quot;https://github.com/iii-org/akasha&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存日誌</span></span><br><span class="line">summ.save_logs(<span class="string">&quot;sumlog.json&quot;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="使用-refine-方法進行摘要"><a href="#使用-refine-方法進行摘要" class="headerlink" title="使用 refine 方法進行摘要"></a>使用 <code>refine</code> 方法進行摘要</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">summ = akasha.summary(</span><br><span class="line">    model=<span class="string">&quot;openai:gpt-4o&quot;</span>,</span><br><span class="line">    sum_type=<span class="string">&quot;refine&quot;</span>,</span><br><span class="line">    chunk_size=<span class="number">1000</span>,</span><br><span class="line">    sum_len=<span class="number">500</span>,</span><br><span class="line">    language=<span class="string">&quot;zh&quot;</span>,</span><br><span class="line">    keep_logs=<span class="literal">True</span>,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">    max_input_tokens=<span class="number">8000</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 總結內容，來源可以是本地文件或目錄</span></span><br><span class="line">ret = summ(content=[<span class="string">&quot;docs/example.txt&quot;</span>, <span class="string">&quot;docs/reports/&quot;</span>])</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="summary-參數"><a href="#summary-參數" class="headerlink" title="summary 參數"></a>summary 參數</h3><h4 id="初始化參數"><a href="#初始化參數" class="headerlink" title="初始化參數"></a>初始化參數</h4><h5 id="model-str"><a href="#model-str" class="headerlink" title="model: str"></a>model: str</h5><p>使用的語言模型，例如 <code>&quot;openai:gpt-4o&quot;</code> 或 <code>&quot;openai:gpt-3.5-turbo&quot;</code>。</p>
<h5 id="sum-type-str"><a href="#sum-type-str" class="headerlink" title="sum_type: str"></a>sum_type: str</h5><p>摘要方法，支持：</p>
<ul>
<li><code>&quot;map_reduce&quot;</code>：分塊摘要後合併，速度較快。</li>
<li><code>&quot;refine&quot;</code>：逐塊摘要並使用前一塊的摘要作為提示，摘要一致性較高。</li>
</ul>
<h5 id="sum-len-int"><a href="#sum-len-int" class="headerlink" title="sum_len: int"></a>sum_len: int</h5><p>建議的摘要長度（以字數或 token 數計）。</p>
<h5 id="chunk-size-int"><a href="#chunk-size-int" class="headerlink" title="chunk_size: int"></a>chunk_size: int</h5><p>分塊大小，單位為字數或 token。</p>
<h5 id="chunk-overlap-int"><a href="#chunk-overlap-int" class="headerlink" title="chunk_overlap: int"></a>chunk_overlap: int</h5><p>分塊重疊大小，單位為字數或 token。</p>
<h5 id="max-input-tokens-int"><a href="#max-input-tokens-int" class="headerlink" title="max_input_tokens: int"></a>max_input_tokens: int</h5><p>單次輸入模型的最大 token 數。</p>
<h5 id="max-output-tokens-int"><a href="#max-output-tokens-int" class="headerlink" title="max_output_tokens: int"></a>max_output_tokens: int</h5><p>模型輸出的最大 token 數。</p>
<h5 id="language-str"><a href="#language-str" class="headerlink" title="language: str"></a>language: str</h5><p>內容的語言，支持 <code>&quot;en&quot;</code>（英文）和 <code>&quot;zh&quot;</code>（中文）。</p>
<h5 id="keep-logs-bool"><a href="#keep-logs-bool" class="headerlink" title="keep_logs: bool"></a>keep_logs: bool</h5><p>是否保存執行過程與結果的日誌。</p>
<h5 id="verbose-bool"><a href="#verbose-bool" class="headerlink" title="verbose: bool"></a>verbose: bool</h5><p>是否顯示詳細的執行過程。</p>
<h5 id="temperature-float"><a href="#temperature-float" class="headerlink" title="temperature: float"></a>temperature: float</h5><p>語言模型的隨機性參數，範圍為 0.0 到 1.0。</p>
<h5 id="system-prompt-str"><a href="#system-prompt-str" class="headerlink" title="system_prompt: str"></a>system_prompt: str</h5><p>指示語言模型的輸出格式需求。</p>
<hr>
<h3 id="call-參數"><a href="#call-參數" class="headerlink" title="call 參數"></a><strong>call</strong> 參數</h3><h5 id="content-Union-str-list-Path-Document"><a href="#content-Union-str-list-Path-Document" class="headerlink" title="content: Union[str, list, Path, Document]"></a>content: Union[str, list, Path, Document]</h5><p>需要總結的內容，可以是：</p>
<ul>
<li>單個或多個文件路徑（如 <code>.txt</code>, <code>.docx</code>, <code>.pdf</code>）。</li>
<li>單個或多個網址。</li>
<li>單個或多個純文字內容。</li>
</ul>
<h5 id="sum-type-str-1"><a href="#sum-type-str-1" class="headerlink" title="sum_type: str"></a>sum_type: str</h5><p>摘要方法，支持 <code>&quot;map_reduce&quot;</code> 或 <code>&quot;refine&quot;</code>。</p>
<h5 id="sum-len-int-1"><a href="#sum-len-int-1" class="headerlink" title="sum_len: int"></a>sum_len: int</h5><p>建議的摘要長度。</p>
<h5 id="chunk-size-int-1"><a href="#chunk-size-int-1" class="headerlink" title="chunk_size: int"></a>chunk_size: int</h5><p>分塊大小。</p>
<h5 id="chunk-overlap-int-1"><a href="#chunk-overlap-int-1" class="headerlink" title="chunk_overlap: int"></a>chunk_overlap: int</h5><p>分塊重疊大小。</p>
<h5 id="max-input-tokens-int-1"><a href="#max-input-tokens-int-1" class="headerlink" title="max_input_tokens: int"></a>max_input_tokens: int</h5><p>單次輸入模型的最大 token 數。</p>
<h5 id="max-output-tokens-int-1"><a href="#max-output-tokens-int-1" class="headerlink" title="max_output_tokens: int"></a>max_output_tokens: int</h5><p>模型輸出的最大 token 數。</p>
<h5 id="temperature-float-1"><a href="#temperature-float-1" class="headerlink" title="temperature: float"></a>temperature: float</h5><p>語言模型的隨機性參數。</p>
<hr>
<h3 id="日誌與結果"><a href="#日誌與結果" class="headerlink" title="日誌與結果"></a>日誌與結果</h3><ul>
<li>總結過程與結果會保存到指定的日誌文件中。</li>
<li>日誌包括摘要的詳細過程、分塊信息、模型輸入輸出 token 數等。</li>
</ul>
<hr>
<h3 id="相關連結"><a href="#相關連結" class="headerlink" title="相關連結"></a>相關連結</h3><ul>
<li><a href="/akasha/2024/12/26/%E6%96%87%E4%BB%B6%E6%90%9C%E5%B0%8B/">文件搜尋</a></li>
<li><a href="/akasha/2024/12/30/%E8%A8%AD%E5%AE%9A%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B/">設定語言模型</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/akasha/page/2/">2</a><a class="page-number" href="/akasha/page/3/">3</a><a class="extend next" rel="next" href="/akasha/page/2/"><i class="fa fa-angle-right" aria-label="下一頁"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Chih Chuan Chang<ccchang@iii.org.tw></p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/akasha/archives/">
        
          <span class="site-state-item-count">22</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分類</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">標籤</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chih Chuan Chang<ccchang@iii.org.tw></span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 強力驅動
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/akasha/lib/anime.min.js"></script>
  <script src="/akasha/lib/velocity/velocity.min.js"></script>
  <script src="/akasha/lib/velocity/velocity.ui.min.js"></script>

<script src="/akasha/js/utils.js"></script>

<script src="/akasha/js/motion.js"></script>


<script src="/akasha/js/schemes/muse.js"></script>


<script src="/akasha/js/next-boot.js"></script>




  















  

  

</body>
</html>
