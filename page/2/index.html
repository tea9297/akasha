<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/akasha/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/akasha/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/akasha/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/akasha/images/logo.svg" color="#222">

<link rel="stylesheet" href="/akasha/css/main.css">


<link rel="stylesheet" href="/akasha/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"tea9297.github.io","root":"/akasha/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="akasha 0.9 使用手冊">
<meta property="og:url" content="https://tea9297.github.io/akasha/page/2/index.html">
<meta property="og:site_name" content="akasha 0.9 使用手冊">
<meta property="og:locale" content="zh_TW">
<meta property="article:author" content="Chih Chuan Chang&lt;ccchang@iii.org.tw&gt;">
<meta property="article:tag" content="akasha, manual, llm, rag">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://tea9297.github.io/akasha/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-TW'
  };
</script>

  <title>akasha 0.9 使用手冊</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/akasha/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">akasha 0.9 使用手冊</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">akasha 0.9 manual</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/akasha/" rel="section"><i class="fa fa-home fa-fw"></i>首頁</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/akasha/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>歸檔</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/27/summary/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/27/summary/" class="post-title-link" itemprop="url">summary</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-27 23:59:59" itemprop="dateCreated datePublished" datetime="2024-12-27T23:59:59+08:00">2024-12-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2025-04-21 16:44:24" itemprop="dateModified" datetime="2025-04-21T16:44:24+08:00">2025-04-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E5%8A%9F%E8%83%BD/" itemprop="url" rel="index"><span itemprop="name">功能</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h2><p><code>summary</code> 是一個用於總結文件內容的class，支援多種摘要方法（如 <code>map_reduce</code> 和 <code>refine</code>），可以處理多種格式的文件（如 <code>.txt</code>, <code>.docx</code>, <code>.pdf</code>, <code>.md</code>, <code>.csv</code>, <code>.pptx</code>），並將內容分塊後進行摘要，最終合併成一個完整的摘要。</p>
<h3 id="summary-功能"><a href="#summary-功能" class="headerlink" title="summary 功能"></a>summary 功能</h3><ol>
<li><strong>多種摘要方法</strong>：<ul>
<li><code>map_reduce</code>：將內容分塊後分別摘要，最後合併成完整摘要，速度較快，適合大規模內容。</li>
<li><code>refine</code>：逐塊摘要並使用前一塊的摘要作為提示，摘要一致性較高，但速度較慢。</li>
</ul>
</li>
<li><strong>支援多種輸入格式</strong>：可處理本地文件、目錄、網址或純文字內容。</li>
<li><strong>日誌保存</strong>：支持保存執行過程與結果的日誌，便於後續分析。</li>
</ol>
<hr>
<h3 id="summary-範例"><a href="#summary-範例" class="headerlink" title="summary 範例"></a>summary 範例</h3><h4 id="使用-map-reduce-方法進行摘要"><a href="#使用-map-reduce-方法進行摘要" class="headerlink" title="使用 map_reduce 方法進行摘要"></a>使用 <code>map_reduce</code> 方法進行摘要</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"></span><br><span class="line">summ = akasha.summary(</span><br><span class="line">    model=<span class="string">&quot;openai:gpt-4o&quot;</span>,</span><br><span class="line">    sum_type=<span class="string">&quot;map_reduce&quot;</span>,</span><br><span class="line">    chunk_size=<span class="number">1000</span>,</span><br><span class="line">    sum_len=<span class="number">1000</span>,</span><br><span class="line">    language=<span class="string">&quot;en&quot;</span>,</span><br><span class="line">    keep_logs=<span class="literal">True</span>,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">    max_input_tokens=<span class="number">8000</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 總結內容，來源可以是網址、文件或純文字</span></span><br><span class="line">ret = summ(content=[<span class="string">&quot;https://github.com/iii-org/akasha&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存日誌</span></span><br><span class="line">summ.save_logs(<span class="string">&quot;sumlog.json&quot;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="使用-refine-方法進行摘要"><a href="#使用-refine-方法進行摘要" class="headerlink" title="使用 refine 方法進行摘要"></a>使用 <code>refine</code> 方法進行摘要</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">summ = akasha.summary(</span><br><span class="line">    model=<span class="string">&quot;openai:gpt-4o&quot;</span>,</span><br><span class="line">    sum_type=<span class="string">&quot;refine&quot;</span>,</span><br><span class="line">    chunk_size=<span class="number">1000</span>,</span><br><span class="line">    sum_len=<span class="number">500</span>,</span><br><span class="line">    language=<span class="string">&quot;zh&quot;</span>,</span><br><span class="line">    keep_logs=<span class="literal">True</span>,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">    max_input_tokens=<span class="number">8000</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 總結內容，來源可以是本地文件或目錄</span></span><br><span class="line">ret = summ(content=[<span class="string">&quot;docs/example.txt&quot;</span>, <span class="string">&quot;docs/reports/&quot;</span>])</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="summary-參數"><a href="#summary-參數" class="headerlink" title="summary 參數"></a>summary 參數</h3><h4 id="初始化參數"><a href="#初始化參數" class="headerlink" title="初始化參數"></a>初始化參數</h4><h5 id="model-str"><a href="#model-str" class="headerlink" title="model: str"></a>model: str</h5><p>使用的語言模型，例如 <code>&quot;openai:gpt-4o&quot;</code> 或 <code>&quot;openai:gpt-3.5-turbo&quot;</code>。</p>
<h5 id="sum-type-str"><a href="#sum-type-str" class="headerlink" title="sum_type: str"></a>sum_type: str</h5><p>摘要方法，支持：</p>
<ul>
<li><code>&quot;map_reduce&quot;</code>：分塊摘要後合併，速度較快。</li>
<li><code>&quot;refine&quot;</code>：逐塊摘要並使用前一塊的摘要作為提示，摘要一致性較高。</li>
</ul>
<h5 id="sum-len-int"><a href="#sum-len-int" class="headerlink" title="sum_len: int"></a>sum_len: int</h5><p>建議的摘要長度（以字數或 token 數計）。</p>
<h5 id="chunk-size-int"><a href="#chunk-size-int" class="headerlink" title="chunk_size: int"></a>chunk_size: int</h5><p>分塊大小，單位為字數或 token。</p>
<h5 id="chunk-overlap-int"><a href="#chunk-overlap-int" class="headerlink" title="chunk_overlap: int"></a>chunk_overlap: int</h5><p>分塊重疊大小，單位為字數或 token。</p>
<h5 id="max-input-tokens-int"><a href="#max-input-tokens-int" class="headerlink" title="max_input_tokens: int"></a>max_input_tokens: int</h5><p>單次輸入模型的最大 token 數。</p>
<h5 id="max-output-tokens-int"><a href="#max-output-tokens-int" class="headerlink" title="max_output_tokens: int"></a>max_output_tokens: int</h5><p>模型輸出的最大 token 數。</p>
<h5 id="language-str"><a href="#language-str" class="headerlink" title="language: str"></a>language: str</h5><p>內容的語言，支持 <code>&quot;en&quot;</code>（英文）和 <code>&quot;zh&quot;</code>（中文）。</p>
<h5 id="keep-logs-bool"><a href="#keep-logs-bool" class="headerlink" title="keep_logs: bool"></a>keep_logs: bool</h5><p>是否保存執行過程與結果的日誌。</p>
<h5 id="verbose-bool"><a href="#verbose-bool" class="headerlink" title="verbose: bool"></a>verbose: bool</h5><p>是否顯示詳細的執行過程。</p>
<h5 id="temperature-float"><a href="#temperature-float" class="headerlink" title="temperature: float"></a>temperature: float</h5><p>語言模型的隨機性參數，範圍為 0.0 到 1.0。</p>
<h5 id="system-prompt-str"><a href="#system-prompt-str" class="headerlink" title="system_prompt: str"></a>system_prompt: str</h5><p>指示語言模型的輸出格式需求。</p>
<hr>
<h3 id="call-參數"><a href="#call-參數" class="headerlink" title="call 參數"></a><strong>call</strong> 參數</h3><h5 id="content-Union-str-list-Path-Document"><a href="#content-Union-str-list-Path-Document" class="headerlink" title="content: Union[str, list, Path, Document]"></a>content: Union[str, list, Path, Document]</h5><p>需要總結的內容，可以是：</p>
<ul>
<li>單個或多個文件路徑（如 <code>.txt</code>, <code>.docx</code>, <code>.pdf</code>）。</li>
<li>單個或多個網址。</li>
<li>單個或多個純文字內容。</li>
</ul>
<h5 id="sum-type-str-1"><a href="#sum-type-str-1" class="headerlink" title="sum_type: str"></a>sum_type: str</h5><p>摘要方法，支持 <code>&quot;map_reduce&quot;</code> 或 <code>&quot;refine&quot;</code>。</p>
<h5 id="sum-len-int-1"><a href="#sum-len-int-1" class="headerlink" title="sum_len: int"></a>sum_len: int</h5><p>建議的摘要長度。</p>
<h5 id="chunk-size-int-1"><a href="#chunk-size-int-1" class="headerlink" title="chunk_size: int"></a>chunk_size: int</h5><p>分塊大小。</p>
<h5 id="chunk-overlap-int-1"><a href="#chunk-overlap-int-1" class="headerlink" title="chunk_overlap: int"></a>chunk_overlap: int</h5><p>分塊重疊大小。</p>
<h5 id="max-input-tokens-int-1"><a href="#max-input-tokens-int-1" class="headerlink" title="max_input_tokens: int"></a>max_input_tokens: int</h5><p>單次輸入模型的最大 token 數。</p>
<h5 id="max-output-tokens-int-1"><a href="#max-output-tokens-int-1" class="headerlink" title="max_output_tokens: int"></a>max_output_tokens: int</h5><p>模型輸出的最大 token 數。</p>
<h5 id="temperature-float-1"><a href="#temperature-float-1" class="headerlink" title="temperature: float"></a>temperature: float</h5><p>語言模型的隨機性參數。</p>
<hr>
<h3 id="日誌與結果"><a href="#日誌與結果" class="headerlink" title="日誌與結果"></a>日誌與結果</h3><ul>
<li>總結過程與結果會保存到指定的日誌文件中。</li>
<li>日誌包括摘要的詳細過程、分塊信息、模型輸入輸出 token 數等。</li>
</ul>
<hr>
<h3 id="相關連結"><a href="#相關連結" class="headerlink" title="相關連結"></a>相關連結</h3><ul>
<li><a href="2024/12/26/%E6%96%87%E4%BB%B6%E6%90%9C%E5%B0%8B/">文件搜尋</a></li>
<li><a href="2024/12/30/%E8%A8%AD%E5%AE%9A%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B/">設定語言模型</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/27/websearch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/27/websearch/" class="post-title-link" itemprop="url">websearch</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-27 22:59:59" itemprop="dateCreated datePublished" datetime="2024-12-27T22:59:59+08:00">2024-12-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2025-04-21 16:50:07" itemprop="dateModified" datetime="2025-04-21T16:50:07+08:00">2025-04-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E5%8A%9F%E8%83%BD/" itemprop="url" rel="index"><span itemprop="name">功能</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="websearch"><a href="#websearch" class="headerlink" title="websearch"></a>websearch</h2><p><code>websearch</code> 是一個結合網頁搜尋與語言模型回答的工具。它會根據使用者的問題在網路上搜尋相關資訊，並使用語言模型整合搜尋結果來回答問題。<code>websearch</code> 支援多種搜尋引擎與語言，並提供詳細的日誌記錄功能。 </p>
<p><em><strong>除了wiki，其他搜尋方法皆需要輸入搜尋引擎的API_KEY</strong></em></p>
<ul>
<li>SERPER: </li>
<li>BRAVE:</li>
<li>TAVILY:</li>
</ul>
<h3 id="websearch-功能"><a href="#websearch-功能" class="headerlink" title="websearch 功能"></a>websearch 功能</h3><ol>
<li><strong>網頁搜尋</strong>：支援多種搜尋引擎，包括 <code>wiki</code>、<code>serper</code>、<code>tavily</code> 和 <code>brave</code>。</li>
<li><strong>日誌保存</strong>：支持保存執行過程與結果的日誌，便於後續分析。</li>
<li><strong>流式輸出</strong>：支援流式輸出回答，適合需要即時回應的場景。</li>
</ol>
<hr>
<h3 id="websearch-範例"><a href="#websearch-範例" class="headerlink" title="websearch 範例"></a>websearch 範例</h3><h4 id="使用-serper-搜尋引擎進行搜尋"><a href="#使用-serper-搜尋引擎進行搜尋" class="headerlink" title="使用 serper 搜尋引擎進行搜尋"></a>使用 <code>serper</code> 搜尋引擎進行搜尋</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"></span><br><span class="line">wb = akasha.websearch(</span><br><span class="line">    model=<span class="string">&quot;openai:gpt-4o&quot;</span>,</span><br><span class="line">    language=<span class="string">&quot;ch&quot;</span>,</span><br><span class="line">    search_engine=<span class="string">&quot;serper&quot;</span>,</span><br><span class="line">    search_num=<span class="number">5</span>,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">    keep_logs=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用搜尋引擎回答問題</span></span><br><span class="line">res = wb(<span class="string">&quot;工業4.0是什麼?&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存日誌</span></span><br><span class="line">wb.save_logs(<span class="string">&quot;wb.json&quot;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="使用流式輸出回答"><a href="#使用流式輸出回答" class="headerlink" title="使用流式輸出回答"></a>使用流式輸出回答</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 啟用流式輸出</span></span><br><span class="line">st = wb(<span class="string">&quot;工業4.0是什麼?&quot;</span>, stream=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 逐步輸出回答</span></span><br><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> st:</span><br><span class="line">    <span class="built_in">print</span>(s)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="websearch-參數"><a href="#websearch-參數" class="headerlink" title="websearch 參數"></a>websearch 參數</h3><h4 id="初始化參數"><a href="#初始化參數" class="headerlink" title="初始化參數"></a>初始化參數</h4><h5 id="model-str"><a href="#model-str" class="headerlink" title="model: str"></a>model: str</h5><p>使用的語言模型，例如 <code>&quot;openai:gpt-4o&quot;</code> 或 <code>&quot;openai:gpt-3.5-turbo&quot;</code>。</p>
<h5 id="language-str"><a href="#language-str" class="headerlink" title="language: str"></a>language: str</h5><p>搜尋語言與地區，支持 <code>&quot;en&quot;</code>（英文）或 <code>&quot;ch&quot;</code>（中文）。</p>
<h5 id="search-engine-str"><a href="#search-engine-str" class="headerlink" title="search_engine: str"></a>search_engine: str</h5><p>使用的搜尋引擎，支持：</p>
<ul>
<li><code>&quot;wiki&quot;</code>：維基百科搜尋。</li>
<li><code>&quot;serper&quot;</code>：Google 搜尋 API（需申請 API 金鑰）。</li>
<li><code>&quot;tavily&quot;</code>：Tavily 搜尋 API（需申請 API 金鑰）。</li>
<li><code>&quot;brave&quot;</code>：Brave 搜尋 API（需申請 API 金鑰）。</li>
</ul>
<h5 id="search-num-int"><a href="#search-num-int" class="headerlink" title="search_num: int"></a>search_num: int</h5><p>搜尋結果的數量。</p>
<h5 id="max-input-tokens-int"><a href="#max-input-tokens-int" class="headerlink" title="max_input_tokens: int"></a>max_input_tokens: int</h5><p>單次輸入模型的最大 token 數。</p>
<h5 id="max-output-tokens-int"><a href="#max-output-tokens-int" class="headerlink" title="max_output_tokens: int"></a>max_output_tokens: int</h5><p>模型輸出的最大 token 數。</p>
<h5 id="temperature-float"><a href="#temperature-float" class="headerlink" title="temperature: float"></a>temperature: float</h5><p>語言模型的隨機性參數，範圍為 0.0 到 1.0。</p>
<h5 id="system-prompt-str"><a href="#system-prompt-str" class="headerlink" title="system_prompt: str"></a>system_prompt: str</h5><p>指示語言模型的輸出格式需求。</p>
<h5 id="keep-logs-bool"><a href="#keep-logs-bool" class="headerlink" title="keep_logs: bool"></a>keep_logs: bool</h5><p>是否保存執行過程與結果的日誌。</p>
<h5 id="verbose-bool"><a href="#verbose-bool" class="headerlink" title="verbose: bool"></a>verbose: bool</h5><p>是否顯示詳細的執行過程。</p>
<h5 id="stream-bool"><a href="#stream-bool" class="headerlink" title="stream: bool"></a>stream: bool</h5><p>是否啟用流式輸出。</p>
<h5 id="env-file-str"><a href="#env-file-str" class="headerlink" title="env_file: str"></a>env_file: str</h5><p>指定 <code>.env</code> 環境設定檔的路徑。</p>
<hr>
<h3 id="call-參數"><a href="#call-參數" class="headerlink" title="call 參數"></a><strong>call</strong> 參數</h3><h5 id="prompt-str"><a href="#prompt-str" class="headerlink" title="prompt: str"></a>prompt: str</h5><p>使用者的問題。</p>
<h5 id="stream-bool-1"><a href="#stream-bool-1" class="headerlink" title="stream: bool"></a>stream: bool</h5><p>是否啟用流式輸出。</p>
<h5 id="search-engine-str-1"><a href="#search-engine-str-1" class="headerlink" title="search_engine: str"></a>search_engine: str</h5><p>指定搜尋引擎，支持 <code>&quot;wiki&quot;</code>、<code>&quot;serper&quot;</code>、<code>&quot;tavily&quot;</code> 和 <code>&quot;brave&quot;</code>。</p>
<h5 id="search-num-int-1"><a href="#search-num-int-1" class="headerlink" title="search_num: int"></a>search_num: int</h5><p>搜尋結果的數量。</p>
<h5 id="language-str-1"><a href="#language-str-1" class="headerlink" title="language: str"></a>language: str</h5><p>搜尋語言與地區，支持 <code>&quot;en&quot;</code> 或 <code>&quot;ch&quot;</code>。</p>
<hr>
<h3 id="日誌與結果"><a href="#日誌與結果" class="headerlink" title="日誌與結果"></a>日誌與結果</h3><ul>
<li>搜尋過程與結果會保存到指定的日誌文件中。</li>
<li>日誌包括搜尋引擎、搜尋結果數量、語言模型的輸入輸出 token 數等。</li>
</ul>
<hr>
<h3 id="相關連結"><a href="#相關連結" class="headerlink" title="相關連結"></a>相關連結</h3><ul>
<li><a href="2024/12/26/%E6%96%87%E4%BB%B6%E6%90%9C%E5%B0%8B/">文件搜尋</a></li>
<li><a href="2024/12/30/%E8%A8%AD%E5%AE%9A%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B/">設定語言模型</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/26/%E6%8F%90%E7%A4%BA%E6%A0%BC%E5%BC%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/26/%E6%8F%90%E7%A4%BA%E6%A0%BC%E5%BC%8F/" class="post-title-link" itemprop="url">提示格式</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-26 21:59:59" itemprop="dateCreated datePublished" datetime="2024-12-26T21:59:59+08:00">2024-12-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2024-12-03 17:18:18" itemprop="dateModified" datetime="2024-12-03T17:18:18+08:00">2024-12-03</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E9%80%B2%E9%9A%8E/" itemprop="url" rel="index"><span itemprop="name">進階</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="提示格式"><a href="#提示格式" class="headerlink" title="提示格式"></a>提示格式</h2><p>根據使用的語言模型不同，使用不同的格式來下指令可以得到更好的結果，akasha目前提供 <em><strong>gpt</strong></em>, <em><strong>llama</strong></em>, <em><strong>chat_gpt</strong></em>, <em><strong>chat_mistral</strong></em>, <em><strong>chat_gemini</strong></em>, <em><strong>auto</strong></em> 等格式<br>若選擇 <em><strong>auto</strong></em>會根據模型類別來決定提示格式 </p>
<h4 id="gpt"><a href="#gpt" class="headerlink" title="gpt"></a>gpt</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">prompt_format = System: &#123;system_prompt&#125; \n\n &#123;history_messages&#125; \n\n Human: &#123;prompt&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="llama"><a href="#llama" class="headerlink" title="llama"></a>llama</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">prompt_format = [INST] &lt;&lt;SYS&gt;&gt;  &#123;system_prompt&#125; \n\n &lt;&lt;SYS&gt;&gt; &#123;history_messages&#125; \n\n  &#123;prompt&#125; [\INST]</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h4 id="chat-gpt"><a href="#chat-gpt" class="headerlink" title="chat_gpt"></a>chat_gpt</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">prompt_format = [&#123;&quot;role&quot;:&quot;system&quot;, &quot;content&quot;: &#123;system_prompt&#125; &#125;,</span><br><span class="line">&#123;&quot;role&quot;:&quot;user&quot;, &quot;content&quot;: &#123;history msg1&#125;&#125;,</span><br><span class="line">&#123;&quot;role&quot;:&quot;assistant&quot;, &quot;content&quot;: &#123;history msg2&#125;&#125;,</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">&#123;&quot;role&quot;:&quot;user&quot;, &quot;content&quot;: &#123;prompt&#125;&#125;]</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h4 id="chat-mistral"><a href="#chat-mistral" class="headerlink" title="chat_mistral"></a>chat_mistral</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">prompt_format = [&#123;&quot;role&quot;:&quot;user&quot;, &quot;content&quot;: &quot;start conversation&quot; &#125;,</span><br><span class="line">&#123;&quot;role&quot;:&quot;assistant&quot;, &quot;content&quot;: &#123;system_prompt&#125;&#125;,</span><br><span class="line">&#123;&quot;role&quot;:&quot;user&quot;, &quot;content&quot;: &#123;history msg1&#125;&#125;,</span><br><span class="line">&#123;&quot;role&quot;:&quot;assistant&quot;, &quot;content&quot;: &#123;history msg2&#125;&#125;,</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">&#123;&quot;role&quot;:&quot;user&quot;, &quot;content&quot;: &#123;prompt&#125;&#125;]</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h4 id="chat-gemini"><a href="#chat-gemini" class="headerlink" title="chat_gemini"></a>chat_gemini</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">prompt_format =[&#123;&quot;role&quot;:&quot;model&quot;, &quot;parts&quot;: [&#123;system_prompt&#125;]&#125;,</span><br><span class="line">&#123;&quot;role&quot;:&quot;user&quot;, &quot;parts&quot;: [&#123;history msg1&#125;]&#125;,</span><br><span class="line">&#123;&quot;role&quot;:&quot;model&quot;, &quot;parts&quot;: [&#123;history msg2&#125;]&#125;,</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">&#123;&quot;role&quot;:&quot;user&quot;, &quot;parts&quot;: [&#123;prompt&#125;]&#125;]</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line">sys_prompt = &quot;請用中文回答&quot;</span><br><span class="line">prompt = &quot;五軸是甚麼?&quot;</span><br><span class="line">qa = akasha.Doc_QA(</span><br><span class="line">    verbose=False, </span><br><span class="line">    search_type=&quot;svm&quot;, </span><br><span class="line">    model=&quot;openai:gpt-3.5-turbo&quot;)</span><br><span class="line"></span><br><span class="line">response = qa.get_response(</span><br><span class="line">        doc_path=&quot;docs/mic/&quot;,</span><br><span class="line">        prompt=prompt,</span><br><span class="line">        prompt_format_type=&quot;chat_gpt&quot;,</span><br><span class="line">        system_prompt=sys_prompt,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>


<h2 id="Example2"><a href="#Example2" class="headerlink" title="Example2"></a>Example2</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line">sys_prompt = &quot;請用中文回答&quot;</span><br><span class="line">prompt = &quot;五軸是甚麼?&quot;</span><br><span class="line">input_text = akasha.prompts.format_sys_prompt(sys_prompt,prompt,&quot;chat_gpt&quot;)</span><br><span class="line">model_obj = akasha.handle_model(&quot;openai:gpt-3.5-turbo&quot;,False,0.0)</span><br><span class="line"></span><br><span class="line">response = akasha.call_model(model_obj, input_text)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/26/%E6%96%87%E4%BB%B6%E6%90%9C%E5%B0%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/26/%E6%96%87%E4%BB%B6%E6%90%9C%E5%B0%8B/" class="post-title-link" itemprop="url">文件搜尋</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-26 20:59:59" itemprop="dateCreated datePublished" datetime="2024-12-26T20:59:59+08:00">2024-12-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2024-12-25 16:46:52" itemprop="dateModified" datetime="2024-12-25T16:46:52+08:00">2024-12-25</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E9%80%B2%E9%9A%8E/" itemprop="url" rel="index"><span itemprop="name">進階</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="選擇不同的文件搜尋方法"><a href="#選擇不同的文件搜尋方法" class="headerlink" title="選擇不同的文件搜尋方法"></a>選擇不同的文件搜尋方法</h2><p>使用<em><strong>search_type</strong></em>參數可選擇不同的文件搜尋方法去找出與問題相關的文件段落，可使用<em><strong>svm</strong></em>, <em><strong>mmr</strong></em>, <em><strong>tfidf</strong></em>, <em><strong>knn</strong></em>。另可使用<em><strong>merge</strong></em>，為前三者的合併。</p>
<ol>
<li><p><em><strong>支持向量機（svm）</strong></em> 使用輸入提示和文件向量來訓練svm模型，訓練後，svm可用於基於其與訓練數據的相似性對新向量進行評分。</p>
</li>
<li><p><em><strong>Max Marginal Relevance（mmr）</strong></em> 通過余弦相似度選擇相似的文件，但它也考慮多樣性，因此它還會懲罰與已選擇文件的接近。</p>
</li>
<li><p><em><strong>詞頻-逆文檔頻率（tfidf）</strong></em> 是信息檢索和文本挖掘中常用的權重技術。TF-IDF是一種統計方法，用於評估詞語在一個文檔集合或語料庫中相對於該集合中的一個特定文檔的重要性。</p>
</li>
<li><p><em><strong>K-最近鄰居（KNN）</strong></em> 是一種機器學習算法，用於分類和回歸問題。對於新數據點，它計算其與已知數據點的距離，然後基於最近的 k 個鄰居來預測類別或數值。在分類中，以多數票決定類別，而在回歸中則計算鄰居的平均值。</p>
</li>
<li><p><em><strong>Okapi BM25(bm25)</strong></em>（BM 是最佳匹配的縮寫）是一種基於查詢詞出現在每個文檔中的檢索功能，而不考慮它們在文檔中的相鄰關系的排名一組文檔的方法。它是一系列具有略有不同組件和參數的評分函數。</p>
</li>
<li><p><em><strong>rerank</strong></em> 使用bge-reranker模型對文檔進行相似度排序，速度較慢。 (rerank&#x2F;rerank:bge-reranker-large)</p>
</li>
</ol>
</br>
</br>


<h2 id="自動選擇搜尋方法"><a href="#自動選擇搜尋方法" class="headerlink" title="自動選擇搜尋方法"></a>自動選擇搜尋方法</h2><p><em><strong>auto</strong></em>&#x2F; <em><strong>audo_rerank</strong></em> 是另一種可以選擇的文件搜尋策略，使用 <em><strong>bm25</strong></em> 來搜尋相同詞語的文件，並用 <em><strong>svm</strong></em> 搜尋近似詞意的文件，若為 <em><strong>audo_rerank</strong></em> 且兩者皆沒有找到，則使用rerank模型去遍歷文件，但會相當緩慢。</p>
<h2 id="自訂搜尋方法"><a href="#自訂搜尋方法" class="headerlink" title="自訂搜尋方法"></a>自訂搜尋方法</h2><p>如果你希望設計自己的方法找尋最相似的文檔，可以建立search_type函數，並將此函數作為<em><strong>search_type</strong></em>參數</p>
<p>此函數輸入包含:</p>
<h5 id="1-query-embeds-查詢的嵌入。（numpy-array）"><a href="#1-query-embeds-查詢的嵌入。（numpy-array）" class="headerlink" title="1.query_embeds: 查詢的嵌入。（numpy array）"></a>1.query_embeds: 查詢的嵌入。（numpy array）</h5><h5 id="2-docs-embeds-所有文檔的嵌入。（表示文檔嵌入的-numpy-數組的list）"><a href="#2-docs-embeds-所有文檔的嵌入。（表示文檔嵌入的-numpy-數組的list）" class="headerlink" title="2.docs_embeds: 所有文檔的嵌入。（表示文檔嵌入的 numpy 數組的list）"></a>2.docs_embeds: 所有文檔的嵌入。（表示文檔嵌入的 numpy 數組的list）</h5><h5 id="3-k-所要選擇的最相關文檔的數量。（integer）"><a href="#3-k-所要選擇的最相關文檔的數量。（integer）" class="headerlink" title="3.k: 所要選擇的最相關文檔的數量。（integer）"></a>3.k: 所要選擇的最相關文檔的數量。（integer）</h5><h5 id="4-log-一個字典，可用於記錄任何您希望記錄的其他信息。（dictionary）"><a href="#4-log-一個字典，可用於記錄任何您希望記錄的其他信息。（dictionary）" class="headerlink" title="4.log: 一個字典，可用於記錄任何您希望記錄的其他信息。（dictionary）"></a>4.log: 一個字典，可用於記錄任何您希望記錄的其他信息。（dictionary）</h5></br>
</br>

<h4 id="此函數須回傳相似文檔的index順序-list"><a href="#此函數須回傳相似文檔的index順序-list" class="headerlink" title="此函數須回傳相似文檔的index順序(list)"></a>此函數須回傳相似文檔的index順序(list)</h4></br>
</br>


<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><p>如範例，我們使用歐幾里得距離度量來識別最相關的文檔。它返回一個表示距離小於指定閾值的查詢和文檔嵌入之間的前 k 個文檔的索引列表。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">def cust(query_embeds, docs_embeds, k:int, relevancy_threshold:float, log:dict):</span><br><span class="line">    </span><br><span class="line">    from scipy.spatial.distance import euclidean</span><br><span class="line">    import numpy as np</span><br><span class="line">    distance = [[euclidean(query_embeds, docs_embeds[idx]),idx] for idx in range(len(docs_embeds))]</span><br><span class="line">    distance = sorted(distance, key=lambda x: x[0])</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    ## change dist if embeddings not between 0~1</span><br><span class="line">    max_dist = 1</span><br><span class="line">    while max_dist &lt; distance[-1][0]:</span><br><span class="line">        max_dist *= 10</span><br><span class="line">        relevancy_threshold *= 10</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    ## add log para</span><br><span class="line">    log[&#x27;dd&#x27;] = &quot;miao&quot;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    return  [idx for dist,idx in distance[:k] if (max_dist - dist) &gt;= relevancy_threshold]</span><br><span class="line"></span><br><span class="line">doc_path = &quot;./mic/&quot;</span><br><span class="line">prompt = &quot;五軸是什麼?&quot;</span><br><span class="line"></span><br><span class="line">qa = akasha.Doc_QA(verbose=True, search_type = cust, embeddings=&quot;hf:shibing624/text2vec-base-chinese&quot;)</span><br><span class="line">qa.get_response(doc_path= doc_path, prompt = prompt)</span><br></pre></td></tr></table></figure>

</br>
</br>


<h2 id="Document-物件"><a href="#Document-物件" class="headerlink" title="Document 物件"></a>Document 物件</h2><p>在akasha中，文件搜尋的結果會以list of Document的形式回傳，Docuement為一個儲存文件內容(page_content)和後設資料(metadata)的物件，可以以此進行宣告和取用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.schema <span class="keyword">import</span> Document</span><br><span class="line"></span><br><span class="line">text = <span class="string">&quot;這是一個測試文件段落，這是一個測試文件段落，這是一個測試文件段落。&quot;</span></span><br><span class="line">metadata = &#123;<span class="string">&#x27;page&#x27;</span>:<span class="number">0</span>, <span class="string">&#x27;source&#x27;</span>:<span class="string">&#x27;docs/test1/f1.txt&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">doc1 = Document(page_content=text, metadata=metadata)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(doc1.page_content)</span><br><span class="line"><span class="built_in">print</span>(doc1.metadata)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


</br>
</br>


<h2 id="Retriver"><a href="#Retriver" class="headerlink" title="Retriver"></a>Retriver</h2><p>若您想自行進行文件搜尋，在akasha中，文件搜尋是以以下流程進行:</p>
<ol>
<li>從文件資料夾中建立chromadb，讀取為dbs物件</li>
<li>根據搜尋方法取得retriever物件</li>
<li>利用retriever進行文件搜尋，並根據語言模型和設定的文件token上限回傳不超過token上限的文件內容，與文件的排序(list of Document)</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"></span><br><span class="line">emb_name = <span class="string">&quot;openai:text-embedding-ada-002&quot;</span></span><br><span class="line">emb_obj = akasha.handle_embeddings(emb_name)</span><br><span class="line">search_type = <span class="string">&quot;auto&quot;</span></span><br><span class="line">query = <span class="string">&quot;五軸是甚麼?&quot;</span></span><br><span class="line">model_name = <span class="string">&quot;openai:gpt-3.5-turbo&quot;</span></span><br><span class="line">max_input_tokens = <span class="number">3000</span></span><br><span class="line"><span class="comment"># 1. get dbs object</span></span><br><span class="line">db, _ = akasha.db.processMultiDB(doc_path_list=<span class="string">&quot;docs/mic&quot;</span>, verbose=<span class="literal">False</span>, embeddings=emb_obj,</span><br><span class="line">                                 chunk_size=<span class="number">1000</span>, ignore_check=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. get retriver list</span></span><br><span class="line">retriver_list = akasha.search.get_retrivers(db=db, embeddings=emb_obj, </span><br><span class="line">                                           search_type=search_type, log=&#123;&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. get sorted list of Documents by similarity </span></span><br><span class="line">docs, doc_length, doc_tokens = akasha.search.get_docs(</span><br><span class="line">            db,</span><br><span class="line">            retrivers_list,</span><br><span class="line">            query,</span><br><span class="line">            language=<span class="string">&quot;ch&quot;</span>,</span><br><span class="line">            search_type=search_type,</span><br><span class="line">            verbose=<span class="literal">False</span>,</span><br><span class="line">            model=model_name,</span><br><span class="line">            max_input_tokens=max_input_tokens</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(docs[<span class="number">0</span>].page_content) <span class="comment"># docs is list of Documents</span></span><br><span class="line"><span class="built_in">print</span>(doc_length) <span class="comment"># integer</span></span><br><span class="line"><span class="built_in">print</span>(doc_tokens) <span class="comment"># integer</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="get-relevant-documents-and-scores"><a href="#get-relevant-documents-and-scores" class="headerlink" title="get_relevant_documents_and_scores"></a>get_relevant_documents_and_scores</h3><p>若您只想使用單一的搜尋方法(如 mmr, svm, knn, tfidf, bm25)，且不想限制文件的總token數量，可以使用 <em><strong>get_relevant_documents_and_scores</strong></em>取得文件排序結果(list of Documents)與相似度的分數(list of float)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"></span><br><span class="line">emb_name = <span class="string">&quot;openai:text-embedding-ada-002&quot;</span></span><br><span class="line">emb_obj = akasha.handle_embeddings(emb_name)</span><br><span class="line">search_type = <span class="string">&quot;svm&quot;</span></span><br><span class="line">query = <span class="string">&quot;五軸是甚麼?&quot;</span></span><br><span class="line">model_name = <span class="string">&quot;openai:gpt-3.5-turbo&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. get dbs object</span></span><br><span class="line">db, _ = akasha.db.processMultiDB(doc_path_list=<span class="string">&quot;docs/mic&quot;</span>, verbose=<span class="literal">False</span>, embeddings=emb_obj,</span><br><span class="line">                                 chunk_size=<span class="number">1000</span>, ignore_check=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. get retriver list</span></span><br><span class="line">single_retriver = akasha.search.get_retrivers(db=db, embeddings=emb_obj,</span><br><span class="line">                                           search_type=search_type, log=&#123;&#125;)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. get sorted list of Documents and scores by similarity </span></span><br><span class="line"><span class="comment">### this method is only for single search method, not for &#x27;merge&#x27; and &#x27;auto&#x27; ###</span></span><br><span class="line">docs, scores = single_retriver.get_relevant_documents_and_scores(query)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(docs[<span class="number">0</span>].page_content) <span class="comment"># docs is list of Document</span></span><br><span class="line"><span class="built_in">print</span>(scores[<span class="number">0</span>]) <span class="comment"># float</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(docs), <span class="built_in">len</span>(scores))</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="retri-docs"><a href="#retri-docs" class="headerlink" title="retri_docs"></a>retri_docs</h3><p>若您不想限制文件的總token數量，可以使用 <em><strong>retri_docs</strong></em>取得文件排序結果(list of Documents)<br>可根據參數 <em><strong>topK</strong></em>指定回傳的文件片段數量上限</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"></span><br><span class="line">emb_name = <span class="string">&quot;openai:text-embedding-ada-002&quot;</span></span><br><span class="line">emb_obj = akasha.handle_embeddings(emb_name)</span><br><span class="line">search_type = <span class="string">&quot;auto&quot;</span></span><br><span class="line">query = <span class="string">&quot;五軸是甚麼?&quot;</span></span><br><span class="line">topK = <span class="number">100</span></span><br><span class="line"><span class="comment"># 1. get dbs object</span></span><br><span class="line">db, _ = akasha.db.processMultiDB(doc_path_list=<span class="string">&quot;docs/mic&quot;</span>, verbose=<span class="literal">False</span>, embeddings=emb_obj,</span><br><span class="line">                                 chunk_size=<span class="number">1000</span>, ignore_check=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. get retriver list</span></span><br><span class="line">retriver_list = akasha.search.get_retrivers(db=db, embeddings=emb_obj, </span><br><span class="line">                                           search_type=search_type, log=&#123;&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. get sorted list of Documents by similarity </span></span><br><span class="line">docs = akasha.search.retri_docs(</span><br><span class="line">            db,</span><br><span class="line">            retrivers_list,</span><br><span class="line">            query,</span><br><span class="line">            search_type=search_type,</span><br><span class="line">            topK=topK</span><br><span class="line">            verbose=<span class="literal">False</span>,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(docs[<span class="number">0</span>].page_content) <span class="comment"># docs is list of Document</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/26/%E5%90%91%E9%87%8F%E8%B3%87%E6%96%99%E5%BA%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/26/%E5%90%91%E9%87%8F%E8%B3%87%E6%96%99%E5%BA%AB/" class="post-title-link" itemprop="url">向量資料庫</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-26 20:58:59" itemprop="dateCreated datePublished" datetime="2024-12-26T20:58:59+08:00">2024-12-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2024-12-25 16:43:04" itemprop="dateModified" datetime="2024-12-25T16:43:04+08:00">2024-12-25</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E9%80%B2%E9%9A%8E/" itemprop="url" rel="index"><span itemprop="name">進階</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="dbs物件"><a href="#dbs物件" class="headerlink" title="dbs物件"></a>dbs物件</h2><p>在akasha中，chromadb建立完之後，會被儲存成dbs物件，會儲存chromadb中的文件內容、metadata、向量資料、unique id，並被使用於後續的vector similarity search。</p>
<p>該物件可以添加多個chromadb資料，也可與其他dbs物件互相結合，也可根據filter抽取出需要的向量資料。</p>
<h3 id="建立向量資料"><a href="#建立向量資料" class="headerlink" title="建立向量資料"></a>建立向量資料</h3><h4 id="processMultiDB"><a href="#processMultiDB" class="headerlink" title="processMultiDB"></a>processMultiDB</h4><p>processMultiDB可對多個文件集(list of directory)建立chromadb，並回傳dbs物件與建立不成功的檔案list，若文件內容、使用嵌入模型、chunk size相等的chromadb已存在，則不會重新創建而直接讀取。</p>
<p>文件內容改變也會建立新的chromadb，設定參數ignore_check&#x3D;True則不進行文件內容更改與否的確認，可更快的進行chromadb的讀取。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line">doc_paths = [<span class="string">&quot;docs/pns_query&quot;</span>, <span class="string">&quot;docs/mic&quot;</span>]</span><br><span class="line">emb_name = <span class="string">&quot;openai:text-embedding-ada-002&quot;</span></span><br><span class="line">emb_obj = akasha.handle_embeddings(emb_name)</span><br><span class="line">db, ignore_files = akasha.processMultiDB(doc_path_list=doc_paths,</span><br><span class="line">    verbose=<span class="literal">False</span>,</span><br><span class="line">    embeddings=emb_obj,</span><br><span class="line">    chunk_size=<span class="number">1000</span>,</span><br><span class="line">    ignore_check=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="createDB-file-createDB-directory"><a href="#createDB-file-createDB-directory" class="headerlink" title="createDB_file &amp; createDB_directory"></a>createDB_file &amp; createDB_directory</h4><p>使用多個文字檔案創建chromadb可使用 <em><strong>createDB_file</strong></em>，使用資料夾創建chromadb則使用 <em><strong>createDB_directory</strong></em><br>創建完的dbs物件(db_files, db_directory)可以直接輸入進 <em><strong>get_response</strong></em>中，減少重複讀取。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line">db_files = akasha.createDB_file(file_path = [&quot;f1.txt&quot;,&quot;f2.docs&quot;], embeddings=&quot;openai:text-embedding-ada-002&quot;,chunk_size=500, ignore_check=True)</span><br><span class="line">db_directory = akasha.createDB_directory(doc_path= &quot;./docs/mic/&quot;, </span><br><span class="line">embeddings=&quot;openai:text-embedding-ada-002&quot;, ignore_check=True)</span><br><span class="line">qa = akasha.Doc_QA(</span><br><span class="line">    verbose=True, </span><br><span class="line">    search_type=&quot;svm&quot;, </span><br><span class="line">    model=&quot;openai:gpt-3.5-turbo&quot;, </span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">qa.get_response(</span><br><span class="line">        doc_path=db_directory,</span><br><span class="line">        prompt=&quot;五軸是甚麼?&quot;,</span><br><span class="line">        system_prompt=&quot;請用中文回答&quot;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>


<h3 id="根據關鍵字建立向量資料"><a href="#根據關鍵字建立向量資料" class="headerlink" title="根據關鍵字建立向量資料"></a>根據關鍵字建立向量資料</h3><p>在建立向量資料時，若您不想根據整個文件片段進行embedding，可以使用 <em><strong>akasha.db.create_keyword_chromadb</strong></em>，可自訂義函式來輸出想進行embedding的關鍵字，如以下範例<br>我們定義了一個函式 <em><strong>generate_llm_keyword</strong></em> 請語言模型根據文件段落產生3~5個關鍵字並回傳。</p>
<p>當我們使用 <em><strong>akasha.db.create_keyword_chromadb</strong></em>，建立向量資料(chromadb)，每個文件片段便會根據自訂義函式 <em><strong>generate_llm_keyword</strong></em>的輸出來進行embedding</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"></span><br><span class="line">md_obj = akasha.handle_model(<span class="string">&quot;openai:gpt-4o&quot;</span>, temperature=<span class="number">1</span>)</span><br><span class="line">emb_obj = akasha.handle_embeddings(<span class="string">&quot;openai:text-embedding-ada-002&quot;</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_llm_keyword</span>(<span class="params">text, keyword_num</span>):</span><br><span class="line"></span><br><span class="line">    prompt = <span class="string">f&quot;Generate 3~<span class="subst">&#123;keyword_num&#125;</span> keywords for the following text: \n\n&quot;</span> + text + <span class="string">&quot;\n\n use \, to separate each keyword&quot;</span></span><br><span class="line"></span><br><span class="line">    res = akasha.call_model(md_obj, prompt)</span><br><span class="line">    <span class="keyword">return</span> [res]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">db, _ = akasha.db.create_keyword_chromadb(</span><br><span class="line">    <span class="string">&quot;docs/mic&quot;</span>, emb_obj, <span class="number">1000</span>,</span><br><span class="line">    keyword_function=generate_llm_keyword)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><p>若不使用自訂義函式，預設的函式 <em><strong>akasha.generate_keyword</strong></em>需安裝keybert套件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install keybert</span><br></pre></td></tr></table></figure>


</br>
</br>

<h3 id="使用dbs物件"><a href="#使用dbs物件" class="headerlink" title="使用dbs物件"></a>使用dbs物件</h3><h4 id="init"><a href="#init" class="headerlink" title="init"></a>init</h4><p>您可以直接宣告akasha.dbs()建立空的dbs物件，也可以利用已建立的chromadb建立dbs物件。</p>
<p>dbs物件包含ids(每個文字段落的unique id), embeds(每個文字段落的向量), metadatas(每個文字段落的後設資料), docs(每個文字段落的內容) 。 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">from</span> langchain_chroma <span class="keyword">import</span> Chroma</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">db1 = akasha.dbs()</span><br><span class="line"></span><br><span class="line"><span class="comment">### use chromadb to initialize dbs object ###</span></span><br><span class="line">storage_directory = <span class="string">&quot;chromadb/12345&quot;</span></span><br><span class="line">emb_obj = akasha.handle_embeddings()</span><br><span class="line">docsearch = Chroma(persist_directory=storage_directory,</span><br><span class="line">                           embedding_function=emb_obj)</span><br><span class="line">db2 = akasha.dbs(docsearch)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(db2.get_ids()))  <span class="comment"># list[str]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(db2.get_embeds())) <span class="comment"># list[list[float]]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(db2.get_metadatas())) <span class="comment">#list[dict]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(db2.get_docs())) <span class="comment">#list[dict]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="merge"><a href="#merge" class="headerlink" title="merge"></a>merge</h4><p>dbs物件之間可以使用.merge相互結合</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">from</span> langchain_chroma <span class="keyword">import</span> Chroma</span><br><span class="line"></span><br><span class="line">emb_obj = akasha.handle_embeddings()</span><br><span class="line"></span><br><span class="line">docsearch1 = Chroma(persist_directory=<span class="string">&quot;chromadb/123&quot;</span>,</span><br><span class="line">                           embedding_function=emb_obj)</span><br><span class="line">db1 = akasha.dbs(docsearch1)</span><br><span class="line"></span><br><span class="line">docsearch2 = Chroma(persist_directory=<span class="string">&quot;chromadb/456&quot;</span>,</span><br><span class="line">                           embedding_function=emb_obj)</span><br><span class="line">db2 = akasha.dbs(docsearch2)</span><br><span class="line"></span><br><span class="line">db2.merge(db1)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(db2.get_ids()))  <span class="comment"># list[str]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(db2.get_embeds())) <span class="comment"># list[list[float]]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(db2.get_metadatas())) <span class="comment">#list[dict]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(db2.get_docs())) <span class="comment">#list[dict]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h4 id="add-chromadb"><a href="#add-chromadb" class="headerlink" title="add_chromadb"></a>add_chromadb</h4><p>dbs物件可以添加新的chromadb資料</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">from</span> langchain_chroma <span class="keyword">import</span> Chroma</span><br><span class="line"></span><br><span class="line">emb_obj = akasha.handle_embeddings()</span><br><span class="line"></span><br><span class="line">docsearch1 = Chroma(persist_directory=<span class="string">&quot;chromadb/123&quot;</span>,</span><br><span class="line">                           embedding_function=emb_obj)</span><br><span class="line"></span><br><span class="line">docsearch2 = Chroma(persist_directory=<span class="string">&quot;chromadb/456&quot;</span>,</span><br><span class="line">                           embedding_function=emb_obj)</span><br><span class="line"></span><br><span class="line">db = akasha.dbs(docsearch1)</span><br><span class="line"></span><br><span class="line">db.add_chromadb(docsearch2)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(db.get_ids()))  <span class="comment"># list[str]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(db.get_embeds())) <span class="comment"># list[list[float]]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(db.get_metadatas())) <span class="comment">#list[dict]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(db.get_docs())) <span class="comment">#list[dict]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h4 id="get-Documents"><a href="#get-Documents" class="headerlink" title="get_Documents"></a>get_Documents</h4><p>使用get_Docuemnts可以得到當前dbs物件中儲存的Documents list (包含page_contents文件內容和metadata後設資料)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">from</span> langchain_chroma <span class="keyword">import</span> Chroma</span><br><span class="line"></span><br><span class="line">emb_obj = akasha.handle_embeddings()</span><br><span class="line"></span><br><span class="line">docsearch1 = Chroma(persist_directory=<span class="string">&quot;chromadb/123&quot;</span>,</span><br><span class="line">                           embedding_function=emb_obj)</span><br><span class="line"></span><br><span class="line">db = akasha.dbs(docsearch1)</span><br><span class="line"></span><br><span class="line">docs = db.get_Documents()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>([doc.page_contents <span class="keyword">for</span> doc <span class="keyword">in</span> docs])  <span class="comment"># list[str]</span></span><br><span class="line"><span class="built_in">print</span>([docs.metadata <span class="keyword">for</span> doc <span class="keyword">in</span> docs]) <span class="comment"># list[dict]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


</br>
</br>

<h3 id="提取dbs物件"><a href="#提取dbs物件" class="headerlink" title="提取dbs物件"></a>提取dbs物件</h3><h4 id="extract-db-by-file"><a href="#extract-db-by-file" class="headerlink" title="extract_db_by_file"></a>extract_db_by_file</h4><p>extract_db_by_file可以將檔名符合file_name_list中的所有資料提取出來生成新的dbs物件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">from</span> langchain_chroma <span class="keyword">import</span> Chroma</span><br><span class="line"></span><br><span class="line">emb_obj = akasha.handle_embeddings()</span><br><span class="line"></span><br><span class="line">docsearch1 = Chroma(persist_directory=<span class="string">&quot;chromadb/123&quot;</span>,</span><br><span class="line">                           embedding_function=emb_obj)</span><br><span class="line"></span><br><span class="line">db = akasha.dbs(docsearch1)</span><br><span class="line">file_name_list = [<span class="string">&#x27;f1.txt&#x27;</span>, <span class="string">&#x27;f2.docx&#x27;</span>]</span><br><span class="line"></span><br><span class="line">extracted_db = akasha.extract_db_by_file(db=db, file_name_list=file_name_list)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(extracted_db.get_ids()))  <span class="comment"># list[str]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(extracted_db.get_embeds())) <span class="comment"># list[list[float]]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(extracted_db.get_metadatas())) <span class="comment">#list[dict]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(extracted_db.get_docs())) <span class="comment">#list[dict]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h4 id="extract-db-by-keyword"><a href="#extract-db-by-keyword" class="headerlink" title="extract_db_by_keyword"></a>extract_db_by_keyword</h4><p>extract_db_by_keyword可以將文字段落中存在任何keyword_list中keyword的所有資料提取出來生成新的dbs物件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">from</span> langchain_chroma <span class="keyword">import</span> Chroma</span><br><span class="line"></span><br><span class="line">emb_obj = akasha.handle_embeddings()</span><br><span class="line"></span><br><span class="line">docsearch1 = Chroma(persist_directory=<span class="string">&quot;chromadb/123&quot;</span>,</span><br><span class="line">                           embedding_function=emb_obj)</span><br><span class="line"></span><br><span class="line">db = akasha.dbs(docsearch1)</span><br><span class="line">keyword_list = [<span class="string">&quot;資訊產業策進會&quot;</span>, <span class="string">&quot;AI人工智慧&quot;</span>]</span><br><span class="line"></span><br><span class="line">extracted_db = akasha.extract_db_by_keyword(db=db, keyword_list=keyword_list)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(extracted_db.get_ids()))  <span class="comment"># list[str]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(extracted_db.get_embeds())) <span class="comment"># list[list[float]]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(extracted_db.get_metadatas())) <span class="comment">#list[dict]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(extracted_db.get_docs())) <span class="comment">#list[dict]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h4 id="extract-db-by-ids"><a href="#extract-db-by-ids" class="headerlink" title="extract_db_by_ids"></a>extract_db_by_ids</h4><p>extract_db_by_ids可以將存在id_list中的的所有資料提取出來生成新的dbs物件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">from</span> langchain_chroma <span class="keyword">import</span> Chroma</span><br><span class="line"></span><br><span class="line">emb_obj = akasha.handle_embeddings()</span><br><span class="line"></span><br><span class="line">docsearch1 = Chroma(persist_directory=<span class="string">&quot;chromadb/123&quot;</span>,</span><br><span class="line">                           embedding_function=emb_obj)</span><br><span class="line"></span><br><span class="line">db = akasha.dbs(docsearch1)</span><br><span class="line">id_list = [<span class="string">&#x27;2024-10-21-17_45_21_963065_0&#x27;</span>, <span class="string">&#x27;2024-10-21-17_45_23_601845_0&#x27;</span>]</span><br><span class="line"></span><br><span class="line">extracted_db = akasha.extract_db_by_ids(db=db, id_list=id_list)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(extracted_db.get_ids()))  <span class="comment"># list[str]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(extracted_db.get_embeds())) <span class="comment"># list[list[float]]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(extracted_db.get_metadatas())) <span class="comment">#list[dict]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(extracted_db.get_docs())) <span class="comment">#list[dict]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="pop-db-by-ids"><a href="#pop-db-by-ids" class="headerlink" title="pop_db_by_ids"></a>pop_db_by_ids</h4><p><em><strong>pop_db_by_ids</strong></em>會將所選id_list中的的所有資料從dbs物件中移除</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">from</span> langchain_chroma <span class="keyword">import</span> Chroma</span><br><span class="line"></span><br><span class="line">emb_obj = akasha.handle_embeddings()</span><br><span class="line"></span><br><span class="line">docsearch1 = Chroma(persist_directory=<span class="string">&quot;chromadb/123&quot;</span>,</span><br><span class="line">                           embedding_function=emb_obj)</span><br><span class="line"></span><br><span class="line">db = akasha.dbs(docsearch1)</span><br><span class="line">id_list = [<span class="string">&#x27;2024-10-21-17_45_21_963065_0&#x27;</span>, <span class="string">&#x27;2024-10-21-17_45_23_601845_0&#x27;</span>]</span><br><span class="line"></span><br><span class="line">akasha.pop_db_by_ids(db=db, id_list=id_list)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(db.get_ids()))  <span class="comment"># list[str]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(db.get_embeds())) <span class="comment"># list[list[float]]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(db.get_metadatas())) <span class="comment">#list[dict]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(db.get_docs())) <span class="comment">#list[dict]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>

<h3 id="其他輔助函式"><a href="#其他輔助函式" class="headerlink" title="其他輔助函式"></a>其他輔助函式</h3><h4 id="get-docs-from-doc"><a href="#get-docs-from-doc" class="headerlink" title="get_docs_from_doc"></a>get_docs_from_doc</h4><p>若不需要向量資料，只需要Documents(page_content, metadata)，可使用get_docs_from_doc從文件資料夾中讀取文件內容並切割成chunk_size文件段落，此函式會回傳docs(list of Documents)和不成功的檔案名稱list。 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docs, ignore_files = akasha.get_docs_from_doc(doc_path=<span class="string">&quot;docs/mic&quot;</span>, chunk_size=<span class="number">1000</span>, ignore_check=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">db = akasha.dbs(docsearch1)</span><br><span class="line">id_list = [<span class="string">&#x27;2024-10-21-17_45_21_963065_0&#x27;</span>, <span class="string">&#x27;2024-10-21-17_45_23_601845_0&#x27;</span>]</span><br><span class="line"></span><br><span class="line">extracted_db = akasha.extract_db_by_ids(db=db, id_list=id_list)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>([doc.page_contents <span class="keyword">for</span> doc <span class="keyword">in</span> docs])  <span class="comment"># list[str]</span></span><br><span class="line"><span class="built_in">print</span>([docs.metadata <span class="keyword">for</span> doc <span class="keyword">in</span> docs]) <span class="comment"># list[dict]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="get-db-metadata"><a href="#get-db-metadata" class="headerlink" title="get_db_metadata"></a>get_db_metadata</h4><p>根據文件資料夾、嵌入模型、chunk size輸出所有文件段落的後設資料list，用於<a href="/2024/12/26/%E8%87%AA%E6%9F%A5%E8%A9%A2/">自查詢</a></p>
<h4 id="update-db-metadta"><a href="#update-db-metadta" class="headerlink" title="update_db_metadta"></a>update_db_metadta</h4><p>將更新完的metadata list存回chromadb，用於<a href="/2024/12/26/%E8%87%AA%E6%9F%A5%E8%A9%A2/">自查詢</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_metadata</span>(<span class="params">metadata_list: <span class="built_in">list</span></span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> json</span><br><span class="line">    <span class="keyword">for</span> metadata <span class="keyword">in</span> metadata_list:</span><br><span class="line">        metadata[<span class="string">&#x27;testing&#x27;</span>]= <span class="string">&#x27;後設資料新增測試&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### set parameter ###</span></span><br><span class="line">dir_path = <span class="string">&quot;docs/pns_query&quot;</span></span><br><span class="line">embed_name = <span class="string">&quot;openai:text-embedding-ada-002&quot;</span></span><br><span class="line">chunk_size = <span class="number">99999</span>  <span class="comment"># make sure 1 file 1 chunk</span></span><br><span class="line">emb_obj = akasha.handle_embeddings(<span class="string">&quot;openai:text-embedding-ada-002&quot;</span>)</span><br><span class="line"><span class="comment">####################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># create chromadb from docs</span></span><br><span class="line">db, _ = akasha.db.processMultiDB(dir_path, <span class="literal">False</span>, emb_obj, chunk_size, <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### add metadata to chromadb ###</span></span><br><span class="line">metadata_list = akasha.db.get_db_metadata(dir_path, embed_name, chunk_size) <span class="comment"># get original metada from chromadb, list of dictionary</span></span><br><span class="line">metadata_list = add_metadata(metadata_list)  <span class="comment"># update/add metadata, you can build your own function to update metadata</span></span><br><span class="line">akasha.db.update_db_metadata(metadata_list, dir_path, embed_name, chunk_size)  <span class="comment"># update and save new metadatas to chromadb</span></span><br><span class="line"><span class="built_in">print</span>(akasha.db.get_db_metadata(dir_path, embed_name, chunk_size)[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/26/%E8%BC%94%E5%8A%A9%E5%87%BD%E6%95%B8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/26/%E8%BC%94%E5%8A%A9%E5%87%BD%E6%95%B8/" class="post-title-link" itemprop="url">輔助函數</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-26 19:59:59" itemprop="dateCreated datePublished" datetime="2024-12-26T19:59:59+08:00">2024-12-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2024-12-25 16:30:31" itemprop="dateModified" datetime="2024-12-25T16:30:31+08:00">2024-12-25</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E9%80%B2%E9%9A%8E/" itemprop="url" rel="index"><span itemprop="name">進階</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="儲存紀錄"><a href="#儲存紀錄" class="headerlink" title="儲存紀錄"></a>儲存紀錄</h2><p>每次執行akasha 的任何函數時，如果使用參數keep_logs&#x3D;True，它都會保存此次運行的參數和結果到logs。每個運行都有一個timestamp，您可以使用 {obj_name}.timestamp_list 來查看它們，並使用它來找到您想要查看的logs。<br>您還可以將logs保存為 .txt 文件或 .json 文件。</p>
<h3 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h3><p>執行完get_response後，可以利用timestamp獲取log，也可以使用<em><strong>save_logs</strong></em>來保存log</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">qa = akasha.Doc_QA(verbose=False, keep_logs=True, search_type=&quot;merge&quot;, max_input_tokens=3000,model=&quot;llama-gpu:model/chinese-alpaca-2-7b.Q5_K_S.gguf&quot;)</span><br><span class="line">query1 = &quot;五軸是什麼&quot;</span><br><span class="line">qa.get_response(doc_path=&quot;./doc/mic/&quot;, prompt = query1)</span><br><span class="line"></span><br><span class="line">tp = qa.timestamp_list</span><br><span class="line">print(tp)</span><br><span class="line">## [&quot;2023/09/26, 10:52:36&quot;, &quot;2023/09/26, 10:59:49&quot;, &quot;2023/09/26, 11:09:23&quot;]</span><br><span class="line"></span><br><span class="line">print(qa.logs[tp[-1]])</span><br><span class="line">## &#123;&quot;fn_type&quot;:&quot;get_response&quot;,&quot;search_type&quot;:&quot;merge&quot;, &quot;max_input_tokens&quot;:3000,.....&quot;response&quot;:....&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">qa.save_logs(file_name=&quot;logs.json&quot;,file_type=&quot;json&quot;)</span><br></pre></td></tr></table></figure>

<p><img src="https://hackmd.io/_uploads/SyfwoYk5T.png" alt="logs"></p>
</br>
</br>


<h2 id="AiiDO"><a href="#AiiDO" class="headerlink" title="AiiDO"></a>AiiDO</h2><p>akasha也可以利用AiiDO來保存執行紀錄，您需要在 AiiDO 平台上創建一個項目。完成後，您將收到自動上傳實驗所需的所有參數。<br>在程序的同一目錄下創建一個 .env 文件，並貼上所有參數。</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">##.env file</span><br><span class="line">MINIO_URL= YOUR_MINIO_URL</span><br><span class="line">MINIO_USER= YOUR_MINIO_USER</span><br><span class="line">MINIO_PASSWORD= YOUR_MINIO_PASSWORD</span><br><span class="line">TRACKING_SERVER_URI= YOUR_TRACKING_SERVER_URI</span><br></pre></td></tr></table></figure>



<p>在創建了 .env 文件之後，您可以使用 record_exp 來設置實驗名稱，它將自動記錄實驗指標和結果到 mlflow 服務器。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line">import os</span><br><span class="line">from dotenv import load_dotenv</span><br><span class="line">load_dotenv() </span><br><span class="line"></span><br><span class="line">os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;your openAI key&quot;</span><br><span class="line"></span><br><span class="line">dir_path = &quot;doc/&quot;</span><br><span class="line">prompt = &quot;「塞西莉亞花」的花語是什麼?	「失之交臂的感情」	「赤誠的心」	「浪子的真情」	「無法挽回的愛」&quot;</span><br><span class="line">exp_name = &quot;exp_akasha_get_response&quot;</span><br><span class="line">ak = akasha.Doc_QA(record_exp=exp_name)</span><br><span class="line">response = ak.get_response(dir_path, prompt)</span><br></pre></td></tr></table></figure>

</br>
</br>


<h4 id="在你指定的實驗名稱中，可以看到不同次實驗的紀錄，每個紀錄的名稱是embedding-search-type-and-model-name的組合"><a href="#在你指定的實驗名稱中，可以看到不同次實驗的紀錄，每個紀錄的名稱是embedding-search-type-and-model-name的組合" class="headerlink" title="在你指定的實驗名稱中，可以看到不同次實驗的紀錄，每個紀錄的名稱是embedding, search type and model name的組合"></a>在你指定的實驗名稱中，可以看到不同次實驗的紀錄，每個紀錄的名稱是embedding, search type and model name的組合</h4><p><img src="https://hackmd.io/_uploads/rkSjnt19p.png" alt="upload_experiments"></p>
</br>
</br>

<h4 id="你也可以直接比較不同次實驗的結果"><a href="#你也可以直接比較不同次實驗的結果" class="headerlink" title="你也可以直接比較不同次實驗的結果"></a>你也可以直接比較不同次實驗的結果</h4><p><img src="https://hackmd.io/_uploads/SyvahY1qp.png" alt="response_comparison"></p>
</br>
</br>


<h2 id="翻譯器"><a href="#翻譯器" class="headerlink" title="翻譯器"></a>翻譯器</h2><p>helper模組中提供寫好的函數<em><strong>call_translator</strong></em>讓LLM協助翻譯回答，如以下的範例使用語言模型將中文的回答翻譯成英文。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ak = akasha.Doc_QA(verbose=False, search_type=&quot;auto&quot;)</span><br><span class="line"></span><br><span class="line">response = ak.get_response(doc_path=&quot;docs/mic/&quot;, prompt=&quot;五軸是什麼?&quot;)</span><br><span class="line"></span><br><span class="line">translated_response = akasha.helper.call_translator(ak.model_obj, response, language=&quot;en&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


</br>
</br>


<h2 id="JSON-格式輸出器"><a href="#JSON-格式輸出器" class="headerlink" title="JSON 格式輸出器"></a>JSON 格式輸出器</h2><p>helper模組中提供寫好的函數<em><strong>call_JSON_formatter</strong></em>讓LLM協助將回答轉成JSON格式。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ak = akasha.Doc_QA(verbose=True,)</span><br><span class="line">response = ak.ask_whole_file(file_path=&quot;docs/resume_pool/A.docx&quot;, prompt=f&#x27;&#x27;&#x27;以上是受試者的履歷，請回答該受試者的學歷、經驗、專長、年資&#x27;&#x27;&#x27;)</span><br><span class="line">formatted_response = akasha.helper.call_JSON_formatter(ak.model_obj, response, keys=[&quot;學歷&quot;, &quot;經驗&quot;, &quot;專長&quot;, &quot;年資&quot;])</span><br><span class="line"></span><br><span class="line">print(formatted_response, type(formatted_response))</span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#x27;學歷&#x27;: &#x27;xxx大學電資學士班四技&#x27;, &#x27;經驗&#x27;: &#x27;帶班導師xx文理補習班擔任補習班導師／管理人員&#x27;, &#x27;專長&#x27;: &#x27;計算機網路(協定)、資料庫系統、物件導向程式設計、C語言、Python、C++、Gitlab、Jenkins、Git、Linux(Bash shell、Ubuntu), &#x27;年資&#x27;: &#x27;0-1年&#x27;&#125; &lt;class &#x27;dict&#x27;&gt;</span><br></pre></td></tr></table></figure>

</br>
</br>


<h2 id="call-model"><a href="#call-model" class="headerlink" title="call_model"></a>call_model</h2><p>若要呼叫語言模型，可以使用輔助函數call_model</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line">system_prompt = &quot;用中文回答&quot;</span><br><span class="line">prompt = &quot;五軸是什麼?&quot;</span><br><span class="line">model_obj = akasha.handle_model(&quot;openai:gpt-e3.5-turbo&quot;, False, 0.0)</span><br><span class="line">input_text = akasha.prompts.format_sys_prompt(system_prompt, prompt, &quot;gpt&quot;)</span><br><span class="line"></span><br><span class="line">response = akasha.call_model(model_obj, input_text)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>


<h2 id="call-stream-model"><a href="#call-stream-model" class="headerlink" title="call_stream_model"></a>call_stream_model</h2><p>若要呼叫語言模型即時回答，可以使用輔助函數call_stream_model</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import akasha</span><br><span class="line"></span><br><span class="line">system_prompt = &quot;用中文回答&quot;</span><br><span class="line">prompt = &quot;五軸是什麼?&quot;</span><br><span class="line">model_obj = akasha.handle_model(&quot;openai:gpt-e3.5-turbo&quot;, False, 0.0)</span><br><span class="line">input_text = akasha.prompts.format_sys_prompt(system_prompt, prompt, &quot;gpt&quot;)</span><br><span class="line"></span><br><span class="line">streaming = akasha.call_stream_model(model_obj, input_text)</span><br><span class="line"></span><br><span class="line">for s in streaming:</span><br><span class="line">    print(s)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</br>
</br>


<h2 id="call-batch-model"><a href="#call-batch-model" class="headerlink" title="call_batch_model"></a>call_batch_model</h2><p>如果你有大量不需要連貫的推理需求，可以使用<strong>akasha.helper.call_batch_model</strong> 來進行批量推理來提升速度。</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def call_batch_model(model: LLM, prompt: List[str], </span><br><span class="line">    system_prompt: Union[List[str], str] = &quot;&quot;) -&gt; List[str]:</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"></span><br><span class="line">model_obj = akasha.helper.handle_model(<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>, <span class="literal">False</span>, <span class="number">0.0</span>)</span><br><span class="line"><span class="comment"># this prompt ask LLM to response &#x27;yes&#x27; or &#x27;no&#x27; if the document segment is relevant to the user question or not.</span></span><br><span class="line">SYSTEM_PROMPT = akasha.prompts.default_doc_grader_prompt() </span><br><span class="line">documents = [<span class="string">&quot;Doc1...&quot;</span>, <span class="string">&quot;Doc2...&quot;</span>, <span class="string">&quot;Doc3...&quot;</span>, <span class="string">&quot;Doc4...&quot;</span>]</span><br><span class="line">question = <span class="string">&quot;五軸是什麼?&quot;</span></span><br><span class="line"></span><br><span class="line">prompts = [<span class="string">&quot;document: &quot;</span> + doc +<span class="string">&quot;\n\n&quot;</span> + <span class="string">&quot;User Question: &quot;</span>+ question <span class="keyword">for</span> doc <span class="keyword">in</span> documents]</span><br><span class="line"></span><br><span class="line">response_list = call_batch_model(model_obj, prompt, SYSTEM_PROMPT)</span><br><span class="line"></span><br><span class="line"><span class="comment">## [&quot;yes&quot;, &quot;no&quot;, &quot;yes&quot;, &quot;yes&quot;]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


</br>
</br>


<h2 id="self-rag"><a href="#self-rag" class="headerlink" title="self-rag"></a>self-rag</h2><p>實作<a target="_blank" rel="noopener" href="https://github.com/AkariAsai/self-rag">self-rag</a>，利用語言模型來找出與問題相關的文件片段。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">question = &quot;LPWAN和5G的區別是什麼?&quot;</span><br><span class="line"></span><br><span class="line">model_name = &quot;openai:gpt-3.5-turbo&quot;</span><br><span class="line">model_obj = akasha.handle_model(model_name, False, 0.0)</span><br><span class="line">emb_obj = akasha.handle_embeddings()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">db = akasha.createDB_directory(&quot;./docs/mic/&quot;, emb_obj, ignore_check=True)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">retrivers_list = akasha.search.get_retrivers(db2, emb_obj, 0.0,</span><br><span class="line">                                             &quot;auto&quot;, &#123;&#125;)</span><br><span class="line"></span><br><span class="line">### max_input_tokens is the max length of tokens, so get_docs function will return top relevant docs that their total legnth do not exceed 6000 tokens ###</span><br><span class="line">docs, doc_length, doc_tokens = akasha.search.get_docs(</span><br><span class="line">    db2,</span><br><span class="line">    retrivers_list,</span><br><span class="line">    question,</span><br><span class="line">    &quot;ch&quot;,</span><br><span class="line">    &quot;auto&quot;,</span><br><span class="line">    False,</span><br><span class="line">    model_name,</span><br><span class="line">    max_input_tokens=6000,</span><br><span class="line">    compression=False,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">### we use self-RAG to sort those docs and using llm to determine the order of relevant docs ###</span><br><span class="line">RAGed_docs = akasha.self_RAG(model_obj,</span><br><span class="line">                             question,</span><br><span class="line">                             docs,)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="計算token數量"><a href="#計算token數量" class="headerlink" title="計算token數量"></a>計算token數量</h2><p>Tokenizer.compute_tokens，此函數回傳該語言模型輸入的文字所需要的token數量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">text = <span class="string">&quot;你是一個歷史學家詳細介紹札幌的歷史&quot;</span></span><br><span class="line">model =  <span class="string">&quot;openai:gpt-3.5-turbo&quot;</span></span><br><span class="line">num_tokens = akasha.myTokenizer.compute_tokens(</span><br><span class="line">    text=text, model_id=model)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(num_tokens)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="根據文件產生關鍵句子"><a href="#根據文件產生關鍵句子" class="headerlink" title="根據文件產生關鍵句子"></a>根據文件產生關鍵句子</h2><p><em><strong>generate_keyword</strong></em>使用keybert，根據輸入的文件來產生相關的關鍵字，可用於建立embeddings</p>
<h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><p><em><strong>akasha.generate_keyword</strong></em>需安裝keybert套件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install keybert</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">text = <span class="string">&quot;&quot;&quot;五軸工具機是一種比三軸工具機更先進的加工裝置。它透過兩個軸控制工具的旋轉方向，再透過長寬高三個軸移動進行切削加工，能</span></span><br><span class="line"><span class="string">進行更複雜形狀的加工，確保加工精密度並符合自動化的訴求。  五軸加工的優勢在於首次手動調整後就能無人運作，節省人力物力，尤其在電動車等</span></span><br><span class="line"><span class="string">領域的生產中，因應零件種類和產量變動頻繁的需求。  然而，五軸加工也面臨加工誤差穩定性的挑戰，例如溫度變動可能導致加工差距。  因此，廠</span></span><br><span class="line"><span class="string">商也致力於開發相關技術，例如大隈的「熱親和理念」和「5軸微調」，以確保加工精密度在自動化環境下保持穩定。&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">keyword_num = <span class="number">3</span> <span class="comment">#產生的關鍵字數量</span></span><br><span class="line"></span><br><span class="line">keyword_model = <span class="string">&quot;paraphrase-multilingual-MiniLM-L12-v2&quot;</span> <span class="comment">#default</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">keywords = akasha.generate_keyword(text=text, keyword_num=keyword_num, keyword_model=keyword_model)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(keywords)</span><br><span class="line"></span><br><span class="line"><span class="comment">### [&#x27;五軸工具機是一種比三軸工具機更先進的加工裝置&#x27;, &#x27;五軸加工的優勢在於首次手動調整後就能無人運作&#x27;, &#x27;五軸加工也面臨加工誤差穩定性的挑戰&#x27;]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/26/%E4%BB%A3%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/26/%E4%BB%A3%E7%90%86/" class="post-title-link" itemprop="url">代理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-26 18:59:59" itemprop="dateCreated datePublished" datetime="2024-12-26T18:59:59+08:00">2024-12-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2024-10-30 16:19:27" itemprop="dateModified" datetime="2024-10-30T16:19:27+08:00">2024-10-30</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E9%80%B2%E9%9A%8E/" itemprop="url" rel="index"><span itemprop="name">進階</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h2><p>使用代理(agent)可以賦予語言模型其他能力，以便完成你下的指令，例如提供文件编辑、google搜尋的工具，便可以使語言模型提供更準確地回答，也可以請他幫忙儲存或刪除文件。</p>
<h3 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h3><p>在範例1中，創建了一個可以讓使用者輸入文字的工具，也提供給代理一個將文字儲存成json檔案的工具。創建代理後，我們指示它詢問用戶問題，並將結果儲存到default.json中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">input_func</span>(<span class="params">question: <span class="built_in">str</span></span>):</span><br><span class="line">    response = <span class="built_in">input</span>(question)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">str</span>(&#123;<span class="string">&quot;question&quot;</span>: question, <span class="string">&quot;answer&quot;</span>: response&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">input_tool = akasha.create_tool(</span><br><span class="line">    <span class="string">&quot;user_question_tool&quot;</span>,</span><br><span class="line">    <span class="string">&quot;This is the tool to ask user question, the only one param question is the question string that has not been answered and we want to ask user.&quot;</span>,</span><br><span class="line">    func=input_func)</span><br><span class="line"></span><br><span class="line">ao = akasha.test_agent(verbose=<span class="literal">True</span>,</span><br><span class="line">                    tools=[</span><br><span class="line">                        input_tool,</span><br><span class="line">                        akasha.get_saveJSON_tool(),</span><br><span class="line">                    ],</span><br><span class="line">                    model=<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">    ao(<span class="string">&quot;逐個詢問使用者以下問題，若所有問題都回答了，則將所有問題和回答儲存成default.json並結束。問題為:1.房間燈關了嗎? \n2. 有沒有人在家?  \n3.有哪些電器開啟?\n&quot;</span></span><br><span class="line">        ))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">I have successfully saved all the questions and answers into the &quot;default.json&quot; file. The conversation is now complete.</span><br><span class="line"></span><br><span class="line">### default.json ###</span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;question&quot;: &quot;房間燈關了嗎?&quot;,</span><br><span class="line">        &quot;answer&quot;: &quot;no&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;question&quot;: &quot;有沒有人在家?&quot;,</span><br><span class="line">        &quot;answer&quot;: &quot;no&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;question&quot;: &quot;有哪些電器開啟?&quot;,</span><br><span class="line">        &quot;answer&quot;: &quot;phone, shower&quot;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br></pre></td></tr></table></figure>


</br>
</br>

<p>在範例二中，我們添加了wikipedia工具，讓語言模型能透過Wikipedia API查詢必要的資訊來幫助回答。由於wiki的回答中可能包含不必要的資訊，我們可以使用retri_observation來擷取與問題有關的回答。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">ao = akasha.test_agent(</span><br><span class="line">        verbose=<span class="literal">True</span>,</span><br><span class="line">        tools=[input_tool,</span><br><span class="line">               akasha.get_saveJSON_tool(),</span><br><span class="line">               akasha.get_wiki_tool()],</span><br><span class="line">        retri_observation=<span class="literal">True</span>,</span><br><span class="line">        model=<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(ao(<span class="string">&quot;請用中文回答李遠哲跟黃仁勳誰比較老?將查到的資訊和答案儲存成json檔案，檔名為AGE.json&quot;</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">根據查到的資訊，李遠哲（Yuan T. Lee）比黃仁勳（Jensen Huang）更老。李遠哲於1936年11月19日出生，而黃仁勳的出生日期是1963年2月17日。我已將這些資訊儲存成名為&quot;AGE.json&quot;的</span><br><span class="line">JSON檔案。</span><br><span class="line"></span><br><span class="line">### AGE.json ###</span><br><span class="line">&#123;</span><br><span class="line">    &quot;李遠哲&quot;: &quot;1936-11-19&quot;,</span><br><span class="line">    &quot;黃仁勳&quot;: &quot;1963-02-17&quot;,</span><br><span class="line">    &quot;答案&quot;: &quot;李遠哲比黃仁勳更老&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</br>
</br>

<h3 id="stream"><a href="#stream" class="headerlink" title="stream"></a>stream</h3><p>若你想及時得到每輪agent的回應，可以使用stream function，此函式將每輪agent的回應回傳為generator</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">ao = akasha.test_agent(</span><br><span class="line">        verbose=True,</span><br><span class="line">        tools=[input_tool,</span><br><span class="line">               akasha.get_saveJSON_tool(),</span><br><span class="line">               akasha.get_wiki_tool()],</span><br><span class="line">        retri_observation=True,</span><br><span class="line">        model=&quot;openai:gpt-3.5-turbo&quot;)</span><br><span class="line">st = ao.stream(&quot;請用中文回答李遠哲跟黃仁勳誰比較老?將查到的資訊和答案儲存成json檔案，檔名為AGE.json&quot;)</span><br><span class="line">for s in st:</span><br><span class="line">    print(s)</span><br></pre></td></tr></table></figure>

</br>
</br>
</br>
</br>

<h3 id="test-agent-中的所有參數"><a href="#test-agent-中的所有參數" class="headerlink" title="test_agent 中的所有參數:"></a>test_agent 中的所有參數:</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Args:</span><br><span class="line">   model (str, optional): 使用的大語言模型. Defaults to &quot;gpt-3.5-turbo&quot;.\n</span><br><span class="line">   verbose (bool, optional): 是否顯示log文字. Defaults to False.\n</span><br><span class="line">   language (str, optional): 用來計算文字長度(max_doc_len)的語言. Defaults to &quot;zh&quot;</span><br><span class="line">   temperature (float, optional): 大語言模型的temperature(0.0 ~ 1.0) . Defaults to 0.0.\n</span><br><span class="line">   keep_logs (bool, optional)**: 是否紀錄執行的log. Defaults to False.\n</span><br><span class="line">   max_round (int, optional)**: agent最多執行次數，超過即跳出，避免無線迴圈. Defaults to 20.\n</span><br><span class="line">   max_input_tokens (int, optional): agent保留的之前做過的思考與動作的文字最大長度. Defaults to 3200.\n</span><br><span class="line">   max_past_observation (int, optional)**: agent保留的之前做過的思考與動作的最多次數. Defaults to 10.\n</span><br><span class="line">   retri_observation (bool, optional)**: 若設為True, agent會利用大語言模型去擷取tool回傳內容，避免多餘文字輸入. Defaults to False.\n</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/26/%E6%B5%81%E8%BC%B8%E5%87%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/26/%E6%B5%81%E8%BC%B8%E5%87%BA/" class="post-title-link" itemprop="url">流輸出</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-26 17:59:59" itemprop="dateCreated datePublished" datetime="2024-12-26T17:59:59+08:00">2024-12-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2024-11-13 11:27:48" itemprop="dateModified" datetime="2024-11-13T11:27:48+08:00">2024-11-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E9%80%B2%E9%9A%8E/" itemprop="url" rel="index"><span itemprop="name">進階</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="call-stream-model"><a href="#call-stream-model" class="headerlink" title="call_stream_model"></a>call_stream_model</h2><p>在輔助函數中，若LLM模型為若為<em><strong>openai</strong></em>, <em><strong>huggingface</strong></em>, <em><strong>remote</strong></em>, <em><strong>gemini</strong></em>, <em><strong>anthropic</strong></em>類模型，可以使用akasha.call_stream_model()來得到流輸出</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line">prompt = <span class="string">&quot;say something.&quot;</span></span><br><span class="line">model_obj = akasha.handle_model(<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>, <span class="literal">False</span>, <span class="number">0.0</span>)</span><br><span class="line">streaming = akasha.call_stream_model(model_obj, prompt)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> streaming:</span><br><span class="line">    <span class="built_in">print</span>(s)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="Doc-QA-stream"><a href="#Doc-QA-stream" class="headerlink" title="Doc_QA stream"></a>Doc_QA stream</h2><p>Doc_QA class的函式皆可使用參數stream&#x3D;True來得到流輸出</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"></span><br><span class="line">ak = akasha.Doc_QA(stream=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">streaming = ak.get_response(<span class="string">&quot;docs/mic&quot;</span>, <span class="string">&quot;say something&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> streaming:</span><br><span class="line">    <span class="built_in">print</span>(s)</span><br></pre></td></tr></table></figure>


<h2 id="Stream-Output"><a href="#Stream-Output" class="headerlink" title="Stream Output"></a>Stream Output</h2><p>要在網頁上或API中使用流輸出(及時一個字一個字輸出語言模型回答)時，若為<em><strong>openai</strong></em>, <em><strong>huggingface</strong></em>, <em><strong>remote</strong></em>, <em><strong>gemini</strong></em>, <em><strong>anthropic</strong></em> 類模型，可以使用model_obj.stream(prompt)，以下為streamlit write_stream在網頁上即時輸出回答為範例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> streamlit <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"><span class="keyword">import</span> gc, torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="string">&quot;pre&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> st.session_state:</span><br><span class="line">    st.session_state.pre = <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">if</span> <span class="string">&quot;model_obj&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> st.session_state:</span><br><span class="line">    st.session_state.model_obj = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">clean</span>():</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        gc.collect()</span><br><span class="line">        torch.cuda.ipc_collect()</span><br><span class="line">        torch.cuda.empty_cache()</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_response</span>(<span class="params">prompt:<span class="built_in">str</span>, model_name:<span class="built_in">str</span>=<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span></span>):</span><br><span class="line">    <span class="comment"># Mistral-7B-Instruct-v0.3   Llama3-8B-Chinese-Chat</span></span><br><span class="line">    streaming = akasha.call_stream_model(st.session_state.model_obj, prompt)</span><br><span class="line">    <span class="keyword">yield</span> <span class="keyword">from</span> streaming</span><br><span class="line"></span><br><span class="line">model = st.selectbox(<span class="string">&quot;select model&quot;</span>, [<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>,<span class="string">&quot;hf:model/Mistral-7B-Instruct-v0.3&quot;</span>])</span><br><span class="line">prompt = st.chat_input(<span class="string">&quot;Say something&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> st.session_state.pre != model:</span><br><span class="line">    st.session_state.model_obj = <span class="literal">None</span></span><br><span class="line">    clean()</span><br><span class="line">    st.session_state.model_obj = akasha.helper.handle_model(model, <span class="literal">False</span>, <span class="number">0.0</span>)</span><br><span class="line">    st.session_state.pre = model</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> prompt:</span><br><span class="line">    st.write(<span class="string">&quot;question: &quot;</span> + prompt)</span><br><span class="line">    st.write_stream(stream_response(prompt, model))</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>使用model_obj &#x3D; akasha.helper.handle_model(model, False, 0.0)建立模型物件，當要使用推論時，使用akasha.call_stream_model(model_obj, prompt)進行推論，可使用yield讓stream_response函式回傳generator, 便可即時輸出回答。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/26/%E6%89%B9%E9%87%8F%E6%8E%A8%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/26/%E6%89%B9%E9%87%8F%E6%8E%A8%E7%90%86/" class="post-title-link" itemprop="url">批量推理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-26 16:59:59" itemprop="dateCreated datePublished" datetime="2024-12-26T16:59:59+08:00">2024-12-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2024-08-30 11:03:53" itemprop="dateModified" datetime="2024-08-30T11:03:53+08:00">2024-08-30</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E9%80%B2%E9%9A%8E/" itemprop="url" rel="index"><span itemprop="name">進階</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="批量推理"><a href="#批量推理" class="headerlink" title="批量推理"></a>批量推理</h2><p>如果你有大量不需要連貫的推理需求，可以使用<strong>akasha.helper.call_batch_model</strong> 來進行批量推理來提升速度。</p>
<h3 id="call-batch-model"><a href="#call-batch-model" class="headerlink" title="call_batch_model"></a>call_batch_model</h3><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def call_batch_model(model: LLM, prompt: List[str], </span><br><span class="line">    system_prompt: Union[List[str], str] = &quot;&quot;) -&gt; List[str]:</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> akasha</span><br><span class="line"></span><br><span class="line">model_obj = akasha.helper.handle_model(<span class="string">&quot;openai:gpt-3.5-turbo&quot;</span>, <span class="literal">False</span>, <span class="number">0.0</span>)</span><br><span class="line"><span class="comment"># this prompt ask LLM to response &#x27;yes&#x27; or &#x27;no&#x27; if the document segment is relevant to the user question or not.</span></span><br><span class="line">SYSTEM_PROMPT = akasha.prompts.default_doc_grader_prompt() </span><br><span class="line">documents = [<span class="string">&quot;Doc1...&quot;</span>, <span class="string">&quot;Doc2...&quot;</span>, <span class="string">&quot;Doc3...&quot;</span>, <span class="string">&quot;Doc4...&quot;</span>]</span><br><span class="line">question = <span class="string">&quot;五軸是什麼?&quot;</span></span><br><span class="line"></span><br><span class="line">prompts = [<span class="string">&quot;document: &quot;</span> + doc +<span class="string">&quot;\n\n&quot;</span> + <span class="string">&quot;User Question: &quot;</span>+ question <span class="keyword">for</span> doc <span class="keyword">in</span> documents]</span><br><span class="line"></span><br><span class="line">response_list = call_batch_model(model_obj, prompt, SYSTEM_PROMPT)</span><br><span class="line"></span><br><span class="line"><span class="comment">## [&quot;yes&quot;, &quot;no&quot;, &quot;yes&quot;, &quot;yes&quot;]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://tea9297.github.io/akasha/2024/12/26/FAST%20API/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/akasha/images/avatar.gif">
      <meta itemprop="name" content="Chih Chuan Chang<ccchang@iii.org.tw>">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="akasha 0.9 使用手冊">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/akasha/2024/12/26/FAST%20API/" class="post-title-link" itemprop="url">FAST API</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2024-12-26 15:59:59" itemprop="dateCreated datePublished" datetime="2024-12-26T15:59:59+08:00">2024-12-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新於</span>
                <time title="修改時間：2024-11-13 11:15:36" itemprop="dateModified" datetime="2024-11-13T11:15:36+08:00">2024-11-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/akasha/categories/%E9%80%B2%E9%9A%8E/" itemprop="url" rel="index"><span itemprop="name">進階</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="FAST-API"><a href="#FAST-API" class="headerlink" title="FAST API"></a>FAST API</h2><p>akasha 提供get_response, ask_self, ask_whole_file, get_summary的api server</p>
<h3 id="啟動"><a href="#啟動" class="headerlink" title="啟動"></a>啟動</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">akasha api (–port &#123;port&#125; –host &#123;host&#125; –workers &#123;num_of_workers&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">HOST = os.getenv(&quot;API_HOST&quot;, &quot;http://127.0.0.1&quot;)</span><br><span class="line">PORT = os.getenv(&quot;API_PORT&quot;, &quot;8000&quot;)</span><br><span class="line">urls = &#123;</span><br><span class="line">    &quot;summary&quot;: f&quot;&#123;HOST&#125;:&#123;PORT&#125;/get_summary&quot;,</span><br><span class="line">    &quot;qa&quot;: f&quot;&#123;HOST&#125;:&#123;PORT&#125;/get_response&quot;,</span><br><span class="line">    &quot;self&quot;: f&quot;&#123;HOST&#125;:&#123;PORT&#125;/ask_self&quot;,</span><br><span class="line">    &quot;file&quot;: f&quot;&#123;HOST&#125;:&#123;PORT&#125;/ask_whole_file&quot;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">openai_config = &#123;</span><br><span class="line">    &quot;azure_key&quot;: &#123;your api key&#125;,</span><br><span class="line">    &quot;azure_base&quot;: &#123;your api base&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">self_data = &#123;</span><br><span class="line">    &quot;prompt&quot;: &quot;太陽電池技術?&quot;,</span><br><span class="line">    &quot;info&quot;: &quot;太陽能電池技術5塊錢&quot;,</span><br><span class="line">    &quot;model&quot;: &quot;openai:gpt-3.5-turbo&quot;,</span><br><span class="line">    &quot;system_prompt&quot;: &quot;&quot;,</span><br><span class="line">    &quot;max_input_tokens&quot;: 3000,</span><br><span class="line">    &quot;temperature&quot;: 0.0,</span><br><span class="line">    &quot;openai_config&quot;: openai_config</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">file_data = &#123;</span><br><span class="line">    &quot;doc_path&quot;: &quot;docs/mic/20230317_5軸工具機因應市場訴求改變的發展態勢.pdf&quot;,</span><br><span class="line">    &quot;prompt&quot;: &quot;五軸是什麼?&quot;,</span><br><span class="line">    &quot;chunk_size&quot;: 1000,</span><br><span class="line">    &quot;model&quot;: &quot;openai:gpt-3.5-turbo&quot;,</span><br><span class="line">    &quot;embedding_model&quot;: &quot;openai:text-embedding-ada-002&quot;,</span><br><span class="line">    &quot;system_prompt&quot;: &quot;&quot;,</span><br><span class="line">    &quot;max_input_tokens&quot;: 3000,</span><br><span class="line">    &quot;temperature&quot;: 0.0,</span><br><span class="line">    &quot;openai_config&quot;: openai_config</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">chat_data = &#123;</span><br><span class="line">    &quot;doc_path&quot;: &quot;docs/pns/&quot;,</span><br><span class="line">    &quot;prompt&quot;: &quot;太陽電池技術?&quot;,</span><br><span class="line">    &quot;chunk_size&quot;: 1000,</span><br><span class="line">    &quot;model&quot;: &quot;openai:gpt-3.5-turbo&quot;,</span><br><span class="line">    &quot;embedding_model&quot;: &quot;openai:text-embedding-ada-002&quot;,</span><br><span class="line">    &quot;search_type&quot;: &#x27;auto&#x27;,</span><br><span class="line">    &quot;system_prompt&quot;: &quot;&quot;,</span><br><span class="line">    &quot;max_input_tokens&quot;: 3000,</span><br><span class="line">    &quot;temperature&quot;: 0.0,</span><br><span class="line">    &quot;openai_config&quot;: openai_config</span><br><span class="line">&#125;</span><br><span class="line">summary_data = &#123;</span><br><span class="line">    &quot;file_path&quot;: &quot;docs/pns/2484.txt&quot;,</span><br><span class="line">    &quot;model&quot;: &quot;openai:gpt-3.5-turbo&quot;,</span><br><span class="line">    &quot;summary_type&quot;: &quot;reduce_map&quot;,</span><br><span class="line">    &quot;summary_len&quot;: 500,</span><br><span class="line">    &quot;system_prompt&quot;: &quot;&quot;,</span><br><span class="line">    &quot;openai_config&quot;: openai_config</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># chat_response = requests.post(urls[&quot;qa&quot;], json=chat_data).json()</span><br><span class="line"># print(chat_response)</span><br><span class="line"></span><br><span class="line"># sum_response = requests.post(</span><br><span class="line">#     urls[&quot;summary&quot;],</span><br><span class="line">#     json=summary_data,</span><br><span class="line"># ).json()</span><br><span class="line"></span><br><span class="line"># print(sum_response)</span><br><span class="line"></span><br><span class="line">self_response = requests.post(urls[&quot;self&quot;], json=self_data).json()</span><br><span class="line">print(self_response)</span><br><span class="line">file_response = requests.post(urls[&quot;file&quot;], json=file_data).json()</span><br><span class="line">print(file_response)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/akasha/"><i class="fa fa-angle-left" aria-label="上一頁"></i></a><a class="page-number" href="/akasha/">1</a><span class="page-number current">2</span><a class="page-number" href="/akasha/page/3/">3</a><a class="extend next" rel="next" href="/akasha/page/3/"><i class="fa fa-angle-right" aria-label="下一頁"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Chih Chuan Chang<ccchang@iii.org.tw></p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/akasha/archives/">
        
          <span class="site-state-item-count">25</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">分類</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">標籤</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chih Chuan Chang<ccchang@iii.org.tw></span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 強力驅動
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/akasha/lib/anime.min.js"></script>
  <script src="/akasha/lib/velocity/velocity.min.js"></script>
  <script src="/akasha/lib/velocity/velocity.ui.min.js"></script>

<script src="/akasha/js/utils.js"></script>

<script src="/akasha/js/motion.js"></script>


<script src="/akasha/js/schemes/muse.js"></script>


<script src="/akasha/js/next-boot.js"></script>




  















  

  

</body>
</html>
